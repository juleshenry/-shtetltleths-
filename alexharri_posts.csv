title,post,timestamp
ASCII characters are not pixels: a deep dive into ASCII rendering,"Recently, I’ve been spending my time building an image-to-ASCII renderer. Below is the result — try dragging it around, the demo is interactive!
One thing I spent a lot of effort on is getting edges looking sharp. Take a look at this rotating cube example:
Try opening the “split” view. Notice how well the characters follow the contour of the square.
This renderer works well for animated scenes, like the ones above, but we can also use it to render static images:
The image of Saturn was
generated with ChatGPT
.
Then, to get better separation between different colored regions, I also implemented a
cel shading
-like effect to enhance contrast between edges. Try dragging the contrast slider below:
The contrast enhancement makes the separation between different colored regions far clearer. That was key to making the 3D scene above look as good as it does.
I put so much focus on sharp edges because they’re an aspect of ASCII rendering that is often overlooked when programmatically rendering images as ASCII. Consider this animated 3D scene from Cognition’s landing page that is rendered via ASCII characters:
Source:
cognition.ai
It’s a cool effect, especially while in motion, but take a look at those blurry edges! The characters follow the cube contours very poorly, and as a result, the edges look blurry and jagged in places:
This blurriness happens because the ASCII characters are being treated like pixels — their
shape
is ignored. It’s disappointing to see because ASCII art looks
so much
better when shape is utilized. I don’t believe I’ve ever seen shape utilized in generated ASCII art, and I think that’s because it’s not really obvious how to consider shape when building an ASCII renderer.
I started building my ASCII renderer to prove to myself that it’s possible to utilize shape in ASCII rendering. In this post, I’ll cover the techniques and ideas I used to capture shape and build this ASCII renderer in detail.
We’ll start with the basics of image-to-ASCII conversion and see where the common issue of blurry edges comes from. After that, I’ll show you the approach I used to fix that and achieve sharp, high-quality ASCII rendering. At the end, we’ll improve on that by implementing the contrast enhancement effect I showed above.
Let’s get to it!
Image to ASCII conversion
ASCII contains
95 printable characters
that we can use. Let’s start off by rendering the following image containing a white circle using those ASCII characters:
ASCII art is (almost) always rendered using a
monospace
font. Since every character in a monospace font is equally wide and tall, we can split the image into a grid. Each grid cell will contain a single ASCII character.
The image with the circle is
pixels. For the ASCII grid, I’ll pick a row height of
pixels and a column width of
pixels. That splits the canvas into
rows and
columns — an
grid:
Monospace characters are typically taller than they are wide, so I made each grid cell a bit taller than it is wide.
Our task is now to pick which character to place in each cell. The simplest approach is to calculate a lightness value for each cell and pick a character based on that.
We can get a lightness value for each cell by sampling the lightness of the pixel at the cell’s center:
We want each pixel’s lightness as a numeric value between
and
, but our image data consists of pixels with
RGB
color values.
We can use the following formula to convert an RGB color (with component values between
and
) to a lightness value:
See
relative luminance
.
Mapping lightness values to ASCII characters
Now that we have a lightness value for each cell, we want to use those values to pick ASCII characters. As mentioned before, ASCII has 95 printable characters, but let’s start simple with just these characters:
: - # = + @ * % .
We can sort them in approximate density order like so, with lower-density characters to the left, and high-density characters to the right:
. : - = + * # % @
We’ll put these characters in a
CHARS
array:
const
CHARS
=
[
"" ""
,
"".""
,
"":""
,
""-""
,
""=""
,
""+""
,
""*""
,
""#""
,
""%""
,
""@""
]
I added space as the first (least dense) character.
We can then map lightness values between
and
to one of those characters like so:
function
getCharacterFromLightness
(
lightness
:
number
)
{
const
index
=
Math
.
floor
(
lightness
*
(
CHARS
.
length
-
1
)
)
;
return
CHARS
[
index
]
;
}
This maps low lightness values to low-density characters and high lightness values to high-density characters.
Rendering the circle from above with this method gives us:
That works... but the result is pretty ugly. We seem to always get
@
for cells that fall within the circle and a space for cells that fall outside.
That is happening because we’ve pretty much just implemented nearest-neighbor downsampling. Let’s see what that means.
Nearest neighbor downsampling
Downsampling, in the context of image processing, is taking a larger image (in our case, the
image with the circle) and using that image’s data to construct a lower resolution image (in our case, the
ASCII grid). The pixel values of the lower resolution image are calculated by sampling values from the higher resolution image.
The simplest and fastest method of sampling is
nearest-neighbor interpolation
, where, for each cell (pixel), we only take a single sample from the higher resolution image.
Consider the circle example again. Using nearest-neighbor interpolation, every sample either falls inside or outside of the shape, resulting in either
or
lightness:
If, instead of picking an ASCII character for each grid cell, we color each grid cell (pixel) according to the sampled value, we get the following pixelated rendering:
This pixelated rendering is pretty much equivalent to the ASCII rendering from before. The only difference is that instead of
@
s we have white pixels, and instead of spaces we have black pixels.
These square, jagged looking edges are aliasing artifacts, commonly called
jaggies
. They’re a common result of using nearest-neighbor interpolation.
Supersampling
To get rid of jaggies, we can collect more samples for each cell. Consider this line:
The line’s slope on the
axis is
. When we pixelate it with nearest-neighbor interpolation, we get the following:
Let’s try to get rid of the jagginess by taking multiple samples within each cell and using the average sampled lightness value as the cell’s lightness. The example below lets you vary the number of samples using the slider:
With multiple samples, cells that lie on the edge of a shape will have some of their samples fall within the shape, and some outside of it. Averaging those, we get gray in-between colors that smooth the downsampled image. Below is the same example, but with an overlay showing where the samples are taken:
This method of collecting multiple samples from the larger image is called
supersampling
. It’s a common method of
spatial anti-aliasing
(avoiding jaggies at edges). Here’s what the rotating square looks like with supersampling (using
samples for each cell):
Let’s look at what supersampling does for the circle example from earlier. Try dragging the sample quality slider:
The circle becomes less jagged, but the edges feel blurry. Why’s that?
Well, they feel blurry because we’re pretty much just rendering a low-resolution, pixelated image of a circle. Take a look at the pixelated view:
The ASCII and pixelated views are mirror images of each other. Both are just low-resolution versions of the original high-resolution image, scaled up to the original’s size — it’s no wonder they both look blurry.
Increasing the number of samples is insufficient. No matter how many samples we take per cell, the samples will be averaged into a single lightness value, used to render a single pixel.
And that’s the core problem: treating each grid cell as a pixel in an image. It’s an obvious and simple method, but it disregards that ASCII characters have shape.
We can make our ASCII renderings far more crisp by picking characters based on their shape. Here’s the circle rendered that way:
The characters follow the contour of the circle very well. By picking characters based on shape, we get a far higher
effective
resolution. The result is also more visually interesting.
Let’s see how we can implement this.
Shape
So what do I mean by shape? Well, consider the characters
T
,
L
, and
O
placed within grid cells:
The character
T
is top-heavy. Its visual density in the upper half of the grid cell is higher than in the lower half. The opposite can be said for
L
— it’s bottom-heavy.
O
is pretty much equally dense in the upper and lower halves of the cell.
We might also compare characters like
L
and
J
. The character
L
is heavier within the left half of the cell, while
J
is heavier in the right half:
We also have more “extreme” characters, such as
_
and
^
, that only occupy the lower or upper portion of the cell, respectively:
This is, roughly, what I mean by “shape” in the context of ASCII rendering. Shape refers to which regions of a cell a given character visually occupies.
Quantifying shape
To pick characters based on their shape, we’ll somehow need to quantify (put numbers to) the shape of each character.
Let’s start by only considering how much characters occupy the upper and lower regions of our cell. To do that, we’ll define two “sampling circles” for each grid cell — one placed in the upper half and one in the lower half:
It may seem odd or arbitrary to use circles instead of just splitting the cell into two rectangles, but using circles will give us more flexibility later on.
A character placed within a cell will overlap each of the cell’s sampling circles to
some
extent.
One can compute that overlap by taking a bunch of samples within the circle (for example, at every pixel). The fraction of samples that land inside the character gives us the overlap as a numeric value between
and
:
For T, we get an overlap of approximately
for the upper circle and
for the lower. Those overlap values form a
-dimensional vector:
We can generate such a
-dimensional vector for each character within the ASCII alphabet. These vectors quantify the shape of each ASCII character along these
dimensions (upper and lower). I’ll call these vectors
shape vectors
.
Below are some ASCII characters and their shape vectors. I’m coloring the sampling circles using the component values of the shape vectors:
We can use the shape vectors as 2D coordinates — here’s every ASCII character on a 2D plot:
0
0
0.05
0.05
0.1
0.1
0.15
0.15
0.2
0.2
0.25
0.25
0.3
0.3
0.35
0.35
0.4
0.4
Upper
Lower
^
@
q
T
M
u
X
$
g
=
C
Shape-based lookup
Let’s say that we have our ASCII characters and their associated shape vectors in a
CHARACTERS
array:
const
CHARACTERS
:
Array
<
{
character
:
string
,
shapeVector
:
number
[
]
,
}
>
=
[
...
]
;
We can then perform a nearest neighbor search like so:
function
findBestCharacter
(
inputVector
:
number
[
]
)
{
let
bestCharacter
=
""""
;
let
bestDistance
=
Infinity
;
for
(
const
{
character
,
shapeVector
}
of
CHARACTERS
)
{
const
dist
=
getDistance
(
shapeVector
,
inputVector
)
;
if
(
dist
<
bestDistance
)
{
bestDistance
=
dist
;
bestCharacter
=
character
;
}
}
return
bestCharacter
;
}
The
findBestCharacter
function gives us the ASCII character whose shape best matches the input lookup vector.
Note: this brute force search is not very performant. This becomes a bottleneck when we start rendering thousands of ASCII characters at
FPS
. I’ll talk more about this later.
To make use of this in our ASCII renderer, we’ll calculate a lookup vector for each cell in the ASCII grid and pass it to
findBestCharacter
to determine the character to display.
Let’s try it out. Consider the following zoomed-in circle as an example. It is split into three grid cells:
Overlaying our sampling circles, we see varying degrees of overlap:
When calculating the shape vector of each ASCII character, we took a huge number of samples. We could afford to do that because we only need to calculate those shape vectors once up front. After they’re calculated, we can use them again and again.
However, if we’re converting an animated image (e.g. canvas or video) to ASCII, we need to be mindful of performance when calculating the lookup vectors. An ASCII rendering might have hundreds or thousands of cells. Multiplying that by tens or hundreds of samples would be incredibly costly in terms of performance.
With that being said, let’s pick a sampling quality of
with the samples placed like so:
For the top sampling circle of the leftmost cell, we get one white sample and two black, giving us an average lightness of
. Doing the same calculation for all of the sampling circles, we get the following 2D vectors:
From now on, instead of using the term “lookup vectors”, I’ll call these vectors, sampled from the image that we’re rendering as ASCII,
sampling vectors
. One sampling vector is calculated for each cell in the grid.
Anyway, we can use these sampling vectors to find the best-matching ASCII character. Let’s see what that looks like on our 2D plot — I’ll label the sampling vectors (from left to right) C0, C1, and C2:
0
0
0.1
0.1
0.2
0.2
0.3
0.3
0.4
0.4
0.5
0.5
0.6
0.6
0.7
0.7
0.8
0.8
0.9
0.9
1
1
Upper
Lower
C0
C1
C2
P
$
Hmm... this is not what we want. Since none of the ASCII shape vector components exceed
, they’re all clustered towards the bottom-left region of our plot. This makes our sampling vectors map to a few characters on the edge of the cluster.
We can fix this by
normalizing
the shape vectors. We’ll do that by taking the maximum value of each component across all shape vectors, and dividing the components of each shape vector by the maximum. Expressed in code, that looks like so:
const
max
=
[
0
,
0
]
for
(
const
vector
of
characterVectors
)
{
for
(
const
[
i
,
value
]
of
Object
.
entries
(
vector
)
)
{
if
(
value
>
max
[
i
]
)
{
max
[
i
]
=
value
;
}
}
}
const
normalizedCharacterVectors
=
characterVectors
.
map
(
vector
=>
vector
.
map
(
(
value
,
i
)
=>
value
/
max
[
i
]
)
)
Here’s what the plot looks like with the shape vectors normalized:
0
0
0.1
0.1
0.2
0.2
0.3
0.3
0.4
0.4
0.5
0.5
0.6
0.6
0.7
0.7
0.8
0.8
0.9
0.9
1
1
Upper
Lower
^
@
q
T
M
u
X
$
g
=
C
If we now map the sampling vectors to their nearest neighbors, we get a much more sensible result:
0
0
0.1
0.1
0.2
0.2
0.3
0.3
0.4
0.4
0.5
0.5
0.6
0.6
0.7
0.7
0.8
0.8
0.9
0.9
1
1
Upper
Lower
C0
C1
C2
M
$
'
We get
'
,
M
and
$
.  Let’s see how well those characters match the circle:
Nice! They match very well.
Let’s try rendering the full circle from before with the same method:
Much better than before! The picked characters follow the contour of the circle very well.
Limits of a 2D shape vector
Using two sampling circles — one upper and one lower — produces a much better result than the
-dimensional (pixelated) approach. However, it still falls short when trying to capture other aspects of a character’s shape.
For example, two circles don’t capture the shape of characters that fall in the middle of the cell. Consider
-
:
For
-
, we get a shape vector of
. That doesn’t represent the character very well at all.
The two upper-lower sampling circles also don’t capture left-right differences, such as the difference between
p
and
q
:
We could use such differences to get better character picks, but our two sampling circles don’t capture them. Let’s add more dimensions to our shape to fix that.
Increasing to 6 dimensions
Since cells are taller than they are wide (at least with the monospace font I’m using), we can use
sampling circles to cover the area of each cell quite well:
sampling circles capture left-right differences, such as between
p
and
q
, while also capturing differences across the top, bottom, and middle regions of the cell, differentiating
^
,
-
, and
_
. They also capture the shape of “diagonal” characters like
/
to a reasonable degree.
One problem with this grid-like configuration for the sampling circles is that there are gaps. For example,
.
falls between the sampling circles:
To compensate for this, we can stagger the sampling circles vertically (e.g. lowering the left sampling circles and raising the right ones) and make them a bit larger. This causes the cell to be almost fully covered while not causing excessive overlap across the sampling circles:
We can use the same procedure as before to generate character vectors using these sampling circles, this time yielding a
-dimensional vector. Consider the character
L
:
For
L
, we get the vector:
I’m presenting
-dimensional shape vectors in a
matrix form because it’s easier to grok geometrically, but the actual vector is a flat list of numbers.
The lightness values certainly look L-shaped! The 6D shape vector captures
L
’s shape very well.
Nearest neighbor lookups in a 6D space
Now we have a 6D shape vector for every ASCII character. Does that affect character lookups (how we find the best matching character)?
Earlier, in the
findBestCharacter
function, I referenced a
getDistance
function. That function returns the
Euclidean distance
between the input points. Given two 2D points
and
, the formula to calculate their Euclidean distance looks like so:
This generalizes to higher dimensions:
Put into code, this looks like so:
function
getDistance
(
a
:
number
[
]
,
b
:
number
[
]
)
:
number
{
let
sum
=
0
;
for
(
let
i
=
0
;
i
<
a
.
length
;
i
++
)
{
sum
+=
(
a
[
i
]
-
b
[
i
]
)
**
2
;
}
return
Math
.
sqrt
(
sum
)
;
}
Note: since we’re just using this for the purposes of finding the closest point, we can skip the expensive
Math
.
sqrt
(
)
call and just return the squared distance. It does not affect the result.
So, no, the dimensionality of our shape vector does not change lookups at all. We can use the same
getDistance
function for both 2D and 6D.
With that out of the way, let’s see what the 6D approach yields!
Trying out the 6D approach
Our new 6D approach works really well for flat shapes, like the circle example we’ve been using:
Now let’s see how this approach works when we render a 3D scene with more shades of gray:
Firstly, the outer contours look nice and sharp. I also like how well the gradients across the sphere and cone look.
However, internally, the objects all kind of blend together. The edges
between
surfaces with different lightnesses aren’t sharp enough. For example, the lighter faces of the cubes all kind of blend into one solid color. When there is a change in color — like when two faces of a cube meet — I’d like to see more sharpness in the ASCII rendering.
To demonstrate what I mean, consider the following split:
It’s currently rendered like so:
The different shades result in
i
s on the left and
B
s on the right, but the boundary is not very sharp.
By applying some effects to the sampling vector, we can enhance the contrast at the boundary so that it appears sharper:
The added contrast makes a
big
difference in readability for the 3D scene. Let’s look at how we can implement this contrast enhancement effect.
Contrast enhancement
Consider cells overlapping a color boundary like so:
For the cells on the boundary, we get a 6D sampling vector that looks like so:
To make future examples easier to visualize, I’ll start drawing the sampling vector using
circles like so:
0.65
0.65
0.31
0.31
0.22
0.22
Currently, this sampling vector resolves to the character
T
:
0.65
0.65
0.31
0.31
0.22
0.22
→
T
Picked character:
T
That’s a sensible choice. The character
T
is visually dense in the top half and less so in the bottom half, so it matches the image fairly well.
Still, I want the picked character to emphasize the shape of the boundary better. We can achieve that by enhancing the contrast of the sampling vector.
To increase the contrast of our sampling vector, we might raise each component of the vector to the power of some exponent.
Consider how an exponent affects values between
and
. Numbers close to
experience a strong pull towards
while larger numbers experience less pull. For example,
, a 90% reduction, while
, only a reduction of 10%.
The level of pull depends on the exponent. Here’s a chart of
for values of
between
and
:
This effect becomes more pronounced with higher exponents:
A higher exponent translates to a stronger pull towards zero.
Applying an exponent should make dark values darker more quickly than light ones. The example below allows you to vary the exponent applied to the sampling vector:
0.65
0.65
0.31
0.31
0.22
0.22
Exponent
1
2
1
As the exponent is increased to
, the darker components of the sampling vector quickly become
much
darker, just like we wanted. However, the lighter components also get pulled towards zero by a significant amount.
I don’t want that. I want to increase the contrast
between
the lighter and darker components of the sampling vector, not the vector in its entirety.
To achieve that, we can normalize the sampling vector to the range
prior to applying the exponent, and then “denormalize” the vector back to the original range afterwards.
The normalization to
can be done by dividing each component by the maximum component value. After applying the exponent, mapping back to the original range is done by multiplying each component by the same max value:
const
maxValue
=
Math
.
max
(
...
samplingVector
)
samplingVector
=
samplingVector
.
map
(
(
value
)
=>
{
value
=
value
/
maxValue
;
// Normalize
value
=
Math
.
pow
(
value
,
exponent
)
;
value
=
value
*
maxValue
;
// Denormalize
return
value
;
}
)
Here’s the same example, but with this normalization applied:
0.65
0.65
0.31
0.31
0.22
0.22
Exponent
1
2
1
Very nice! The lightest component values are retained, and the contrast between the lighter and darker components is increased by “crunching” the lower values.
This affects which character is picked. The following example shows how the selected character changes as the contrast is increased:
0.65
0.65
0.31
0.31
0.22
0.22
→
T
Picked character:
T
Exponent
1
2
1
Awesome! The pick of
""
over
T
emphasizes the separation between the lighter region above and the darker region below!
By enhancing the contrast of the sampling vector, we exaggerate its shape. This gives us a character that less faithfully represents the underlying image, but improves readability as a whole by enhancing the separation between different colored regions.
Let’s look at another example. Observe how the L-shape of the sampling vector below becomes more pronounced as the exponent increases, and how that affects the picked character:
0.68
0.31
0.76
0.31
0.77
0.78
→
&
Picked character:
&
Exponent
1
2
1
Works really nicely! I
love
the transition from
& -> b -> L
as the L-shape of the vector becomes clearer.
What’s nice about applying exponents to normalized sampling vectors is that it barely affects vectors that are uniform in value. If all component values are similar, applying an exponent has a minimal effect:
0.64
0.52
0.62
0.51
0.60
0.50
→
&
Picked character:
&
Exponent
1
2
1
Because the vector is fairly uniform, the exponent only has a slight effect and doesn’t change the picked character.
This is a good thing! If we have a smooth gradient in our image, we want to retain it. We very much do
not
want to introduce unnecessary choppiness.
Compare the 3D scene ASCII rendering with and without this contrast enhancement:
We do see more contrast at boundaries, but this is not quite there yet. Some edges are still not sharp enough, and we also observe a “staircasing” effect happening at some boundaries.
Let’s look at the staircasing effect first. We can reproduce it with a boundary like so:
Below is the ASCII rendering of that boundary. Notice how the lower edge (the
!
s) becomes “staircase-y” as you increase the exponent:
We see a staircase pattern like so:
!!!!!
!!!!!!!!!!
!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!
To understand why that’s happening, let’s consider the row in the middle of the canvas, progressing from left to right. As we start off, every sample is equally light, giving us
U
s:
UUUUUUUU ->
As we reach the boundary, the lower right samples become a bit darker. Those darker components are crunched by contrast enhancement, giving us some
Y
s:
0.60
0.60
0.60
0.60
0.40
0.30
→
A
Picked character:
A
Exponent
1
2
1
So we get:
UUUUUUUUYY ->
As we progress further right, the middle and lower samples get darker, so we get some
f
s:
0.60
0.60
0.55
0.46
0.32
0.26
→
f
Picked character:
f
This trend continues towards
""
,
'
, and finally,
`
:
0.54
0.45
0.34
0.25
0.20
0.20
→
!
Picked character:
!
Exponent
1
2
1
Giving us a sequence like so:
UUUUUUUUYYf""""''` ->
That looks good, but at some point we get
no
light samples. Once we get no light samples, our contrast enhancement has no effect because every component is equally light. This causes us to always get
!
s:
0.20
0.20
0.20
0.20
0.20
0.20
→
!
Picked character:
!
Exponent
1
2
1
Making our sequence look like so:
UUUUUUUUYYf""""''`!!!!!!!!!! ->
This sudden stop in contrast enhancement having an effect is what causes the staircasing effect:
!!!!!
!!!!!!!!!!
!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!
Let’s see how we can counteract this staircasing effect with
another
layer of contrast enhancement, this time looking outside of the boundary of each cell.
Directional contrast enhancement
We currently have sampling circles arranged like so:
For each of those sampling circles, we’ll specify an “external sampling circle”, placed outside of the cell’s boundary, like so:
Each of those external sampling circles is “reaching” into the region of a neighboring cell. Together, the samples that are collected by the external sampling circles constitute an “external sampling vector”.
Let’s simplify the visualization and consider a single example. Imagine that we collected a sampling vector and an external sampling vector that look like so:
0.51
0.51
0.52
0.52
0.53
0.53
0.80
0.51
0.57
0.52
0.53
0.53
→
U
Picked character:
U
The circles colored red are the external sampling vector components. Currently, they have no effect.
The “internal” sampling vector itself is fairly uniform, with values ranging from
to
. The external vector’s values are similar, except in the upper left region where the values are significantly lighter (
and
). This indicates a color boundary above and to the left of the cell.
To enhance this apparent boundary, we’ll darken the top-left and middle-left components of the sampling vector. We can do that by applying
component-wise
contrast enhancement using the values from the external vector.
In the previous contrast enhancement, we calculated the maximum component value across the sampling vector and normalized the vector using that value:
const
maxValue
=
Math
.
max
(
...
samplingVector
)
samplingVector
=
samplingVector
.
map
(
(
value
)
=>
{
value
=
value
/
maxValue
;
// Normalize
value
=
Math
.
pow
(
value
,
exponent
)
;
value
=
value
*
maxValue
;
// Denormalize
return
value
;
}
)
But the new component-wise contrast enhancement will take the maximum value between each component of the sampling vector and the corresponding component in the external sampling vector:
samplingVector
=
samplingVector
.
map
(
(
value
,
i
)
=>
{
const
maxValue
=
Math
.
max
(
value
,
externalSamplingVector
[
i
]
)
// ...
}
)
;
Aside from that, the contrast enhancement is performed in the same way:
samplingVector
=
samplingVector
.
map
(
(
value
,
i
)
=>
{
const
maxValue
=
Math
.
max
(
value
,
externalSamplingVector
[
i
]
)
;
value
=
value
/
maxValue
;
value
=
Math
.
pow
(
value
,
exponent
)
;
value
=
value
*
maxValue
;
return
value
;
}
)
;
The example below shows how light values in the external sampling vector push values in the sampling vector down:
0.51
0.51
0.52
0.52
0.53
0.53
0.80
0.51
0.57
0.52
0.53
0.53
→
U
Picked character:
U
Exponent
1
4
1
I call this “directional contrast enhancement”, since each of the external sampling circles reaches outside of the cell in the
direction
of the sampling vector component that it is enhancing the contrast of. I describe the other effect as “global contrast enhancement” since it acts on all of the sampling vector’s components together.
Let’s see what this directional contrast enhancement does to get rid of the staircasing effect:
Hmm, that’s not doing what I wanted. I wanted to see a sequence like so:
..::!!
..::!!!!!!!!
..::!!!!!!!!!!!!!!
But we just see
!
changing to
:
0.20
0.20
0.20
0.20
0.20
0.20
0.40
0.35
0.20
0.20
0.20
0.20
→
!
Picked character:
!
Exponent
1
4
1
This happens because the directional contrast enhancement doesn’t reach far enough into our sampling vector. The light upper values in the external vector
do
push the upper values of the sampling vector down, but because the lightness of the four bottom components is retained, we don’t get to
.
, just
:
.
Widening the directional contrast enhancement
I’d like to “widen” the directional contrast enhancement so that, for example, light external values at the top spread to the middle components of the sampling vector.
To do that, I’ll introduce a few more external sampling circles, arranged like so:
These are a total of
external sampling circles. Each of the external sampling circles will affect one or more of the internal sampling circles. Here’s an illustration showing which internal circles each external circle affects:
0.30
0.30
0.30
0.30
0.30
0.30
0.30
0.30
0.30
0.30
0.30
0.30
0.30
0.30
0.30
0.30
For each component of the internal sampling vector, we’ll calculate the maximum value across the external sampling vector components that affect it, and use that maximum to perform the contrast enhancement.
Let’s implement that. I’ll order the internal and external sampling circles like so:
0
1
2
3
4
5
0
1
2
3
4
5
6
7
8
9
We can then define a mapping from the internal circles to the external sampling circles that affect them:
const
AFFECTING_EXTERNAL_INDICES
=
[
[
0
,
1
,
2
,
4
]
,
[
0
,
1
,
3
,
5
]
,
[
2
,
4
,
6
]
,
[
3
,
5
,
7
]
,
[
4
,
6
,
8
,
9
]
,
[
5
,
7
,
8
,
9
]
,
]
;
With this, we can change the calculation of
maxValue
to take the maximum affecting external value:
// Before
const
maxValue
=
Math
.
max
(
value
,
externalSamplingVector
[
i
]
)
;
// After
let
maxValue
=
value
;
for
(
const
externalIndex
of
AFFECTING_EXTERNAL_INDICES
[
i
]
)
{
maxValue
=
Math
.
max
(
maxValue
,
externalSamplingVector
[
externalIndex
]
)
;
}
Now look what happens if the top four external sampling circles are light: it causes the contrast enhancement to reach into the middle of the sampling vector, giving us the desired effect:
0.20
0.20
0.20
0.20
0.20
0.20
0.58
0.52
0.31
0.26
0.20
0.20
0.20
0.20
0.20
0.20
→
!
Picked character:
!
Exponent
1
4
1
We now smoothly transition from
! -> : -> .
— beautiful stuff!
Let’s see if this change resolves the staircasing effect:
Oh yeah, looks awesome! We get the desired effect. The boundary is nice and sharp while not being too jagged.
Here’s the 3D scene again. The contrast slider now applies both types of contrast enhancement at the same time — try it out:
This really enhances the contrast at boundaries, making the image far more readable!
Together, the 6D shape vector approach and contrast enhancement techniques have given us a really nice final ASCII rendering.
Final words
This post was really fun to build and write! I hope you enjoyed reading it.
ASCII rendering is perhaps not the most useful topic to write about, but I think the idea of using a high-dimensional vector to capture shape is interesting and could easily be applied to many other problems. There are parallels to be drawn to
word embeddings
.
I started writing this ASCII renderer to see if the idea of using a vector to capture the shape of characters would work at all. That approach turned out to work very well, but the initial prototype was terribly slow — I only got single-digit FPS on my iPhone. To get the ASCII renderer running at a smooth
FPS on mobile required a lot of optimization work. I describe some of that optimization work in the appendices on
character lookup performance
and
GPU acceleration
below.
My colleagues, after reading a draft of this post, suggested
many
alternatives to the approaches I described in this post. For example, why not make the sampling vector
? That would capture the shape of
T
far better — just look how
T
’s stem falls between the two sampling circles in each row:
And yeah, he’s right! A
layout would certainly capture it better. They also suggested many alternative approaches to the contrast enhancement methods I described, but I won’t explore those in this post.
It’s really fun how large the solution space to the problem of ASCII rendering is. There are so, so many approaches and trade-offs to explore. I imagine you probably thought of a few yourself while reading this post!
One dimension I intentionally did not explore was using different colors or lightnesses for the ASCII characters themselves. This is for many reasons, but the two primary ones are that 1) it would have expanded the scope of this post too much, and 2) it’s just a different effect, and I personally don’t like the look.
At the time of writing these final words, around
months have elapsed since I started working on this post. This has been my longest writing process to date. Much of that can be explained by the birth of my now
-month-old daughter. I’ve needed to be a lot more intentional about finding time to write — and disciplined when spending it. I intend to write some smaller posts next. Let’s see if I manage to stick to that promise.
Thanks for reading! And huge thanks to
Gunnlaugur Þór Briem
and
Eiríkur Fannar Torfason
for reading and providing feedback on a draft of this post.
— Alex Harri
Mailing list
To be notified of new posts, subscribe to my mailing list.
Subscribe
Appendix I: Character lookup performance
Earlier in this post, I showed how to find the best character by finding the character with the shortest Euclidean distance to our sampling vector.
function
findBestCharacter
(
inputVector
:
number
[
]
)
{
let
bestCharacter
=
""""
;
let
bestDistance
=
Infinity
;
for
(
const
{
character
,
shapeVector
}
of
CHARACTERS
)
{
const
dist
=
getDistance
(
shapeVector
,
inputVector
)
;
if
(
dist
<
bestDistance
)
{
bestDistance
=
dist
;
bestCharacter
=
character
;
}
}
return
bestCharacter
;
}
I tried benchmarking this for
input sampling vectors on my MacBook —
K invocations of this function consistently take about
ms. If we want to be able to use this for an animated canvas at
FPS, we only have
ms to render each frame. We can use this to get a rough budget for how many lookups we can perform each frame:
If we allow ourselves
of the performance budget for just lookups, this gives us a budget of about
K characters. Not terrible, but far from great, especially considering that we’re using numbers from a powerful laptop. A mobile device might have a
times lower budget. Let’s see how we can improve this.
k-d trees
-d trees are a data structure that enables nearest-neighbor lookups in multi-dimensional (
-dimensional) space. Their performance
degrades in higher dimensions
(e.g.
), but they perform well in
dimensions — perfect for our purpose.
Internally,
-d trees are a binary tree where each node is a
-dimensional point. Each node can be thought to split the
-dimensional space in half with a hyperplane, with the left subtree on one side of the hyperplane and the right subtree on the other.
I won’t go into much detail on
-d trees here. You’ll have to look at other resources if you’re interested in learning more.
One could also look at the
hierarchical navigable small worlds
(HNSW) algorithm, which
Eiríkur
pointed me to. It is used for approximate nearest neighbor lookups in vector databases, so definitely relevant.
Let’s see how it performs! We’ll construct a
-d tree with our characters and their associated vectors:
const
kdTree
=
new
KdTree
(
CHARACTERS
.
map
(
(
{
character
,
shapeVector
}
)
=>
(
{
point
:
shapeVector
,
data
:
character
,
}
)
)
)
;
We can now perform nearest-neighbor lookups on the
-d tree:
const
result
=
kdTree
.
findNearest
(
samplingVector
)
;
Running
K such lookups takes about
ms on my MacBook. That’s about
x faster than the brute-force approach. We can use this to calculate, roughly, the number of lookups we can perform per frame:
That’s a lot of lookups per frame, but again, we’re benchmarking on a powerful machine. This is still not good enough.
Let’s see how we can eke out even more performance.
Caching
An obvious avenue for speeding up lookups is to cache the result:
function
searchCached
(
samplingVector
:
number
[
]
)
{
const
key
=
generateCacheKey
(
samplingVector
)
if
(
cache
.
has
(
key
)
)
{
return
cache
.
get
(
key
)
!
;
}
const
result
=
search
(
samplingVector
)
;
cache
.
set
(
key
,
result
)
;
return
result
;
}
But how does one generate a cache key for a
-dimensional vector?
Well, one way is to quantize each vector component so that it fits into a set number of bits and packing those bits into a single number. JavaScript numbers give us
bits to work with, so each vector component gets
bits.
We can quantize a numeric value between
and
to the range
to
(the most that
bits can store) like so:
const
BITS
=
5
;
const
RANGE
=
2
**
BITS
;
function
quantizeTo5Bits
(
value
:
number
)
{
return
Math
.
min
(
RANGE
-
1
,
Math
.
floor
(
value
*
RANGE
)
)
;
}
Applying a max of
RANGE
-
1
is done so that a
value
of exactly
is mapped to
instead of
.
We can quantize each of the sampling vector components in this manner and use bit shifting to pack all of the quantized values into a single number like so:
const
BITS
=
5
;
const
RANGE
=
2
**
BITS
;
function
generateCacheKey
(
vector
:
number
[
]
)
:
number
{
let
key
=
0
;
for
(
let
i
=
0
;
i
<
vector
.
length
;
i
++
)
{
const
quantized
=
Math
.
min
(
RANGE
-
1
,
Math
.
floor
(
vector
[
i
]
*
RANGE
)
)
;
key
=
(
key
<<
BITS
)
|
quantized
;
}
return
key
;
}
The
RANGE
is current set to
2
**
5
, but consider how large that makes our key space. Each vector component is one of
possible values. With
vector components, that makes the total number of possible keys
, which equals
. If the cache were to be fully saturated, just storing the keys would take
GB of memory! I’d also expect the cache hit rate to be incredibly low if we were to lazily fill the cache.
Alright,
is too high, but what value should we pick? We can pick any number under
for our range. To help, here’s a table showing the number of possible keys (and the memory needed to store them) for range values between
and
:
Range
Number of keys
Memory needed to store keys
6
46,656
364 KB
7
117,649
919 KB
8
262,144
2.00 MB
9
531,441
4.05 MB
10
1,000,000
7.63 MB
11
1,771,561
13.52 MB
12
2,985,984
22.78 MB
There are trade-offs to consider here. As the range gets smaller, the quality of the results drops. If we pick a range of
, for example, the only possible lightness values are
,
,
,
,
and
. That noticeably affects the quality of character picks.
At the same time, if we increase the possible number of keys, we need more memory to store them. Additionally, the cache hit rate might be very low, especially when the cache is relatively empty.
I ended up picking a range of
. It’s a large enough range that quality doesn’t suffer too much while keeping the cache size reasonably low.
Cached lookups are incredibly fast — fast enough that lookup performance just isn’t a concern anymore (
K lookups take a few ms on my MacBook). And if we prepopulate the cache, we can expect consistently fast performance, though I encountered no problems just lazily populating the cache.
Appendix II: GPU acceleration
Lookups were not the only performance concern. Just collecting the sampling vectors (internal and external) turned out to be terribly expensive.
Just consider the sheer amount of samples that need to be collected. The 3D scene I’ve been using as an example uses a
grid, which equals
cells. For each of those cells, we compute a
-dimensional sampling vector and a
-dimensional external sampling vector. That is more than
K vector components to compute on every frame!
And that’s if we use a sampling quality of
. If we increase the sampling quality, this number just gets bigger.
Collecting these samples absolutely
crushed
performance on my iPhone, so I needed to either collect fewer samples or speed up the collection of samples. Collecting fewer samples would have meant rendering fewer ASCII characters or removing the directional contrast enhancement, neither of which was an appealing solution.
My initial implementation ran on the CPU, which could only collect one sample at a time. To speed this up, I moved the work of sampling collection and applying the contrast enhancement to the GPU. The pipeline for that looks like so (each of the steps listed is a single shader pass):
Collect the raw internal sampling vectors into a
texture, using the canvas (image) as the input texture.
Do the same for the external sampling vectors.
Calculate the maximum external value affecting each internal vector component into a
texture.
Apply directional contrast enhancement to each sampling vector component, using the maximum external values texture.
Calculate the maximum value for each internal sampling vector into a
texture.
Apply global contrast enhancement to each sampling vector component, using the maximum internal values texture.
I’m glossing over the details because I could spend a whole other post covering them, but moving work to the GPU made the renderer many times more performant than it was when everything ran on the CPU.
Mailing list
To be notified of new posts, subscribe to my mailing list.
Subscribe","Jan 17, 2026"
"A flowing WebGL gradient, deconstructed","A few weeks ago I embarked on a journey to create a flowing gradient effect — here’s what I ended up making:
Loading canvas...
This effect is written in a WebGL shader using noise functions and some clever math.
In this post, I’ll break it down step by step. You need no prior knowledge of WebGL or shaders — we’ll start by building a mental model for writing shaders and then recreate the effect from scratch.
We’ll cover a lot in this post: writing shaders, interpolation, color mapping, gradient noise, and more. I’ll help you develop an intuition for these concepts using dozens of visual (and interactive!) explanations.
If you just want to see the final code, I’ll include a link to the shader code at the end of the post (this blog is
open source
so you can just take a look).
Let’s get started!
Color as a function of position
Building the gradient effect will boil down to writing a function that takes in a pixel position and returns a color value:
type
Position
=
{
x
:
number
,
y
:
number
}
;
function
pixelColor
(
{
x
,
y
}
:
Position
)
:
Color
;
For every pixel on the canvas, we’ll invoke the color function with the pixel’s position to calculate its color. A canvas frame might be rendered like so:
for
(
let
x
=
0
;
x
<
canvas
.
width
;
x
++
)
{
for
(
let
y
=
0
;
y
<
canvas
.
height
;
y
++
)
{
const
color
=
pixelColor
(
{
x
,
y
}
)
;
canvas
.
drawPixel
(
{
x
,
y
}
,
color
)
;
}
}
To start, let’s write a color function that produces a linear gradient like so:
Loading canvas...
To produce this red-to-blue gradient we’ll blend red and blue with a blend factor that increases from
to
over the width of the canvas — let’s call that blending factor
. We can calculate it like so:
function
pixelColor
(
{
x
,
y
}
:
Position
)
:
Color
{
const
t
=
x
/
(
canvas
.
width
-
1
)
;
}
Having calculated the blending factor
, we’ll use it to mix red and blue:
const
red
=
color
(
""#ff0000""
)
;
const
blue
=
color
(
""#0000ff""
)
;
function
pixelColor
(
{
x
,
y
}
:
Position
)
:
Color
{
const
t
=
x
/
(
canvas
.
width
-
1
)
;
return
mix
(
red
,
blue
,
t
)
;
}
The
mix
function is an interpolation function that
linearly interpolates
between the two input colors using a blend factor between
and
(
in our case).
A
mix
function for two numbers can be implemented like so:
function
mix
(
a
:
number
,
b
:
number
,
t
:
number
)
{
return
a
*
(
1
-
t
)
+
b
*
t
;
}
The mix function is often called “lerp” — short for linear interpolation.
A
mix
function for two colors works the same way, except we mix the color components. To mix two RGB colors, for example, we’d mix the red, green, and blue channels.
function
mix
(
a
:
Color
,
b
:
Color
,
t
:
number
)
{
return
new
Color
(
a
.
r
*
(
1
-
t
)
+
b
.
r
*
t
,
a
.
g
*
(
1
-
t
)
+
b
.
g
*
t
,
a
.
b
*
(
1
-
t
)
+
b
.
b
*
t
,
)
;
}
Anyway,
mix
(
red
,
blue
,
t
)
produces a red-to-blue gradient over the width of the canvas (the
axis):
Loading canvas...
When
x
==
0
we get a
value of
, giving us 100% red. When
x
==
canvas
.
width
-
1
we get a
value of
, giving us 100% blue. If
we get 70% red and 30% blue.
If we want an oscillating gradient (red to blue to red again, repeating), we can do that by using
sin
(
x
)
to calculate the blending factor:
function
pixelColor
(
{
x
,
y
}
:
Position
)
:
Color
{
let
t
=
sin
(
x
)
;
t
=
(
t
+
1
)
/
2
;
// Normalize
return
mix
(
red
,
blue
,
t
)
;
}
Note:
sin
returns a value between
and
, but the
mix
function accepts a value between
and
. For this reason, we normalize
by remapping
to
via
.
This produces the following effect:
Loading canvas...
Those waves are very thin! That’s because we’re oscillating between red and blue every
pixels.
We can control the rate of oscillation by defining a
frequency
multiplier. It will determine over how many pixels the gradient oscillates from red to blue and red again. To produce a wavelength of
pixels, we’ll set the frequency multiplier to
:
const
L
=
40
;
const
frequency
=
(
2
*
PI
)
/
L
;
function
pixelColor
(
{
x
,
y
}
:
Position
)
:
Color
{
let
t
=
sin
(
x
*
frequency
)
;
// ...
}
This produces an oscillating gradient with the desired wavelength — try changing the value of
using the slider to see the effect:
Loading canvas...
Adding motion
So far we’ve only produced static images. To introduce motion, we’ll update our color function to take in a
time
value as well.
function
pixelColor
(
{
x
,
y
}
:
Position
,
time
:
number
)
:
Color
;
We’ll define
time
as the elapsed time, measured in seconds.
By adding
time
to the pixel’s
position, we simulate the canvas “scrolling” to the right one pixel a second:
let
t
=
sin
(
(
x
+
time
)
*
frequency
)
;
But scrolling one pixel a second is very slow. Let’s add a speed constant
to control the speed of the scrolling motion and multiply
time
by it:
const
S
=
20
;
let
t
=
sin
(
(
x
+
time
*
S
)
*
frequency
)
;
Here’s the result — try adjusting the speed via the
slider:
Loading canvas...
Voila, we’ve got movement!
These two inputs — time and the pixel’s position — will be the main components that drive our final effect.
We’ll spend the rest of the post writing a color function that will calculate a color for every pixel — with the pixel’s position and time as the function’s inputs. Together, the colors of each pixel constitute a single frame of animation.
Loading canvas...
But consider the amount of work that needs to be done. A
canvas
, like the one above,
, for example,
contains
pixels. That’s
invocations of our pixel function every frame — a ton of work for a CPU to perform 60 times a second! This is where WebGL comes in.
WebGL shaders run on the GPU, which is useful to us because the GPU is designed for highly parallel computation. A GPU can invoke our color function thousands of times in parallel, making the task of rendering a single frame a breeze.
Conceptually, nothing changes. We’re still going to be writing a single color function that takes a position and time value and returns a color. But instead of writing it in JavaScript and running it on the CPU, we’ll write it in GLSL and run it on the GPU.
WebGL and GLSL
WebGL can be thought of as a subset of
OpenGL
, which is a cross-platform API for graphics rendering. WebGL is based on
OpenGL ES
— an OpenGL spec for embedded systems (like mobile devices).
Here’s a page listing the
differences between OpenGL and WebGL
. We won’t encounter those differences in this post.
OpenGL shaders are written in GLSL, which stands for
OpenGL Shading Language
. It’s a strongly typed language with a C-like syntax.
There are two types of shaders, vertex shaders and fragment shaders, which serve different purposes. Our color function will run in a fragment shader (sometimes referred to as a “pixel shader”). That’s where we’ll spend most of our time.
There’s tons of boilerplate code involved in setting up a WebGL rendering pipeline. I’ll mostly omit it so that we can stay focused on our main goal, which is creating a cool gradient effect.
Throughout this post, I’ll link to resources I found helpful in learning about how to set up and work with WebGL.
Writing a fragment shader
Here’s a WebGL fragment shader that sets every pixel to the same color.
void
main
(
)
{
vec4
color
=
vec4
(
0.7
,
0.1
,
0.4
,
1.0
)
;
gl_FragColor
=
color
;
}
WebGL fragment shaders have a
main
function that is invoked once for each pixel. The
main
function sets the value of
gl_FragColor
— a special variable that specifies the color of the pixel.
We can think of
main
as the entry point of our color function and
gl_FragColor
as its return value.
WebGL colors are represented through vectors with 3 or 4 components:
vec3
for RGB and
vec4
for RGBA colors. The first three components (RGB) are the red, green, and blue components. For 4D vectors, the fourth component is the
alpha
component of the color — its opacity.
vec3
red
=
vec3
(
1.0
,
0.0
,
0.0
)
;
vec3
blue
=
vec3
(
0.0
,
0.0
,
1.0
)
;
vec3
white
=
vec3
(
1.0
,
1.0
,
1.0
)
;
vec4
semi_transparent_green
=
vec4
(
0.0
,
1.0
,
0.0
,
0.5
)
;
WebGL colors use a
fractional representation
, where each components is a value between
and
. Consider the color in the shader:
void
main
(
)
{
vec4
color
=
vec4
(
0.7
,
0.1
,
0.4
,
1.0
)
;
gl_FragColor
=
color
;
}
We can trivially convert the fractional GLSL color
vec3
(
0.7
,
0.1
,
0.4
)
to the percentage-based CSS color
rgb
(
70
%
,
10
%
,
40
%
)
. We can also multiply the fraction by 255 to get the unsigned integer representation
rgb
(
178
,
25
,
102
)
.
Anyway, if we run the shader we see that every pixel is set to that color:
Loading canvas...
Let’s create a linear gradient that fades to another color over the
axis. Let’s use
rgb
(
229
,
154
,
25
)
— it corresponds to
vec3
(
0.9
,
0.6
,
0.1
)
in GLSL.
vec3
color_1
=
vec3
(
0.7
,
0.1
,
0.4
)
;
vec3
color_2
=
vec3
(
0.9
,
0.6
,
0.1
)
;
I’ve been using
this tool
to convert from hex to GLSL colors, and vice versa
To gradually transition from
color_1
to
color_2
over the
axis, we’ll need the
coordinate of the current pixel. In WebGL fragment shaders, we get that via a special variable called
gl_FragCoord
:
float
y
=
gl_FragCoord
.
y
;
float
corresponds to a 32-bit floating point number. We’ll only use the
float
and
int
number types in this post, both of which are 32-bit.
Similar to before, we’ll use the pixel’s
coordinate to calculate a blend value
by dividing
by the canvas height.
const
float
CANVAS_WIDTH
=
150.0
;
float
y
=
gl_FragCoord
.
y
;
float
t
=
y
/
(
CANVAS_WIDTH
-
1.0
)
;
Note:
I’ve configured the coordinates such that
gl_FragCoord
is
(
0.0
,
0.0
)
at the lower-left corner and
(
CANVAS_WIDTH
-
1
,
CANVAS_HEIGHT
-
1
)
at the upper right corner. This will stay consistent throughout the post.
We’ll mix the two colors with GLSL’s
built-in
mix
function
.
vec3
color
=
mix
(
color_1
,
color_2
,
t
)
;
GLSL has a bunch of
built-in math functions
such as
sin
,
clamp
, and
pow
.
We’ll assign our newly calculated
color
to
gl_FragColor
:
vec3
color
=
mix
(
color_1
,
color_2
,
t
)
;
gl_FragColor
=
color
;
But wait — we get a compile-time error.
ERROR: ‘assign’ : cannot convert from ‘3-component vector of float’ to ‘FragColor 4-component vector of float’
This error is a bit obtuse, but it’s telling us that we can’t assign our
vec3
color
to
gl_FragColor
because
gl_FragColor
is of type
vec4
.
In other words, we need to add an alpha component to
color
before passing it to
gl_FragColor
. We can do that like so:
vec3
color
=
mix
(
color_1
,
color_2
,
t
)
;
gl_FragColor
=
vec4
(
color
,
1.0
)
;
This gives us a linear gradient!
Loading canvas...
Vector constructors
You may have raised an eyebrow at the
vec4
(
color
,
1.0
)
expression above — it’s equivalent to
vec4
(
vec3
(
.
.
.
)
,
1.0
)
, which is perfectly valid in GLSL!
When passing a vector to a
vector constructor
, the components of the input vector are read left-to-right — similar to JavaScript’s
spread
syntax.
vec3
a
;
// this:
vec4
foo
=
vec4
(
a
.
x
,
a
.
y
,
a
.
z
,
1.0
)
;
// is equivalent to this:
vec4
foo
=
vec4
(
a
,
1.0
)
;
You can combine number and vector inputs in any way you see fit as long as the total number of values passed to the vector constructor is correct:
vec4
(
1.0
vec2
(
2.0
,
3.0
)
,
4.0
)
;
// OK
vec4
(
vec2
(
1.0
,
2.0
)
,
vec2
(
3.0
,
4.0
)
)
;
// OK
vec4
(
vec2
(
1.0
,
2.0
)
,
3.0
)
;
// Error, not enough components
Coloring areas different colors
Let’s color the bottom half of our canvas white, like so:
Loading canvas...
To do that, we’ll first calculate the
position of the canvas’ midline:
const
float
MID_Y
=
CANVAS_HEIGHT
*
0.5
;
We can then determine the pixel’s
signed
distance from the line through subtraction:
float
y
=
gl_FragCoord
.
y
;
float
dist
=
MID_Y
-
y
;
What determines whether our pixel should be white or not is whether it’s below the line, which we can determine by reading the sign of the distance via the
sign
function. The
sign
function returns
if the value is negative and
if it’s positive.
float
dist
=
MID_Y
-
y
;
sign
(
dist
)
;
// -1.0 or 1.0
We can calculate an alpha (blend) value by normalizing the sign to
or
via
.
float
alpha
=
(
sign
(
dist
)
+
1.0
)
/
2.0
;
Blending
color
and
white
using
alpha
colors the bottom half of the canvas white:
color
=
mix
(
color
,
white
,
alpha
)
;
Loading canvas...
Here,
alpha
represents how white our pixel is. If
alpha
==
1.0
the pixel is colored white, but if
alpha
==
0.0
the original value of
color
is retained.
Calculating an alpha value by normalizing the sign and passing that to the
mix
function may seem overly roundabout. Couldn’t you just use an if statement?
if
(
sign
(
dist
)
==
1.0
)
{
color
=
white
;
}
You could, but only if you want to pick 100% of either color. As we extend this to smoothly blend between the colors, using conditionals won’t work.
As an additional point, you generally want to avoid branching (if-else statements) in code that runs on the GPU. There are
nuances
to the performance of branches in shader code, but branchless code is usually preferable. In our case, calculating the
alpha
and running the
mix
function boils down to sequential math instructions that GPUs excel at.
Drawing arbitrary curves
We’re currently coloring everything under
MID_Y
white, but the line doesn’t need to be determined by a constant — we can calculate the
of a curve using an arbitrary expression and use that to calculate
dist
:
float
curve_y
=
<
some expression
>
;
float
dist
=
curve_y
-
y
;
That allows us to draw the area under any curve white. Let’s, for example, define the curve as a slanted line
where
is the start position of the line, and
is the
incline
of the line. We can put this into code like so:
const
float
Y
=
0.4
*
CANVAS_HEIGHT
;
const
float
I
=
0.2
;
float
x
=
gl_FragCoord
.
x
;
float
curve_y
=
Y
+
x
*
I
;
This produces the slanted line in the canvas below — you can vary
to see the effect:
Loading canvas...
We could also draw a parabola like so:
// Adjust x=0 to be in the middle of the canvas
float
x
=
gl_FragCoord
.
x
-
CANVAS_WIDTH
/
2.0
;
float
curve_y
=
Y
+
pow
(
x
,
2.0
)
/
40.0
;
Loading canvas...
The point is that we can define the curve however we want.
Producing an animated wave
To draw a sine wave, we can define the curve as:
where
is the wave’s baseline
position,
is the
amplitude
of the wave, and
is the wave’s length in pixels. Putting this into code, we get:
const
float
Y
=
0.5
*
CANVAS_HEIGHT
;
const
float
A
=
15.0
;
const
float
L
=
75.0
;
const
float
frequency
=
(
2.0
*
PI
)
/
L
;
float
curve_y
=
Y
+
sin
(
x
*
frequency
)
*
A
;
This draws a sine wave:
Loading canvas...
At the moment, things are completely static. For our shader to produce any motion we’ll need to introduce a time variable. We can do that using
uniforms
.
uniform
float
u_time
;
You can think of uniforms as per-draw call constants — global variables that the shader has
read-only
access to. The actual values of uniforms are controlled on the JavaScript side.
Within a given draw call, each shader invocation will have uniforms set to the same values. This is what the name “uniform” refers to — the values of uniforms are
uniform
across shader invocations within a given draw call. The JavaScript side can, however, change the values of uniforms
between
draw calls.
Uniforms are constant within draw calls but they are
not compile-time constant
, meaning you cannot use the value of a uniform in
const
variables.
Uniform variables can be of many types, such as floats, vectors, and textures (we’ll cover textures later). But what’s up with the
u_
prefix?
uniform
float
u_time
;
Prefixing uniform names with
u_
is a GLSL convention. You won’t encounter compiler errors if you don’t, but prefixing uniform names with
u_
is a very established pattern.
Note:
There are similar conventions for the names of attributes and varyings (they’re prefixed with
a_
and
v_
, respectively), but we won’t use attributes or varyings in this post.
Anyway, with
u_time
now accessible in our shader we can start producing motion. As a refresher, we’re currently calculating our curve’s
value like so:
float
curve_y
=
Y
+
sin
(
x
*
W
)
*
A
;
Adding
u_time
to the pixel’s
position shifts the wave to the left over time:
float
curve_y
=
Y
+
sin
(
(
x
+
u_time
)
*
W
)
*
A
;
But moving one pixel a second is quite slow (
u_time
is measured in seconds), so we’ll add a speed constant
to control the speed:
const
float
S
=
25.0
;
float
curve_y
=
Y
+
sin
(
(
x
+
u_time
*
S
)
*
W
)
*
A
;
Try varying
to see the speed change:
Loading canvas...
Applying a gradient to the lower half
Instead of the lower half being a flat white color, let’s make it a gradient (like the upper half).
The upper half’s gradient is currently composed of two colors:
color_1
and
color_2
. Let’s rename those to
upper_color_1
and
upper_color_2
:
vec3
upper_color_1
=
vec3
(
0.7
,
0.1
,
0.4
)
;
vec3
upper_color_2
=
vec3
(
0.9
,
0.6
,
0.1
)
;
For the lower half’s gradient, we’ll introduce two new colors:
lower_color_1
and
lower_color_2
.
vec3
lower_color_1
=
vec3
(
1.0
,
0.7
,
0.5
)
;
vec3
lower_color_2
=
vec3
(
1.0
,
1.0
,
0.9
)
;
We’ll calculate a
value using the pixel’s
position, using that to gradually mix the colors over the
axis:
float
t
=
y
/
(
CANVAS_HEIGHT
-
1.0
)
;
vec3
upper_color
=
mix
(
upper_color_1
,
upper_color_2
,
t
)
;
vec3
lower_color
=
mix
(
lower_color_1
,
lower_color_2
,
t
)
;
With this, we’ve effectively calculated two gradients. We’ll then determine which gradient to use for the current pixel’s color using
alpha
:
float
alpha
=
(
sign
(
curve_y
-
y
)
+
1.0
)
/
2.0
;
vec3
color
=
mix
(
upper_color
,
lower_color
,
alpha
)
;
This applies the gradients to the halves:
Loading canvas...
Since the value of
alpha
is calculated using the sign of the distance, its value will abruptly change from
to
at the wave’s edge — that’s what gives us the sharp split.
Let’s look at how we can make the split smoother using blur.
Adding blur
Take another look at the final animation and consider the role that blur plays:
Loading canvas...
The blur isn’t applied uniformly over the wave — a variable amount of blur is applied to different parts of the wave, and the amount fluctuates over time.
How might we achieve that?
Gaussian blur
When thinking about how I’d approach the blur problem, my first thought was to use
Gaussian blur
. I figured I’d determine the amount of blur to apply via a
noise function
and then sample neighboring pixels according to the blur amount.
That’s a valid approach — progressive blur in WebGL is
feasible
— but in order to get a decent blur we’d need to sample lots of neighboring pixels, and the amount of pixels to sample only increases as the blur radius gets larger. The final effect requires a very large blur radius, so that becomes incredibly expensive
very
quickly.
Additionally, for us to be able to sample the alpha values of neighboring pixels with any reasonable performance, we’d need to calculate their alpha values up front. To do that we’d need to pre-render the alpha channel
into a texture
for us to sample, which would require setting up another shader and render pass. Not a huge deal, but it
would
add complexity.
I opted to take a different approach that doesn’t require sampling neighboring pixels. Let’s take a look.
Calculate blur using signed distance
Here’s how we’re currently calculating
alpha
:
float
dist
=
curve_y
-
y
;
float
alpha
=
(
sign
(
dist
)
+
1.0
)
/
2.0
;
By taking the sign of our distance, we always get an opacity of 0% or 100% — either fully transparent or completely opaque. Let’s instead make
alpha
gradually transition from
to
over a number of pixels. Let’s define a constant for that:
const
float
BLUR_AMOUNT
=
50.0
;
We’ll change the calculation for
alpha
to just be
dist
/
BLUR_AMOUNT
.
float
alpha
=
dist
/
BLUR_AMOUNT
;
When
dist
==
0.0
, the alpha will be
, and as
dist
approaches
BLUR_AMOUNT
the alpha approaches
. This will cause
alpha
to transition from
to
over the desired number of pixels, but we need to consider that
when
dist
exceeds
BLUR_AMOUNT
the alpha will exceed
, and
the alpha becomes negative when
dist
is negative.
Both of those would cause problems (alpha values should only range from
to
) so we’ll clamp
alpha
to the range
using the built-in
clamp
function:
float
alpha
=
dist
/
BLUR_AMOUNT
;
alpha
=
clamp
(
alpha
,
0.0
,
1.0
)
;
This produces a blur effect, but we can observe the wave “shifting down” as the blur increases — try varying the amount of blur using the slider:
Loading canvas...
We can fix the downshift by starting
alpha
at
:
float
alpha
=
0.5
+
dist
/
BLUR_AMOUNT
;
alpha
=
clamp
(
alpha
,
0.0
,
1.0
)
;
Starting at
causes
alpha
to transition from
to
as
dist
ranges from
-
BLUR_AMOUNT
/
2
to
BLUR_AMOUNT
/
2
, which keeps the wave centered:
Loading canvas...
Let’s now make blur gradually increase from left to right. To gradually increase the blur, we can
linearly interpolate
from no blur to
BLUR_AMOUNT
over the
axis like so:
float
t
=
gl_FragCoord
.
x
/
(
CANVAS_WIDTH
-
1
)
float
blur_amount
=
mix
(
1.0
,
BLUR_AMOUNT
,
t
)
;
Using
blur_amount
to calculate the alpha, we get a gradually increasing blur:
float
alpha
=
dist
/
blur_amount
;
alpha
=
clamp
(
alpha
,
0.0
,
1.0
)
;
Loading canvas...
This forms the basis for how we’ll produce the blur in the final effect.
The blur currently looks a bit “raw”, but let’s put that aside for the time being. We’ll make it look awesome later in the post.
Let’s now work on creating a natural-looking wave.
Stacking sine waves
I often reach for stacked sine waves when I need a simple and natural wave-like noise function. Here’s an example of a wave created using stacked sine waves:
Loading canvas...
The idea is to sum the output of multiple sine waves with different wavelengths, amplitudes, and phase speeds.
Take the following pure sine waves:
Loading canvas...
If you combine them into a single wave, you get an interesting final wave:
Loading canvas...
The equation for the individual sine waves is
where
,
and
are variables that control different aspects of the wave:
determines the wavelength,
determines the phase evolution speed, and
determines the amplitude of the wave.
The final wave can be described as the sum of
such waves:
Which put into code, looks like so:
float
sum
=
0.0
;
sum
+=
sin
(
x
*
L1
+
u_time
*
S1
)
*
A1
;
sum
+=
sin
(
x
*
L2
+
u_time
*
S2
)
*
A2
;
sum
+=
sin
(
x
*
L3
+
u_time
*
S3
)
*
A3
;
.
.
.
return
sum
;
The problem, then, is finding
,
,
values for each sine wave that, when stacked, produce a nice-looking final wave.
In finding those values, I first create a “baseline wave” with the
,
,
components set to values that feel right. I picked these values:
const
float
L
=
0.015
;
const
float
S
=
0.6
;
const
float
A
=
32.0
;
float
sum
=
sin
(
x
*
L
+
u_time
*
S
)
*
A
;
They produce the following wave:
Loading canvas...
This wave has the rough shape of what I want the final wave to look like, so these values serve as a good baseline.
I then add more sine waves that use the baseline
,
,
values multiplied by some constants. After some trial and error, I ended up with the following:
float
sum
=
0.0
;
sum
+=
sin
(
x
*
(
L
/
1.000
)
+
u_time
*
0.90
*
S
)
*
A
*
0.64
;
sum
+=
sin
(
x
*
(
L
/
1.153
)
+
u_time
*
1.15
*
S
)
*
A
*
0.40
;
sum
+=
sin
(
x
*
(
L
/
1.622
)
+
u_time
*
-
0.75
*
S
)
*
A
*
0.48
;
sum
+=
sin
(
x
*
(
L
/
1.871
)
+
u_time
*
0.65
*
S
)
*
A
*
0.43
;
sum
+=
sin
(
x
*
(
L
/
2.013
)
+
u_time
*
-
1.05
*
S
)
*
A
*
0.32
;
Observe how
is multiplied by a negative number for waves 3 and 5. Making some of the waves travel in the opposite direction prevents the final wave from feeling as if it’s moving in one direction at a constant rate.
These five sine waves give us a reasonably natural-looking final wave:
Loading canvas...
Because all of the sine waves are defined by
,
,
, we can tune the waves together by adjusting those constants. Increase
to make the waves faster,
to make the waves shorter, and
to make the waves taller. Try varying
and
:
Loading canvas...
We won’t actually make use of stacked sine waves in our final effect. We
will
, however, use the idea of stacking waves of different scales and speeds.
Simplex noise
Simplex noise
is a family of
-dimensional gradient noise functions developed by
Ken Perlin
. Ken first introduced “classic”
Perlin noise
in 1983 and later created simplex noise in 2001 to address some of the
drawbacks
of Perlin noise.
The dimensionality of a simplex noise function refers to how many numeric input values the function takes (the 2D simplex noise function takes two numeric arguments, the 3D function takes three). All simplex noise functions return a single numeric value between
and
.
2D simplex noise is frequently used, for example, to
procedurally generate terrain
in video games. Here’s an example texture created using 2D simplex noise that could be used as a height map:
Loading canvas...
It is generated by calculating the lightness of each pixel using the output of the 2D simplex noise function with the pixel’s
and
coordinates as inputs.
const
float
L
=
0.02
;
float
x
=
gl_FragCoord
.
x
*
L
;
float
y
=
gl_FragCoord
.
y
*
L
;
float
lightness
=
(
simplex_noise
(
x
,
y
)
+
1.0
)
/
2.0
;
gl_FragColor
=
vec4
(
vec3
(
lightness
)
,
1.0
)
;
Note:
The
simplex_noise
implementation I’m using can be found in
this GitHub repository
.
controls the scale of the
coordinates. As
increases, the noise becomes smaller. Here’s a canvas where you can adjust
to see the effect:
Loading canvas...
We’ll use 2D simplex noise to create an animated 1D wave. The idea behind that may not be very obvious, so let’s see how it works.
1D animation using 2D noise
Consider the following points:
Loading 3D scene
The points are arranged in a grid configuration on the
and
axes, with the
coordinate of each point calculated via
simplex_noise
(
x
,
z
)
:
for
(
const
point
of
points
)
{
const
{
x
,
z
}
=
point
;
point
.
y
=
simplex_noise
(
x
,
z
)
;
}
By doing this we’ve effectively created a 3D surface from a 2D input (the
and
coordinates).
Fair enough, but how does that relate to generating an animated wave?
Consider what happens if we use time as the
coordinate. As time passes, the value of
increases, giving us different 1D slices of the
values of the surface along the
axis. Here’s a visualization:
Loading 3D scene
Putting this into code for our 2D canvas is fairly simple:
uniform
float
u_time
;
const
float
L
=
0.0015
;
const
float
S
=
0.12
;
const
float
A
=
40.0
;
float
x
=
gl_FragCoord
.
x
;
float
curve_y
=
MID_Y
+
simplex_noise
(
x
*
L
,
u_time
*
S
)
*
A
;
This gives us a smooth animated wave:
Loading canvas...
A single simplex noise function call already produces a very natural-looking wave!
The same three
,
,
variables determine the characteristics of our wave. We scale
by
to make the wave shorter or longer on the horizontal axis:
We scale
by
to control the evolution speed of our wave — the speed at which we move across the
axis in the visualization above:
Lastly, we scale the output of the
function by
, which determines the amplitude (height) of our wave.
Simplex noise returns a value between
and
, so to make a wave with a height of
you’d set
to
.
Even though the simplex wave feels natural, I find the peaks and valleys to look too evenly spaced and predictable.
That’s where stacking comes in. We can stack simplex waves of various lengths and speeds to get a more interesting final wave. I tweaked the constants and added a few increasingly large waves — some slower and some faster. Here’s what I ended up with:
const
float
L
=
0.0018
;
const
float
S
=
0.04
;
const
float
A
=
40.0
;
float
noise
=
0.0
;
noise
+=
simplex_noise
(
x
*
(
L
/
1.00
)
,
u_time
*
S
*
1.00
)
)
*
A
*
0.85
;
noise
+=
simplex_noise
(
x
*
(
L
/
1.30
)
,
u_time
*
S
*
1.26
)
)
*
A
*
1.15
;
noise
+=
simplex_noise
(
x
*
(
L
/
1.86
)
,
u_time
*
S
*
1.09
)
)
*
A
*
0.60
;
noise
+=
simplex_noise
(
x
*
(
L
/
3.25
)
,
u_time
*
S
*
0.89
)
)
*
A
*
0.40
;
This produces a wave that feels natural, yet visually interesting.
Loading canvas...
Looks awesome, but there is one component I feel is missing, which is directional flow. The wave is too “still”, which makes it feel a bit artificial.
To make the wave flow left, we can add
u_time
to the
x
component, scaled by a constant
that determines the amount of flow.
const
float
F
=
0.043
;
float
noise
=
0.0
;
noise
+=
simplex_noise
(
x
*
(
L
/
1.00
)
+
F
*
u_time
,
.
.
.
)
*
.
.
.
;
noise
+=
simplex_noise
(
x
*
(
L
/
1.30
)
+
F
*
u_time
,
.
.
.
)
*
.
.
.
;
noise
+=
simplex_noise
(
x
*
(
L
/
1.86
)
+
F
*
u_time
,
.
.
.
)
*
.
.
.
;
noise
+=
simplex_noise
(
x
*
(
L
/
3.25
)
+
F
*
u_time
,
.
.
.
)
*
.
.
.
;
This adds a subtle flow to the wave. Try changing the amount of flow to feel the difference it makes:
Loading canvas...
The amount of flow may feel subtle, but that’s intentional. If the flow is easily noticeable, there’s too much of it.
I think we’ve got a good-looking wave. Let’s move on to the next step.
Multiple waves
Let’s update our shader to include multiple waves. As a first step, I’ll create a reusable
wave_alpha
function that takes in a
position and height for the wave and returns an alpha value.
float
wave_alpha
(
float
Y
,
float
height
)
{
// ...
}
To keep things clean, I’ll create a
wave_noise
function that returns the stacked simplex wave we defined in the last section:
float
wave_noise
(
)
{
float
noise
=
0.0
;
noise
+=
simplex_noise
(
.
.
.
)
*
.
.
.
;
noise
+=
simplex_noise
(
.
.
.
)
*
.
.
.
;
// ...
return
noise
;
}
We’ll use that in
wave_alpha
to calculate the wave’s
position and the pixel’s distance to it:
float
wave_alpha
(
float
Y
,
float
wave_height
)
{
float
wave_y
=
Y
+
wave_noise
(
)
*
wave_height
;
float
dist
=
wave_y
-
gl_FragCoord
.
y
;
}
Using the distance to compute the
alpha
value:
float
wave_alpha
(
float
Y
,
float
wave_height
)
{
float
wave_y
=
Y
+
wave_noise
(
)
*
wave_height
;
float
dist
=
wave_y
-
gl_FragCoord
.
y
;
float
alpha
=
clamp
(
0.5
+
dist
,
0.0
,
1.0
)
;
return
alpha
;
}
We’ll then use the
wave_alpha
function to calculate alpha values for two waves, each with their separate
positions and heights:
const
float
WAVE1_HEIGHT
=
24.0
;
const
float
WAVE2_HEIGHT
=
32.0
;
const
float
WAVE1_Y
=
0.80
*
CANVAS_HEIGHT
;
const
float
WAVE2_Y
=
0.35
*
CANVAS_HEIGHT
;
float
wave1_alpha
=
wave_alpha
(
WAVE1_Y
,
WAVE1_HEIGHT
)
;
float
wave2_alpha
=
wave_alpha
(
WAVE2_Y
,
WAVE2_HEIGHT
)
;
Two waves split the canvas in three. I like to think of the upper third as the background, with two waves drawn in front of it (with wave 1 in the middle and wave 2 at the front).
To draw a background and two waves, we’ll need three colors. I picked these nice blue colors:
vec3
background_color
=
vec3
(
0.102
,
0.208
,
0.761
)
;
vec3
wave1_color
=
vec3
(
0.094
,
0.502
,
0.910
)
;
vec3
wave2_color
=
vec3
(
0.384
,
0.827
,
0.898
)
;
Finally, we’ll calculate the pixel’s color by blending these colors using the two waves’ alpha values:
vec3
color
=
background_color
;
color
=
mix
(
color
,
wave1_color
,
wave1_alpha
)
;
color
=
mix
(
color
,
wave2_color
,
wave2_alpha
)
;
gl_FragColor
=
vec4
(
color
,
1.0
)
;
This gives us the following result:
Loading canvas...
We do get two waves, but they’re completely in sync with each other.
This makes sense because the inputs to our noise function are the pixel’s
position and the current time, which are the same for both waves.
To fix this we’ll introduce wave-specific offset values that we pass to the noise functions. One way to do that is just to provide each wave with a literal
offset
value and pass that to the noise function:
float
wave_alpha
(
float
Y
,
float
wave_height
,
float
offset
)
{
wave_noise
(
offset
)
;
// ...
}
float
w1_alpha
=
wave_alpha
(
WAVE1_Y
,
WAVE1_HEIGHT
,
-
72.2
)
;
float
w2_alpha
=
wave_alpha
(
WAVE2_Y
,
WAVE2_HEIGHT
,
163.9
)
;
The
wave_noise
function can then add
offset
to
u_time
and use that when calculating the noise.
float
wave_noise
(
float
offset
)
{
float
time
=
u_time
+
offset
;
float
noise
=
0.0
;
noise
+=
simplex_noise
(
x
*
L
+
F
*
time
,
time
*
S
)
*
A
;
// ...
}
This produces identical waves, but offset in time. By making the offset large enough, we get waves spaced far enough apart in time that no one would notice that they’re the same wave.
But we don’t actually need to provide the offset manually. We can derive an offset in the
wave_alpha
function using the
Y
and
wave_height
arguments:
float
wave_alpha
(
float
Y
,
float
wave_height
)
{
float
offset
=
Y
*
wave_height
;
wave_noise
(
offset
)
;
// ...
}
Given the wave constants above and a canvas height of
, we get the following offsets:
With these offsets, the waves differ in time by
seconds. No one’s gonna notice that.
With the offsets added, we get two distinct waves:
Loading canvas...
Now that we’ve updated our shader to handle multiple waves, let’s move onto making the waves not be a single solid color.
Animated 2D noise
When generating the animated waves above, we used a 2D noise function to generate animated 1D noise.
That pattern holds for higher dimensions as well. When generating
-dimensional noise, we use an
-dimensional noise function with time as the value of the last dimension.
Here’s the static 2D simplex noise we saw earlier:
Loading canvas...
To animate it, we’ll use the 3D simplex noise function, passing the pixel’s
and
positions as the first two arguments and time as the third argument.
const
float
L
=
0.02
;
const
float
S
=
0.6
;
float
x
=
gl_FragCoord
.
x
;
float
y
=
gl_FragCoord
.
y
;
float
noise
=
simplex_noise
(
x
*
L
,
y
*
L
,
u_time
*
S
)
;
We’ll normalize the noise to
and use it as a lightness value:
float
lightness
=
(
noise
+
1.0
)
/
2.0
;
gl_FragColor
=
vec4
(
vec3
(
lightness
)
,
1.0
)
;
This gives us animated 2D noise:
Loading canvas...
Our goal for this animated 2D noise is for it to eventually be used to create the colors of the waves in our final gradient:
Loading canvas...
For the noise to start looking like that we’ll need to make some adjustments. Let’s scale up the noise and also make the scale of the noise larger on the
axis than the
axis.
const
float
L
=
0.0017
;
const
float
S
=
0.2
;
const
float
Y_SCALE
=
3.0
;
float
x
=
gl_FragCoord
.
x
;
float
y
=
gl_FragCoord
.
y
*
Y_SCALE
;
I made
around
times smaller and introduced
Y_SCALE
to make the noise shorter on
axis. I also reduced the speed
by about 80%.
With these adjustments, we get the following noise:
Loading canvas...
Looks pretty good, but the noise feels a bit too evenly spaced. Yet again, we’ll use stacking to make the noise more interesting. Here’s what I came up with:
const
float
L
=
0.0015
;
const
float
S
=
0.13
;
const
float
Y_SCALE
=
3.0
;
float
x
=
gl_FragCoord
.
x
;
float
y
=
gl_FragCoord
.
y
*
Y_SCALE
;
float
noise
=
0.5
;
noise
+=
simplex_noise
(
x
*
L
*
1.0
,
y
*
L
*
1.00
,
u_time
*
S
)
*
0.30
;
noise
+=
simplex_noise
(
x
*
L
*
0.6
,
y
*
L
*
0.85
,
u_time
*
S
)
*
0.26
;
noise
+=
simplex_noise
(
x
*
L
*
0.4
,
y
*
L
*
0.70
,
u_time
*
S
)
*
0.22
;
float
lightness
=
clamp
(
noise
,
0.0
,
1.0
)
;
The larger noise provides larger, sweeping fades, and the smaller noise gives us the finer details:
Loading canvas...
As a final cherry on top, I want to add a directional flow component. I’ll make two of the noises drift left, and the other drift right.
float
F
=
0.11
*
u_time
;
float
sum
=
0.5
;
sum
+=
simplex_noise
(
x
.
.
.
+
F
*
1.0
,
.
.
.
,
.
.
.
)
*
.
.
.
;
sum
+=
simplex_noise
(
x
.
.
.
+
-
F
*
0.6
,
.
.
.
,
.
.
.
)
*
.
.
.
;
sum
+=
simplex_noise
(
x
.
.
.
+
F
*
0.8
,
.
.
.
,
.
.
.
)
*
.
.
.
;
float
lightness
=
clamp
(
sum
,
0.0
,
1.0
)
;
Here’s what that looks like:
Loading canvas...
This makes the noise feel like it flows to the left — but not uniformly so.
I think this is looking quite good! Let’s clean things up putting this into a
background_noise
function:
float
background_noise
(
)
{
float
noise
=
0.5
;
noise
+=
simplex_noise
(
.
.
.
)
;
noise
+=
simplex_noise
(
.
.
.
)
;
// ...
return
clamp
(
noise
,
0.0
,
1.0
)
;
}
float
lightness
=
background_noise
(
)
gl_FragColor
=
vec4
(
vec3
(
lightness
)
,
1.0
)
;
Now let’s move beyond black and white and add some color to the mix!
Color mapping
Loading canvas...
This red-to-blue gradient works by calculating a
value based on the pixel’s
coordinate and mapping it to a color — some blend of red and blue — using the
value:
vec3
red
=
vec3
(
1.0
,
0.0
,
0.0
)
;
vec3
blue
=
vec3
(
0.0
,
0.0
,
1.0
)
;
float
t
=
gl_FragCoord
.
x
/
(
CANVAS_WIDTH
-
1.0
)
;
vec3
color
=
mix
(
red
,
blue
,
t
)
;
What we can do is use our new
background_noise
function to calculate the
value.
float
t
=
background_noise
(
)
;
vec3
color
=
mix
(
red
,
blue
,
t
)
;
That has the effect of mapping the noise to a red-to-blue gradient:
Loading canvas...
That’s pretty cool, but I’d like to be able to map the
value to
any
gradient, such as this one:
This gradient is a
<
div
>
element with its background set to this CSS gradient:
background
:
linear-gradient
(
90
deg
,
rgb
(
8
,
0
,
143
)
0
%
,
rgb
(
250
,
0
,
32
)
50
%
,
rgb
(
255
,
204
,
43
)
100
%
)
;
We can replicate this in a shader. First, we’ll convert the three colors of the gradient to
vec3
colors:
vec3
color1
=
vec3
(
0.031
,
0.0
,
0.561
)
;
vec3
color2
=
vec3
(
0.980
,
0.0
,
0.125
)
;
vec3
color3
=
vec3
(
1.0
,
0.8
,
0.169
)
;
We then mix the colors using
and some clever math:
float
t
=
gl_FragCoord
.
x
/
(
CANVAS_WIDTH
-
1.0
)
;
vec3
color
=
color1
;
color
=
mix
(
color
,
color2
,
min
(
1.0
,
t
*
2.0
)
)
;
color
=
mix
(
color
,
color3
,
max
(
0.0
,
(
t
-
0.5
)
*
2.0
)
)
;
gl_FragColor
=
vec4
(
color
,
1.0
)
;
This replicates the CSS gradient perfectly:
Loading canvas...
I’ll move the color calculations into a
calc_color
function to clean things up:
vec3
calc_color
(
float
t
)
{
vec3
color
=
color1
;
color
=
mix
(
color
,
color2
,
min
(
1.0
,
t
*
2.0
)
)
;
color
=
mix
(
color
,
color3
,
max
(
0.0
,
(
t
-
0.5
)
*
2.0
)
)
;
return
color
;
}
Now that we have a
calc_color
function that maps
values to the gradient, we can easily map
background_noise
to it:
float
t
=
background_noise
(
)
;
gl_FragColor
=
vec4
(
calc_color
(
t
)
,
1.0
)
;
Here’s the result:
Loading canvas...
Our
calc_color
function is set up to handle 3-stop gradients, but we can update it to handle gradients with
stops. Here is an example of a 5-stop gradient:
vec3
calc_color
(
float
t
)
{
vec3
color1
=
vec3
(
1.0
,
0.0
,
0.0
)
;
vec3
color2
=
vec3
(
1.0
,
1.0
,
0.0
)
;
vec3
color3
=
vec3
(
0.0
,
1.0
,
0.0
)
;
vec3
color4
=
vec3
(
0.0
,
0.0
,
1.0
)
;
vec3
color5
=
vec3
(
1.0
,
0.0
,
1.0
)
;
float
num_stops
=
5.0
;
float
N
=
num_stops
-
1.0
;
vec3
color
=
mix
(
color1
,
color2
,
min
(
t
*
N
,
1.0
)
)
;
color
=
mix
(
color
,
color3
,
clamp
(
(
t
-
1.0
/
N
)
*
N
,
0.0
,
1.0
)
)
;
color
=
mix
(
color
,
color4
,
clamp
(
(
t
-
2.0
/
N
)
*
N
,
0.0
,
1.0
)
)
;
color
=
mix
(
color
,
color5
,
clamp
(
(
t
-
3.0
/
N
)
*
N
,
0.0
,
1.0
)
)
;
return
color
;
}
The above function produces the following:
Loading canvas...
This works, but defining the gradient in code like this is (obviously) not great. The colors of the gradient are hardcoded into our shader, and we need to manually adjust the function to handle the correct number of color stops.
We can make this more dynamic by reading the gradient from a texture.
Gradient texture
To pass image data — such as a linear gradient — from JavaScript to our shader, we can use
textures
. Textures are arrays of data that can, amongst other things, store a 2D image.
Firstly, we’ll generate an image containing a linear gradient in JavaScript. We’ll write that image to a texture and pass that texture to our WebGL shader. The shader can then read data from the texture.
Rendering a gradient to a canvas
I used
this gradient generator
to pick the following gradient:
It consists of these colors:
const
colors
=
[
""hsl(204deg 100% 22%)""
,
""hsl(199deg 100% 29%)""
,
""hsl(189deg 100% 32%)""
,
""hsl(173deg 100% 33%)""
,
""hsl(154deg 100% 39%)""
,
""hsl( 89deg  70% 56%)""
,
""hsl( 55deg 100% 50%)""
,
]
;
To render the gradient to a canvas, we’ll first have to create one. We can do that like so:
const
canvas
=
document
.
createElement
(
""canvas""
)
;
canvas
.
height
=
256
;
canvas
.
width
=
64
;
const
ctx
=
canvas
.
getContext
(
""2d""
)
;
The gradient is written to a
CanvasGradient
like so:
const
linearGradient
=
ctx
.
createLinearGradient
(
0
,
0
,
// Top-left corner
canvas
.
width
,
0
// Top-right corner
)
;
for
(
const
[
i
,
color
]
of
colors
.
entries
(
)
)
{
const
stop
=
i
/
(
colors
.
length
-
1
)
;
linearGradient
.
addColorStop
(
stop
,
color
)
;
}
Setting the gradient as the active fill style and drawing a rectangle over the dimensions renders the gradient.
ctx
.
fillStyle
=
linearGradient
;
ctx
.
fillRect
(
0
,
0
,
canvas
.
width
,
canvas
.
height
)
;
Loading canvas...
Now that we’ve rendered a linear gradient onto a canvas element, let’s write it into a texture and pass it to our shader.
Reading canvas contents from a shader
The following code creates a WebGL texture and writes the canvas contents to it:
const
texture
=
gl
.
createTexture
(
)
;
gl
.
bindTexture
(
gl
.
TEXTURE_2D
,
texture
)
;
gl
.
texImage2D
(
gl
.
TEXTURE_2D
,
0
,
gl
.
RGBA
,
gl
.
RGBA
,
gl
.
UNSIGNED_BYTE
,
canvas
)
;
gl
.
bindTexture
(
gl
.
TEXTURE_2D
,
null
)
;
I won’t cover how this works — I want to stay focused on shaders, not the WebGL API. I’ll refer you to
this post on rendering to a texture
if you want to explore this in more detail.
GLSL shaders read data from textures using
samplers
. A sampler is a function that takes texture coordinates and returns
a
value for the texture at that position. Emphasis on “
a
” value because when texture coordinates fall
between
data points, the sampler returns an interpolated result derived from surrounding values.
There are different sampler types for different value types:
isampler
for signed integers,
usampler
for unsigned integers, and
sampler
for floats. Our image texture contains floats so we’ll use the unprefixed
sampler
.
Samplers also have dimensionality. You can have 1D, 2D or 3D samplers. Since we’ll be reading from a 2D image texture, we’ll use a
sampler2D
. If you were reading unsigned integers from a 3D texture, you’d use a
usampler3D
.
In our shader, we’ll declare our sampler via a uniform. I’ll name it
u_gradient
:
uniform
sampler2D
u_gradient
;
On the JavaScript side, we’ll make
u_gradient
point to our
texture
like so:
const
gradientUniformLocation
=
gl
.
getUniformLocation
(
program
,
""u_gradient""
)
;
gl
.
activeTexture
(
gl
.
TEXTURE0
)
;
gl
.
bindTexture
(
gl
.
TEXTURE_2D
,
texture
)
;
gl
.
uniform1i
(
gradientUniformLocation
,
0
)
;
Again, I won’t cover how this works — I want to stay focused on the shader side — but I’ll refer you to
this post
on WebGL textures.
To read data from a texture (via a sampler) we’ll use one of OpenGL’s built-in
texture lookup functions
. In our case, we’re reading 2D image data, so we’ll use
texture2D
.
texture2D
takes two arguments, a sampler and 2D texture coordinates. The coordinates are normalized so
is the top-left corner of the texture and
is the bottom-right corner of the texture.
Note:
texture2D
coordinates are typically normalized, but samplers may also use “texel space” coordinates which range from
where
is the size of the texture for that dimension.
Here’s our texture again, for reference:
Loading canvas...
The texture is uniform over the
axis so we can just set the
coordinate to
(we could also use
or
, the result would be the same).
Since the texture is uniform over the
axis, its height doesn’t matter. I’m using a height of
because it looks nice for this post, but you could use a height of
instead.
As for the
axis, reading the color at
should yield blue, and at
we should get yellow. We can verify this with the following shader
uniform
sampler2D
u_gradient
;
uniform
float
u_x
;
void
main
(
)
{
gl_FragColor
=
texture2D
(
u_gradient
,
vec2
(
u_x
,
0.5
)
)
;
}
In the canvas below, the
slider controls the value of
u_x
. As you slide
from
to
the color should change from blue to yellow:
Loading canvas...
It works! We can now map values between
and
to the gradient texture. This makes mapping
background_noise
to the gradient trivial:
uniform
sampler2D
u_gradient
;
float
t
=
background_noise
(
)
;
gl_FragColor
=
texture2D
(
u_gradient
,
vec2
(
t
,
0.5
)
)
;
As we can see, this has the effect of applying our gradient to the background noise:
Loading canvas...
Defining the gradient in JavaScript and generating it dynamically gives us a lot of flexibility. We can easily change the gradient, say, to this funky pastel gradient:
const
colors
=
[
""hsl(141 75% 72%)""
,
""hsl(41 90% 62%)""
,
""hsl(358 64% 50%)""
,
]
;
Loading canvas...
We’ll soon use this in the final effect, but before we get to that, let’s finish blending our waves.
Dynamic blur
In the final effect, we see varying amounts of blur applied to each wave, with the amount of blur evolving:
Loading canvas...
Our current waves, however, have sharp edges:
Loading canvas...
Let’s get started building a dynamic blur. As a refresher, we’re currently calculating the alpha of our waves like so:
float
x
=
gl_FragCoord
.
x
;
float
y
=
gl_FragCoord
.
y
;
float
wave_alpha
(
float
Y
,
float
wave_height
)
{
float
offset
=
Y
*
wave_height
;
float
wave_y
=
Y
+
wave_noise
(
offset
)
*
wave_height
;
float
dist
=
wave_y
-
y
;
float
alpha
=
clamp
(
0.5
+
dist
,
0.0
,
1.0
)
;
return
alpha
;
}
Let’s define a
calc_blur
function that calculates the amount of blur to apply. We’ll start simple with an increasing left-to-right blur over the width of the canvas:
float
calc_blur
(
)
{
float
t
=
x
/
(
CANVAS_WIDTH
-
1.0
)
;
float
blur
=
mix
(
1.0
,
BLUR_AMOUNT
,
t
)
;
return
blur
;
}
We’ll use it to calculate a
blur
value and divide
dist
by it — like we did earlier in this post:
float
blur
=
calc_blur
(
)
;
float
alpha
=
clamp
(
0.5
+
dist
/
blur
,
0.0
,
1.0
)
;
This gives us a left-to-right blur:
Loading canvas...
To make the blur dynamic, we’ll yet again reach for the simplex noise function. The setup should feel familiar, it’s almost identical to the
wave_noise
function we defined earlier:
float
calc_blur
(
)
{
const
float
L
=
0.0018
;
const
float
S
=
0.1
;
const
float
F
=
0.034
;
float
noise
=
simplex_noise
(
x
*
L
+
F
*
u_time
,
u_time
*
S
)
;
float
t
=
(
noise
+
1.0
)
/
2.0
;
float
blur
=
mix
(
1.0
,
BLUR_AMOUNT
,
t
)
;
return
blur
;
}
If we were to apply this as-is to our waves, each wave’s blur would look identical. For the wave blurs to be distinct we’ll need to add an offset to
u_time
.
Conveniently for us, we can reuse the same offset we calculated for the
wave_noise
function:
float
calc_blur
(
float
offset
)
{
float
time
=
u_time
*
offset
;
float
noise
=
simplex_noise
(
x
*
L
+
F
*
time
,
time
*
S
)
;
// ...
}
float
wave_alpha
(
float
Y
,
float
wave_height
)
{
float
offset
=
Y
*
wave_height
;
float
wave_y
=
Y
+
wave_noise
(
offset
)
*
wave_height
;
float
blur
=
calc_blur
(
offset
)
;
// ...
}
This gives us a dynamic blur:
Loading canvas...
But, honestly, the blur looks pretty bad. It feels like it has distinct “edges” at the top and bottom of each wave.
Also, the waves feel somewhat blurry all over, just unevenly so. We don’t seem to get those long, sharp edges that appear in the final effect:
Loading canvas...
Let’s start by fixing the harsh edges.
Making our blur look better
Consider how we’re calculating the alpha:
float
alpha
=
clamp
(
0.5
+
dist
/
blur
,
0.0
,
1.0
)
;
The alpha equals
when the distance is
. It then linearly increases or decreases until it hits either
or
, at which point the
clamp
function kicks in.
Let’s chart the alpha curve so that we can see this visually:
The harsh stops at
and
produce the sharp-feeling edges that we observe at the edges of the blur.
Loading canvas...
The
smoothstep
function can help here. Smoothstep is a family of interpolation functions that, as the name suggests, smooth the transition from
to
.
I’m defining
smoothstep
like so:
float
smoothstep
(
float
t
)
{
return
t
*
t
*
t
*
(
t
*
(
6.0
*
t
-
15.0
)
+
10.0
)
;
}
This is the
“quintic” variant
of the smoothstep function. It applies a bit more smoothing than the “default” smoothstep implementation.
Applying
smoothstep
to our alpha curve is quite simple:
float
alpha
=
clamp
(
0.5
+
dist
/
blur
,
0.0
,
1.0
)
;
alpha
=
smoothstep
(
alpha
)
;
Below is a chart showing the smoothed alpha curve — I’ll include the original non-smoothed curve for comparison:
This results in a
much
smoother blur:
Loading canvas...
Following is a side-by-side comparison. The blur to the left is smoothed, while the right one is not.
Loading canvas...
That takes care of the sharp edges. Let’s now tackle the issue of the wave as a whole being too blurry.
Making the wave less uniformly blurry
Here’s our
calc_blur
method as we left it:
float
calc_blur
(
)
{
// ...
float
noise
=
simplex_noise
(
x
*
L
+
F
*
u_time
,
u_time
*
S
)
;
float
t
=
(
noise
+
1.0
)
/
2.0
;
float
blur
=
mix
(
1.0
,
BLUR_AMOUNT
,
t
)
;
return
blur
;
}
The edge becomes sharper as
approaches
, and blurrier as
approaches
. However, the wave only becomes sharp when
is
very
close to zero.
The canvas below has a visualization that illustrates this. The lower half is a chart showing the value of
over the
axis (with
at the bottom to
at the top):
Loading canvas...
You’ll notice that the wave becomes sharp when the chart gets close to touching the bottom — at values near zero — but it rarely dips that low. The value of
lingers around the middle too much, causing the wave to be
somewhat
blurry over its entire length.
We can bias low values of
to get close to
by raising
to a power — i.e. applying an exponent.
Consider how an exponent affects values between
and
. Numbers close to
experience a strong pull towards
while larger numbers experience less pull. For example,
, a 90% reduction, while
, only a reduction of 10%.
The level of pull depends on the exponent. Here’s a chart of
for values of
between
and
:
This effect becomes more pronounced as we increase the exponent:
got
smaller while
got roughly
smaller!
The following chart shows
over the range
for different values of
:
Notice how an exponent of
has no effect.
As you can see, a higher exponent translates to a stronger pull towards zero.
With that, let’s apply an exponent to
. We can do that with the built-in
pow
function:
float
t
=
(
noise
+
1.0
)
/
2.0
;
t
=
pow
(
t
,
exponent
)
;
Below is a canvas that lets you vary the value of
exponent
from
to
. I intentionally set
exponent
to a default value of
(no effect) so that you can see the effect of increasing the exponent directly (the light-blue line that stays behind represents the value of
prior to applying the exponent).
Loading canvas...
As the exponent increases,
tends to “hug” the bottom of the chart more and more. This produces noticeable periods of relative sharpness while not muting higher values of
too
much. I feel like an exponent of
to
gives good results — I’ll go with
.
Let’s bring back the other wave and see what we’ve got:
Loading canvas...
Applying an exponent does dampen the strength of the blur, so let’s ramp the blur amount up — I’ll increase it from
to
.
Loading canvas...
Now we’re talking! We’ve got a pretty great-looking blur going!
Putting it all together
We’ve got all of the individual pieces we need to construct our final effect — let’s finally put it together!
Each wave is represented by an alpha value:
float
w1_alpha
=
wave_alpha
(
WAVE1_Y
,
WAVE1_HEIGHT
)
;
float
w2_alpha
=
wave_alpha
(
WAVE2_Y
,
WAVE2_HEIGHT
)
;
We’re currently using those alpha values to blend three colors — these three shades of blue from the previous section:
vec3
bg_color
=
vec3
(
0.102
,
0.208
,
0.761
)
;
vec3
wave1_color
=
vec3
(
0.094
,
0.502
,
0.910
)
;
vec3
wave2_color
=
vec3
(
0.384
,
0.827
,
0.898
)
;
The trick to our final effect lies in substituting each of those colors with a unique background noise and blending those.
We need our three background noises to be distinct. To support that we’ll update our
background_noise
function to take an offset value and add that to
u_time
. We’ve done this twice before so at this point this is just routine:
float
background_noise
(
float
offset
)
{
float
time
=
u_time
+
offset
;
float
noise
=
0.5
;
noise
+=
simplex_noise
(
.
.
.
,
time
*
S
)
*
.
.
.
;
noise
+=
simplex_noise
(
.
.
.
,
time
*
S
)
*
.
.
.
;
// ...
return
clamp
(
noise
,
0.0
,
1.0
)
;
}
We can now easily generate multiple distinct background noises. Let’s start by interpreting the background noises as lightness values:
float
bg_lightness
=
background_noise
(
0.0
)
;
float
w1_lightness
=
background_noise
(
200.0
)
;
float
w2_lightness
=
background_noise
(
400.0
)
;
We can blend these lightness values using the wave alpha values to calculate a final
lightness
value and pass
vec3
(
lightness
)
to
gl_FragColor
:
float
lightness
=
bg_lightness
;
lightness
=
mix
(
lightness
,
w1_lightness
,
w1_alpha
)
;
lightness
=
mix
(
lightness
,
w2_lightness
,
w2_alpha
)
;
gl_FragColor
=
vec4
(
vec3
(
lightness
)
,
1.0
)
;
This gives us the following effect:
Loading canvas...
Just try to tell me that this effect doesn’t look
absolutely sick!
It’s smooth, flowing, and quite dramatic at times.
The obvious next step is to map the final
lightness
value to a gradient. Let’s use this one:
Loading canvas...
Like before, we’ll get the texture into our shader via a
uniform
sampler2D
:
uniform
sampler2D
u_gradient
;
We then map the lightness value to the gradient like so:
gl_FragColor
=
texture2D
(
u_gradient
,
vec2
(
lightness
,
0.5
)
)
;
This applies the gradient to our effect:
Loading canvas...
Looks gorgeous. We can make this more sleek by increasing the height of the canvas a bit and adding a skew:
Loading canvas...
Sick, right? This could be used to add a modern and elegant touch to any landing page. Implementing the skew effect is deceptively simple — it’s just a transform of
skewY
(
-6
deg
)
.
Since we’re generating the gradient in JavaScript, we can easily swap out the gradient. Here’s a canvas with a few cool gradients I picked:
Loading canvas...
It took a long time to get here, but we’ve ended up with something really cool.
Final words
I hope this was a good introduction to writing shaders, and I hope I provided you with the tools and intuition to get started writing shaders yourself!
At the beginning of the post I promised to link to the final shader code, so
here it is
.
The final shader includes a few additional elements that were not covered in the post. For example, the blur is calculated in multiple parts using an exponent range, adding a “haziness” element to the effect. I also added an oscillating “blur bias” to introduce periods of global blurriness and sharpness.
Take a look at this black-and-white version of the final effect and see if you can spot those elements (it’s much easier to see without color):
Loading canvas...
I didn’t cover these additional elements because they’re not core to the effect — they just add a layer of refinement. There are loads of ways in which you could tweak or add to the effect. I tried tons of ideas and kept those around because they worked very well. I suggest tweaking the code and trying to add some refinements yourself!
Huge thanks to my friends,
Gunnlaugur Þór Briem
and
Eiríkur Fannar Torfason
, for reading a draft version of this post — they provided great feedback.
Thanks so much for reading. Take what you learned and go write some awesome shaders!
— Alex Harri
Mailing list
To be notified of new posts, subscribe to my mailing list.
Subscribe","Apr 12, 2025"
"The web’s clipboard, and how it stores data of different types","If you’ve been using computers for a while, you probably know that the clipboard can store multiple types of data (images, rich text content, files, and so on). As a software developer, it started frustrating me that I didn’t have a good understanding of how the clipboard stores and organizes data of different types.
I recently decided to unveil the mystery that is the clipboard and wrote this post using my learnings. We’ll focus on the web clipboard and its APIs, though we’ll also touch on how it interacts with operating system clipboards.
We’ll start by exploring the web’s clipboard APIs and their history. The clipboard APIs have some interesting limitations around data types, and we’ll see how some companies have worked around those limitations. We’ll also look at some proposals that aim to resolve those limitations (most notably,
Web Custom Formats
).
If you’ve ever wondered how the web’s clipboard works, this post is for you.
Using the async Clipboard API
If I copy some content from a website and paste it into Google Docs, some of its formatting is retained, such as links, font size, and color.
But if I open VS Code and paste it there, only the raw text content is pasted.
The clipboard serves these two use cases by allowing information to be stored in multiple
representations
associated with MIME types. The W3C Clipboard spec
mandates
that for writing to and reading from the clipboard, these three data types must be supported:
text/plain
for plain text.
text/html
for HTML.
image/png
for PNG images.
So when I pasted before, Google Docs read the
text/html
representation and used that to retain the rich text formatting. VS Code only cares about the raw text and reads the
text/plain
representation. Makes sense.
Reading a specific representation via the async Clipboard API’s
read
method is quite straightforward:
const
items
=
await
navigator
.
clipboard
.
read
(
)
;
for
(
const
item
of
items
)
{
if
(
item
.
types
.
includes
(
""text/html""
)
)
{
const
blob
=
await
item
.
getType
(
""text/html""
)
;
const
html
=
await
blob
.
text
(
)
;
// Do stuff with HTML...
}
}
Writing multiple representations to the clipboard via
write
is a bit more involved, but still relatively straightforward. First, we construct
Blob
s for each representation that we want to write to the clipboard:
const
textBlob
=
new
Blob
(
[
""Hello, world""
]
,
{
type
:
""text/plain""
}
)
;
const
htmlBlob
=
new
Blob
(
[
""Hello, <em>world<em>""
]
,
{
type
:
""text/html""
}
)
;
Once we have the blobs, we pass them to a new
ClipboardItem
in a key-value store with the data types as the keys and the blobs as the values:
const
clipboardItem
=
new
ClipboardItem
(
{
[
textBlob
.
type
]
:
textBlob
,
[
htmlBlob
.
type
]
:
htmlBlob
,
}
)
;
Note:
I like that
ClipboardItem
accepts a key-value store. It nicely aligns with the idea of using a data structure that makes illegal states unrepresentable, as discussed in
Parse, don’t validate
.
Finally, we invoke
write
with our newly constructed
ClipboardItem
:
await
navigator
.
clipboard
.
write
(
[
clipboardItem
]
)
;
What about other data types?
HTML and images are cool, but what about general data interchange formats like JSON? If I were writing an application with copy-paste support, I could imagine wanting to write JSON or some binary data to the clipboard.
Let’s try to write JSON data to the clipboard:
// Create JSON blob
const
json
=
JSON
.
stringify
(
{
message
:
""Hello""
}
)
;
const
blob
=
new
Blob
(
[
json
]
,
{
type
:
""application/json""
}
)
;
// Write JSON blob to clipboard
const
clipboardItem
=
new
ClipboardItem
(
{
[
blob
.
type
]
:
blob
}
)
;
await
navigator
.
clipboard
.
write
(
[
clipboardItem
]
)
;
Upon running this, an exception is thrown:
Failed to execute 'write' on 'Clipboard':
Type application/json not supported on write.
Hmm, what’s up with that? Well, the
spec
for
write
tells us that data types other than
text/plain
,
text/html
, and
image/png
must be rejected:
If
type
is not in the
mandatory data types
list, then reject [...] and abort these steps.
Interestingly, the
application/json
MIME type was in the mandatory data types list from
2012
to
2021
but was removed from the spec in
w3c/clipboard-apis#155
. Prior to that change, the lists of mandatory data types were much longer, with 16 mandatory data types for reading from the clipboard, and 8 for writing to it. After the change, only
text/plain
,
text/html
, and
image/png
remained.
This change was made after browsers opted not to support many of the mandatory types due to
security concerns
. This is reflected by a warning in the
mandatory data types
section in the spec:
Warning! The data types that untrusted scripts are allowed to write to the clipboard are limited as a security precaution.
Untrusted scripts can attempt to exploit security vulnerabilities in local software by placing data known to trigger those vulnerabilities on the clipboard.
Okay, so we can only write a limited set of data types to the clipboard. But what’s that about “
untrusted
scripts”? Can we somehow run code in a “trusted” script that lets us write other data types to the clipboard?
The isTrusted property
Perhaps the “trusted” part refers to the
isTrusted
property on events
.
isTrusted
is a read-only property that is only set to true if the event was dispatched by the user agent.
document
.
addEventListener
(
""copy""
,
(
e
)
=>
{
if
(
e
.
isTrusted
)
{
// This event was triggered by the user agent
}
}
)
Being “dispatched by the user agent” means that it was triggered by the user, such as a copy event triggered by the user pressing
Command
C
. This is in contrast to a synthetic event programmatically dispatched via
dispatchEvent()
:
document
.
addEventListener
(
""copy""
,
(
e
)
=>
{
console
.
log
(
""e.isTrusted is ""
+
e
.
isTrusted
)
;
}
)
;
document
.
dispatchEvent
(
new
ClipboardEvent
(
""copy""
)
)
;
//
=>
""e.isTrusted is false""
Let’s look at the clipboard events and see whether they allow us to write arbitrary data types to the clipboard.
The Clipboard Events API
A
ClipboardEvent
is dispatched for copy, cut, and paste events, and it contains a
clipboardData
property of type
DataTransfer
. The
DataTransfer
object is used by the Clipboard Events API to hold multiple representations of data.
Writing to the clipboard in a
copy
event is very straightforward:
document
.
addEventListener
(
""copy""
,
(
e
)
=>
{
e
.
preventDefault
(
)
;
// Prevent default copy behavior
e
.
clipboardData
.
setData
(
""text/plain""
,
""Hello, world""
)
;
e
.
clipboardData
.
setData
(
""text/html""
,
""Hello, <em>world</em>""
)
;
}
)
;
And reading from the clipboard in a
paste
event is just as simple:
document
.
addEventListener
(
""paste""
,
(
e
)
=>
{
e
.
preventDefault
(
)
;
// Prevent default paste behavior
const
html
=
e
.
clipboardData
.
getData
(
""text/html""
)
;
if
(
html
)
{
// Do stuff with HTML...
}
}
)
;
Now for the big question: can we write JSON to the clipboard?
document
.
addEventListener
(
""copy""
,
(
e
)
=>
{
e
.
preventDefault
(
)
;
const
json
=
JSON
.
stringify
(
{
message
:
""Hello""
}
)
;
e
.
clipboardData
.
setData
(
""application/json""
,
json
)
;
// No error
}
)
;
No exception is thrown, but did this actually write the JSON to the clipboard? Let’s verify that by writing a paste handler that iterates over all of the entries in the clipboard and logs them out:
document
.
addEventListener
(
""paste""
,
(
e
)
=>
{
for
(
const
item
of
e
.
clipboardData
.
items
)
{
const
{
kind
,
type
}
=
item
;
if
(
kind
===
""string""
)
{
item
.
getAsString
(
(
content
)
=>
{
console
.
log
(
{
type
,
content
}
)
;
}
)
;
}
}
}
)
;
Adding both of these handlers and invoking copy-paste results in the following being logged:
{
""type""
:
""application/json""
,
content
:
""{\""message\"":\""Hello\""}""
}
It works! It seems that
clipboardData.setData
does not restrict data types in the same manner as the async
write
method does.
But... why? Why can we read and write arbitrary data types using
clipboardData
but not when using the async Clipboard API?
History of
clipboardData
The relatively new async Clipboard API was added to the spec in
2017
, but
clipboardData
is
much
older than that. A W3C draft for the Clipboard API from
2006
defines
clipboardData
and its
setData
and
getData
methods (which shows us that MIME types were not being used at that point):
setData()
This takes one or two parameters. The first must be set to either ‘text’ or ‘URL’ (case-insensitive).
getData()
This takes one parameter, that allows the target to request a specific type of data.
But it turns out that
clipboardData
is even older than the 2006 draft. Look at this quote from the “Status of this Document” section:
In large part [this document] describes the functionalities as implemented in Internet Explorer...
The intention of this document is [...] to specify what actually works in current browsers, or [be] a simple target for them to improve interoperability, rather than adding new features.
This
2003 article
details how, at the time, in Internet Explorer 4 and above, you could use
clipboardData
to read the user’s clipboard without their consent. Since Internet Explorer 4 was released in 1997 it seems that the
clipboardData
interface is at least 26 years old at the time of writing.
MIME types entered the
spec in 2011
:
The
dataType
argument is a string, for example but not limited to a MIME type...
If a script calls getData(‘text/html’)...
At the time, the spec had not determined which data types should be used:
While it is possible to use any string for setData()‘s type argument, sticking to common types is recommended.
[Issue] Should we list some “common types”?
Being able to use
any
string for
setData
and
getData
still holds today. This works perfectly fine:
document
.
addEventListener
(
""copy""
,
(
e
)
=>
{
e
.
preventDefault
(
)
;
e
.
clipboardData
.
setData
(
""foo bar baz""
,
""Hello, world""
)
;
}
)
;
document
.
addEventListener
(
""paste""
,
(
e
)
=>
{
const
content
=
e
.
clipboardData
.
getData
(
""foo bar baz""
)
;
if
(
content
)
{
console
.
log
(
content
)
;
// Logs ""Hello, world!""
}
}
)
;
If you paste this code snippet into your DevTools and then hit copy and paste, you will see the message “Hello, world” logged to your console.
The reason for the Clipboard Events API’s
clipboardData
allowing us to use any data type seems to be a historical one.
“Don’t break the web”
.
Revisiting isTrusted
Let’s consider this sentence from the
mandatory data types
section again:
The data types that untrusted scripts are allowed to write to the clipboard are limited as a security precaution.
So what happens if we attempt to write to the clipboard in a synthetic (untrusted) clipboard event?
document
.
addEventListener
(
""copy""
,
(
e
)
=>
{
e
.
preventDefault
(
)
;
e
.
clipboardData
.
setData
(
""text/plain""
,
""Hello""
)
;
}
)
;
document
.
dispatchEvent
(
new
ClipboardEvent
(
""copy""
,
{
clipboardData
:
new
DataTransfer
(
)
,
}
)
)
;
This runs successfully, but it doesn’t modify the clipboard. This is the expected behavior
as explained in the spec
:
Synthetic cut and copy events
must not
modify data on the system clipboard.
Synthetic paste events
must not
give a script access to data on the real system clipboard.
So only copy and paste events dispatched by the user agent are allowed to modify the clipboard. Makes total sense—I wouldn’t want websites to freely read my clipboard contents and steal my passwords.
To summarize our findings so far:
The async Clipboard API introduced in 2017 restricts which data types can be written to and read from the clipboard. However, it can read from and write to the clipboard at any time, given that the user has granted permission to do so (and the
document is focused
).
The older Clipboard Events API has no real restrictions on which data types can be written to and read from the clipboard. However, it can only be used in copy and paste event handlers triggered by the user agent (i.e. when
isTrusted
is true).
It seems that using the Clipboard Events API is the only way forward if you want to write data types to the clipboard that are not just plain text, HTML, or images. It’s much less restrictive in that regard.
But what if you want to build a Copy button that writes non-standard data types to the clipboard? It doesn’t seem like you’d be able to use the Clipboard Events API if the user did not trigger a copy event. Right?
Building a copy button that writes arbitrary data types
I went and tried out Copy buttons in different web applications and inspected what was written to the clipboard. It yielded interesting results.
Google Docs has a Copy button which can be found in their right-click menu.
This copy button writes three representations to the clipboard:
text/plain
,
text/html
, and
application/x-vnd.google-docs-document-slice-clip+wrapped
Note:
The third representation contains JSON data.
They’re writing a custom data type to the clipboard, which means that they aren’t using the async Clipboard API. How are they doing that through a click handler?
I ran the profiler, hit the copy button, and inspected the results. It turns out that clicking the copy button triggers a call to
document.execCommand(""copy"")
.
This was surprising to me. My first thought was
“Isn’t
execCommand
the old, deprecated way of copying text to the clipboard?”
.
Yes, it is, but Google uses it for a reason.
execCommand
is special in that it allows you to programmatically dispatch a trusted copy event
as if
the user invoked the copy command themselves.
document
.
addEventListener
(
""copy""
,
(
e
)
=>
{
console
.
log
(
""e.isTrusted is ""
+
e
.
isTrusted
)
;
}
)
;
document
.
execCommand
(
""copy""
)
;
//
=>
""e.isTrusted is true""
Note:
Safari requires an active selection for
execCommand(""copy"")
to dispatch a copy event. That selection can be faked by adding a non-empty input element to the DOM and selecting it prior to invoking
execCommand(""copy"")
, after which the input can be removed from the DOM.
Okay, so using
execCommand
allows us to write arbitrary data types to the clipboard in response to click events. Cool!
What about paste? Can we use
execCommand(""paste"")
?
Building a paste button
Let’s try the Paste button in Google Docs and see what it does.
On my Macbook, I got a popup telling me that I need to install an extension to use the paste button.
But oddly, on my Windows laptop, the paste button just worked.
Weird. Where does the inconsistency come from? Well, whether or not the paste button will work can be checked by running
queryCommandSupported(""paste"")
:
document
.
queryCommandSupported
(
""paste""
)
;
On my Macbook, I got
false
on Chrome and Firefox, but
true
on Safari.
Safari, being privacy-conscious, required me to confirm the paste action. I think that’s a really good idea. It makes it very explicit that the website will read from your clipboard.
On my Windows laptop, I got
true
on Chrome and Edge, but
false
on Firefox. The inconsistency with Chrome is surprising. Why does Chrome allow
execCommand(""paste"")
on Windows but not macOS? I wasn’t able to find any info on this.
I find it surprising that Google doesn’t attempt to fall back to the async Clipboard API when
execCommand(""paste"")
is unavailable. Even though they wouldn’t be able to read the
application/x-vnd.google-[...]
representation using it, the HTML representation contains internal IDs that could be used.
<!-- HTML representation, cleaned up -->
<
meta
charset
=
""
utf-8
""
>
<
b
id
=
""
docs-internal-guid-[guid]
""
style
=
""
...
""
>
<
span
style
=
""
...
""
>
Copied text
</
span
>
</
b
>
Another web application with a paste button is Figma, and they take a completely different approach. Let’s see what they’re doing.
Copy and Paste in Figma
Figma is a web-based application (their native app uses
Electron
). Let’s see what their copy button writes to the clipboard.
Figma’s copy button writes two representations to the clipboard:
text/plain
and
text/html
. This was surprising to me at first. How would Figma represent their various layout and styling features in plain HTML?
But looking at the HTML, we see two empty
span
elements with
data-metadata
and
data-buffer
properties:
<
meta
charset
=
""
utf-8
""
>
<
div
>
<
span
data-metadata
=
""
<!--(figmeta)eyJma[...]9ifQo=(/figmeta)-->
""
>
</
span
>
<
span
data-buffer
=
""
<!--(figma)ZmlnL[...]P/Ag==(/figma)-->
""
>
</
span
>
</
div
>
<
span
style
=
""
white-space
:
pre-wrap
;
""
>
Text
</
span
>
Note:
The
data-buffer
string is ~26,000 characters for an empty frame. After that, the length of
data-buffer
seems to grow linearly with the amount of content that was copied.
Looks like base64. The
eyJ
start is a clear indication of
data-metadata
being a base64 encoded JSON string. Running
JSON.parse(atob())
on
data-metadata
yields:
{
""fileKey""
:
""4XvKUK38NtRPZASgUJiZ87""
,
""pasteID""
:
1261442360
,
""dataType""
:
""scene""
}
Note:
I’ve replaced the real
fileKey
and
pasteID
.
But what about the big
data-buffer
property? Base64 decoding it yields the following:
fig-kiwiF\x00\x00\x00\x1CK\x00\x00µ½\v\x9CdI[...]\x197Ü\x83\x03
Looks like a binary format. After a bit of digging—using
fig-kiwi
as a clue—I discovered that this is the
Kiwi message format
(created by Figma’s co-founder and former CTO,
Evan Wallace
), which is used to encode
.fig
files.
Since Kiwi is a schema-based format, it seemed like we wouldn’t be able to parse this data without knowing the schema. However, lucky for us, Evan created a
public
.fig
file parser
. Let’s try plugging the buffer into that!
To convert the buffer into a
.fig
file, I wrote a small script to generate a Blob URL:
const
base64
=
""ZmlnL[...]P/Ag==""
;
const
blob
=
base64toBlob
(
base64
,
""application/octet-stream""
)
;
console
.
log
(
URL
.
createObjectURL
(
blob
)
)
;
//
=>
blob:<origin>/1fdf7c0a-5b56-4cb5-b7c0-fb665122b2ab
I then downloaded the resulting blob as a
.fig
file, uploaded that to the
.fig
file parser, and voilà:
So copying in Figma works by creating a small Figma file, encoding that as a base64, placing the resulting base64 string into the
data-buffer
attribute of an empty HTML
span
element, and storing that in the user’s clipboard.
The benefits of copy-pasting HTML
This seemed a bit silly to me at first, but there is a strong benefit to taking that approach. To understand why, consider how the web-based Clipboard API interacts with the various operating system Clipboard APIs.
Windows, macOS, and Linux all offer different formats for writing data to the clipboard. If you want to write HTML to the clipboard,
Windows has
CF_HTML
and
macOS has
NSPasteboard.PasteboardType.html
.
All of the operating systems offer types for “standard” formats (plain text, HTML, and PNG images). But which OS format should the browser use when the user attempts to write an arbitrary data type like
application/foo-bar
to the clipboard?
There isn’t a good match, so the browser doesn’t write that representation to common formats on the OS clipboard. Instead, that representation only exists within a custom browser-specific clipboard format on the OS clipboard. This results in being able to copy and paste arbitrary data types across browser tabs, but
not
across applications.
This is why using the common data types
text/plain
,
text/html
and
image/png
is so convenient. They are mapped to common OS clipboard formats and as such can be easily read by other applications, which makes copy/paste work across applications. In Figma’s case, using
text/html
enables copying a Figma element from
figma.com
in the browser and then pasting it into the native Figma app, and vice versa.
What do browsers write to the clipboard for custom data types?
We’ve learned that we can write and read custom data types to and from the clipboard across browser tabs, but not across applications. But what exactly are browsers writing to the native OS clipboard when we write custom data types to the web clipboard?
I ran the following in a
copy
listener in each of the major browsers on my Macbook:
document
.
addEventListener
(
""copy""
,
(
e
)
=>
{
e
.
preventDefault
(
)
;
e
.
clipboardData
.
setData
(
""text/plain""
,
""Hello, world""
)
;
e
.
clipboardData
.
setData
(
""text/html""
,
""<em>Hello, world</em>""
)
;
e
.
clipboardData
.
setData
(
""application/json""
,
JSON
.
stringify
(
{
type
:
""Hello, world""
}
)
)
;
e
.
clipboardData
.
setData
(
""foo bar baz""
,
""Hello, world""
)
;
}
)
;
I then inspected the clipboard using
Pasteboard Viewer
. Chrome adds four entries to the Pasteboard:
public.html
contains the HTML representation.
public.utf8-plain-text
contains the plain text representation.
org.chromium.web-custom-data
contains the custom representations.
org.chromium.source-url
contains the URL of the web page where the copy was performed.
Looking at the
org.chromium.web-custom-data
, we see the data we copied:
I imagine the accented “î” and inconsistent line breaks are the result of some delimiters being displayed incorrectly.
Firefox creates the
public.html
and
public.utf8-plain-text
entries as well, but writes the custom data to
org.mozilla.custom-clipdata
. It does not store the source URL like Chrome does.
Safari, as you might expect, also creates the
public.html
and
public.utf8-plain-text
entries. It writes the custom data to
com.apple.WebKit.custom-pasteboard-data
and, interestingly, it also stores the full list of representations (including plain text and HTML) and source URL there.
Note:
Safari allows copy-pasting custom data types across browser tabs if the source URL (domain) is the same, but not across different domains. This limitation does not seem to be present in Chrome or Firefox (even though Chrome stores the source URL).
Raw Clipboard Access for the Web
A proposal for
Raw Clipboard Access
was created in 2019, which proposed an API for giving web applications raw read and write access to the native OS clipboards.
This excerpt from the
Motivation section on chromestatus.com
for the Raw Clipboard Access feature highlights the benefits rather succinctly:
Without Raw Clipboard Access [...] web applications are generally limited to a small subset of formats, and are unable to interoperate with the long tail of formats. For example, Figma and Photopea are unable to interoperate with most image formats.
However, the Raw Clipboard Access proposal ended up not being taken further due to
security concerns
around exploits such as remote code execution in native applications.
The most recent proposal for writing custom data types to the clipboard is the Web Custom Formats proposal (often referred to as pickling).
Web Custom Formats (Pickling)
In 2022, Chromium implemented support for
Web Custom Formats
in the async Clipboard API.
It allows web applications to write custom data types via the async Clipboard API by prefixing the data type with
""web ""
:
// Create JSON blob
const
json
=
JSON
.
stringify
(
{
message
:
""Hello, world""
}
)
;
const
jsonBlob
=
new
Blob
(
[
json
]
,
{
type
:
""application/json""
}
)
;
// Write JSON blob to clipboard as a Web Custom Format
const
clipboardItem
=
new
ClipboardItem
(
{
[
`
web
${
jsonBlob
.
type
}
`
]
:
jsonBlob
,
}
)
;
navigator
.
clipboard
.
write
(
[
clipboardItem
]
)
;
These are read using the async Clipboard API like any other data type:
const
items
=
await
navigator
.
clipboard
.
read
(
)
;
for
(
const
item
of
items
)
{
if
(
item
.
types
.
includes
(
""web application/json""
)
)
{
const
blob
=
await
item
.
getType
(
""web application/json""
)
;
const
json
=
await
blob
.
text
(
)
;
// Do stuff with JSON...
}
}
What’s more interesting is what is written to the native clipboard. When writing web custom formats, the following is written to the native OS clipboard:
A mapping from the data types to clipboard entry names
Clipboard entries for each data type
On macOS, the mapping is written to
org.w3.web-custom-format.map
and its content looks like so:
{
""application/json""
:
""org.w3.web-custom-format.type-0""
,
""application/octet-stream""
:
""org.w3.web-custom-format.type-1""
}
The
org.w3.web-custom-format.type-[index]
keys correspond to entries on the OS clipboard containing the unsanitized data from the blobs. This allows native applications to look at the mapping to see if a given representation is available and then read the unsanitized content from the corresponding clipboard entry.
Note:
Windows and Linux
use a different naming convention
for the mapping and clipboard entries.
This avoids the security issues around raw clipboard access since web applications cannot write unsanitized data to whatever OS clipboard format they want to. That comes with an interoperability trade-off that is explicitly listed in the
Pickling for Async Clipboard API spec
:
Non-goals
Allow interoperability with legacy native applications, without update. This was explored in a raw clipboard proposal, and may be explored further in the future, but comes with significant security challenges (remote code execution in system native applications).
This means that native applications need to be updated for clipboard interop with web applications when using custom data types.
Web Custom Formats have been available in Chromium-based browsers since 2022, but other browsers have not implemented this proposal yet.
Final words
As of right now, there isn’t a great way to write custom data types to the clipboard that works across all browsers. Figma’s approach of placing base64 strings into an HTML representation is crude but effective in that it circumvents the plethora of limitations around the clipboard API. It seems like a good approach to take if you need to transmit custom data types via the clipboard.
I find the Web Custom Formats proposal promising, and I hope it becomes implemented by all of the major browsers. It seems like it would enable writing custom data types to the clipboard in a secure and practical manner.
Thanks for reading! I hope this was interesting.
— Alex Harri
Appendix: the
unsanitized
option
When reading from the clipboard via the async Clipboard API, browsers may sanitize the data. For example, browsers may strip potentially dangerous script tags from HTML, and they may re-encode PNG images to avoid
zip bomb
attacks.
For this reason, the async Clipboard API’s
read
method contains an
unsanitized
option that allows you to request the unsanitized data. You can read more about this option and how it works in this post from
Thomas Steiner
.
Currently, the
unsanitized
option is only supported in Chromium-based browsers (added in late 2023). The other browsers may support this option in the future (though Safari seems unlikely to do so, see
Stakeholder Feedback/Opposition
).
Thanks, Tom, for reaching out in regards to mentioning the
unsanitized
option! It fits well within the scope of this post.
Mailing list
To be notified of new posts, subscribe to my mailing list.
Subscribe","Sept 1, 2024"
Compressing Icelandic name declension patterns into a 3.27 kB trie,"Displaying personal names in Icelandic user interfaces is surprisingly hard. This is because of
declension
— a language feature where the forms of nouns change to communicate a syntactic function.
In Icelandic, personal names have four forms, one for each of the
grammatical cases of Icelandic nouns
. Take the name
“Guðmundur”
:
Grammatical case
Form
Nominative
Guðmundur
Accusative
Guðmund
Dative
Guðmundi
Genitive
Guðmundar
When including a name in a sentence, the sentence’s structure determines the grammatical case, and correspondingly, a certain form of the name should be used. Using the wrong form results in a “broken” feel that native speakers associate with non-native speakers not yet fluent in the language.
The problem is that Icelandic personal names are always stored in the
nominative
case. If you’ve loaded a user from a database, their name will be in the nominative case. This creates a problem when you have a sentence structure that requires, for example, the
accusative
form of the name.
As a developer, you can work around that by rewriting the sentence to use the nominative case, which can be
very
awkward, or by using a pronoun (e.g.
they
). Both are unsatisfactory.
A few years ago, I built a JavaScript library to solve this issue. It applies any of the four grammatical cases to an Icelandic name, provided in the nominative case:
applyCase
(
""Guðmundur""
,
""accusative""
)
//
=>
""Guðmund""
When building this library, I did not code
any
declension rules by hand. Instead, the rules of Icelandic name declension are derived from public Icelandic data for personal names and their forms. The rules are encoded in a trie-like data structure that uses clever compression techniques to get the library’s bundle size under 4.5 kB gzipped. This lets the library be included in web apps without increasing bundle size significantly.
The rest of the post will walk through this problem in detail, and go over the compression techniques I used to get the trie to such a small size.
Data for Icelandic name declension
Iceland has a publicly run institution,
Árnastofnun
, that manages the
Database of Icelandic Morphology
(DIM). The database was created, amongst other reasons, to support Icelandic language technology.
DIM publishes various
datasets
, but we’ll use
Kristín’s Format
(the K-format), downloadable as a CSV. Here’s what the K-format data entries for “Guðmundur” look like:
Guðmundur
;355264;kk;ism;1;;;;K;
Guðmundur
;
NFET
;1;;;
Guðmundur
;355264;kk;ism;1;;;;K;
Guðmund
;
ÞFET
;1;;;
Guðmundur
;355264;kk;ism;1;;;;K;
Guðmundi
;
ÞGFET
;1;;;
Guðmundur
;355264;kk;ism;1;;;;K;
Guðmundar
;
EFET
;1;;;
^^^^^^^^^
^^^^^^^^^
^^^^
Name
Form
Case
From this, we can see that the name “Guðmundur” in the accusative (ÞFET) case is “Guðmund”, and so on.
From the K-format data, we can construct an array for each name containing its form for each grammatical case:
[
""Guðmundur""
,
// Nominative
""Guðmund""
,
// Accusative
""Guðmundi""
,
// Dative
""Guðmundar""
,
// Genitive
]
However, the K-format has data for most words in the Icelandic language, not just personal names. With over
7 million
entries, this data set is huge. We’ll need some way to whittle the list down.
Luckily for us, Iceland has the
Personal Names Register
. It lists all Icelandic personal names approved — and rejected — by the
Personal Names Committee
(yes, that exists).
We can use the set of approved Icelandic names to filter the K-format data. Of the roughly 4,500 approved Icelandic names, the K-format has declension data for over 3,600. With that, we have declension data for more than 80% of Icelandic names:
const
NAME_FORMS
=
[
[
""Aðalberg""
,
""Aðalberg""
,
""Aðalberg""
,
""Aðalbergs""
]
,
[
""Agnes""
,
""Agnesi""
,
""Agnesi""
,
""Agnesar""
]
,
// ...and over 3,600 more
]
Naive implementation
With the declension data in place, let’s get to writing our library. The library will export a single
applyCase
function that takes a name in the nominative case and the grammatical case that the name should be returned in:
function
applyCase
(
name
:
string
,
grammaticalCase
:
Case
)
{
// ...
}
applyCase
(
""Guðmundur""
,
""accusative""
)
//
=>
""Guðmund""
The naive implementation would be to find the forms of the name and the index of the form to return:
const
CASES
=
[
""nominative""
,
""accusative""
,
""dative""
,
""genitive""
]
;
function
applyCase
(
name
:
string
,
grammaticalCase
:
Case
)
{
const
nameForms
=
NAME_FORMS
.
find
(
forms
=>
forms
[
0
]
===
name
)
;
const
caseIndex
=
CASES
.
indexOf
(
grammaticalCase
)
;
}
and, with those in hand, return the form at
caseIndex
if
nameForms
was found for the input
name
, otherwise returning
name
as a fallback:
function
applyCase
(
name
:
string
,
grammaticalCase
:
Case
)
{
const
nameForms
=
NAME_FORMS
.
find
(
forms
=>
forms
[
0
]
===
name
)
;
const
caseIndex
=
CASES
.
indexOf
(
grammaticalCase
)
;
return
nameForms
?.
[
caseIndex
]
||
name
;
}
This “works” but has two main issues, the first of which is bundle size. The
NAME_FORMS
list is about 30 kB gzipped, which I think is a tad much to add to a web app’s bundle size.
The second issue is that this naive implementation only works for names in the
NAME_FORMS
list. As mentioned earlier, there are around 800 approved Icelandic names that are not covered by the DIM data.
Let’s see how we can solve both of those.
Encoding the forms compactly
We’re currently storing the four forms of each name in full. We can remove a lot of redundancy by finding the
longest common prefix
of the name and the suffixes of each form.
Consider the forms of “Guðmundur”:
Guðmundur
Guðmund
Guðmundi
Guðmundar
The longest common prefix is “Guðmund”, and the suffixes are as follows:
Guðmund
ur
Guðmund
Guðmund
i
Guðmund
ar
^^^^^^^
^^
Prefix
Suffix
We can store the suffixes compactly in a string like so:
suffixes
.
join
(
"",""
)
Which for Guðmundur, gives us:
""ur,,i,ar""
Since
applyCase
receives the nominative case of the name as input, we can derive the prefix from the length of the nominative suffix’s length.
function
getPrefix
(
nameNominative
,
suffixLength
)
{
return
nameNominative
.
slice
(
0
,
-
suffixLength
)
;
}
const
suffixes
=
""ur,,i,ar""
;
const
nominativeSuffix
=
suffixes
.
split
(
"",""
)
[
0
]
;
getPrefix
(
""Guðmundur""
,
nominativeSuffix
.
length
)
//
=>
""Guðmund""
We’ll call this method of encoding the suffixes of each form in a string the “suffix encoding”, or just “encoding”, from here on.
A feature of the suffix encoding is that the encoding is not tied to any specific name (“Guðmund” appears nowhere). Instead, the suffix encoding describes a
pattern
of declension, which we’ll use to our advantage later.
Retrieving the suffixes by name
When we were storing the raw forms in an array, it was very easy to find the forms of any given name:
NAME_FORMS
.
find
(
forms
=>
forms
[
0
]
===
name
)
But the suffix encoding doesn’t encode the name itself, so we need a way to retrieve the encoding. The simplest method would be a plain hash map:
const
nameToFormsEncoding
=
{
Guðmundur
:
""ur,,i,ar""
,
// ...3,600 more lines
}
;
Putting bundle size concerns aside, a hash map doesn’t solve the problem of names not in the list of approved Icelandic names being excluded.
Here, one helpful fact about Icelandic declension is that names with similar suffixes
tend
to follow the same pattern of declension. These names ending in
“ur”
all have the same suffix encoding of
""ur,,i,ar""
:
Ástvaldur
Bárður
Freymundur
Ingimundur
Sigurður
Þórður
There are, in fact, 88 approved Icelandic names with this exact pattern of declension, and they all end with
“dur”
,
“tur”
or “
ður
”.
The naive approach, then, would be to implement a
getSuffixEncoding
function that captures these patterns:
function
getSuffixEncoding
(
name
)
{
if
(
/
(d|ð|t)ur$
/
.
test
(
name
)
)
{
return
""ur,,i,ar""
;
}
// ...
}
But that quickly breaks down. There are other names ending with
“ður”
or
“dur”
that follow a different pattern of declension:
“Aðalráður”
and
“Arnmóður”
have a suffix encoding of
""ur,,i,s""
“Baldur”
has a suffix encoding of
""ur,ur,ri,urs""
“Hlöður”
and
“Lýður”
both have a suffix encoding of
""ur,,,s""
In fact, take a look at this
gist
showing every approved Icelandic personal name grouped by their suffix encoding (there are 124 unique encodings). You’ll immediately find patterns, but if you take a closer look you’ll find numerous counterexamples to those patterns. Capturing all of these rules and their exceptions in code would be a tedious and brittle affair.
Instead of trying to code up the rules manually, we can use a data structure that lends itself perfectly to this problem.
Tries
The
trie
data structure, also known as a prefix tree, is a tree data structure that maps string keys to values. In tries, each character in the key becomes a node in the tree that points to the next possible characters.
Take, for example, the name
“Heimir”
, which has a suffix encoding of
""r,,,s""
. If we create an empty trie and insert
“Heimir”
and
""r,,,s""
as a key-value pair into it, we get:
Let’s now insert
“Heiðar”
into the trie, which has a suffix encoding of
""r,,i,s""
. The names share the first three characters, so they share the first three nodes in the trie:
However, we actually want to insert the keys
backwards
into the trie. That is because, like I mentioned earlier, names with similar endings (suffixes) tend to have similar suffix encodings. Inserting keys backwards results in the values for all names sharing a certain suffix being grouped within that suffix’s subtree.
Let’s take a concrete example — consider the following names that end with
“ur”
and their encodings:
Ylfur
ur,i,i,ar
Knútur
ur,,i,s
Hrútur
ur,,i,s
Loftur
ur,,i,s
Name
Suffix encoding
Inserting them
backwards
into a new trie gives us the following:
Once we start inserting the names backwards, every node in the trie corresponds to a specific suffix match:
The
r
u
subtree corresponds to the
“ur”
suffix.
The
r
u
t
subtree corresponds to the
“tur”
suffix.
Additionally:
The
r
u
subtree contains the values for all names ending in
“ur”
.
The
r
u
t
subtree contains the values for all names ending in
“tur”
.
Having the values of names sharing a common suffix all within the same subtree will help us find patterns in suffix-to-value mappings. We can then apply those patterns to not-before-seen names.
Before we get to that, let’s quickly cover trie lookups.
Trie lookups
Let’s implement a
trieLookup
function that takes the trie’s
root
node and a
key
(name) to find a value for:
interface
TrieNode
{
children
?
:
{
[
key
:
string
]
:
TrieNode
}
;
value
?
:
string
;
}
function
trieLookup
(
root
:
TrieNode
,
key
:
string
)
{
// ...
}
For each character in the key, we traverse to the child
node
for that character, stopping if no such
node
exists. After that, we return the value of the resulting
node
, if present:
function
trieLookup
(
root
:
TrieNode
,
key
:
string
)
{
let
node
:
TrieNode
|
undefined
=
root
;
for
(
const
char
of
reverse
(
key
)
)
{
node
=
node
.
children
?.
[
char
]
;
if
(
!
node
)
{
break
;
}
}
return
node
?.
value
;
}
Note:
We reverse the lookup key because names are inserted into the trie backwards.
Looking up a name that we insert into the trie returns its suffix encoding, as expected:
trieLookup
(
root
,
""Loftur""
)
//
=>
""ur,,i,s""
Compressing the trie
In our trie from earlier, every leaf in the
r
u
t
subtree has the same value of
""ur,,i,s""
:
When every leaf in a subtree has a common value, we can
compress
the subtree. We do that by setting the value of the subtree’s root to the value of its leaves, and then deleting every child of the root.
The trie from above, compressed.
Let’s quickly implement a recursive
compress
function that performs this operation:
function
compress
(
node
:
TrieNode
)
:
string
|
null
{
// ...
}
The
compress
function should return
null
and do nothing if
node
’s children do not share a single common value. If they
do
share a common value, it should delete all of its children and assign their common value to itself.
The first step is to collect the values of
node
’s children by invoking
compress
recursively (using a
depth-first
traversal):
const
values
=
Object
.
values
(
node
.
children
)
.
map
(
compress
)
;
If there is not a single shared value, we return
null
:
if
(
new
Set
(
values
)
.
size
!==
1
||
values
[
0
]
==
null
)
{
return
null
;
}
Otherwise, we assign the value to
node
, remove the children, and return the value.
node
.
value
=
values
[
0
]
;
node
.
children
=
{
}
;
return
node
.
value
;
This gives us:
function
compress
(
node
:
TrieNode
)
{
const
values
=
Object
.
values
(
node
.
children
)
.
map
(
compress
)
;
values
.
push
(
node
.
value
)
;
if
(
new
Set
(
values
)
.
size
!==
1
||
values
[
0
]
==
null
)
{
return
null
;
}
node
.
value
=
values
[
0
]
;
node
.
children
=
{
}
;
return
node
.
value
;
}
compress
(
root
)
;
Let’s take a second look at the compressed trie:
After compression, it communicates the following information:
All names ending in
“fur”
resolve to a value of
""ur,i,i,ar""
All names ending in
“tur”
resolve to a value of
""ur,,i,s""
When we originally inserted
“Ylfur”
into the trie, the associated value was stored under
r
u
f
l
Y
, but after compressing the trie, only the
r
u
f
part of that path remains.
This means that our
trieLookup
function from earlier will return
null
for
“Ylfur”
:
function
trieLookup
(
root
:
TrieNode
,
key
:
string
)
{
let
node
:
TrieNode
|
undefined
=
root
;
for
(
const
char
of
reverse
(
key
)
)
{
node
=
node
.
children
?.
[
char
]
;
//
'node' will be null for 'f->l'
if
(
!
node
)
{
break
;
}
}
return
node
?.
value
;
}
trieLookup
(
root
,
""Ylfur""
)
//
=>
null
We can fix that by returning the value of the last node we encountered:
function
trieLookup
(
root
:
TrieNode
,
key
:
string
)
{
let
node
=
root
;
for
(
const
char
of
reverse
(
key
)
)
{
const
next
=
node
.
children
?.
[
char
]
;
if
(
!
next
)
{
break
;
}
node
=
next
;
}
return
node
.
value
;
}
trieLookup
(
root
,
""Ylfur""
)
//
=>
""ur,i,i,ar""
We only override
node
if there is a
next
node.
Now, looking up the original four input names returns the values for those names:
trieLookup
(
trie
,
""Ylfur""
)
//
=>
""ur,i,i,ar""
trieLookup
(
trie
,
""Knútur""
)
//
=>
""ur,,i,s""
trieLookup
(
trie
,
""Hrútur""
)
//
=>
""ur,,i,s""
trieLookup
(
trie
,
""Loftur""
)
//
=>
""ur,,i,s""
However, we also get values for lookup keys not in the original input data:
trieLookup
(
trie
,
""Bjartur""
)
//
=>
""ur,,i,s""
This was not the case prior to compressing the trie — only the original input keys returned a value in the original trie.
Lookups in the compressed trie return
""ur,i,i,ar""
for all lookup keys matching
*fur
, and
""ur,,i,s""
for all lookup keys matching
*tur
.
The compressed trie has, in some sense, “learned” the suffix patterns of the input data, and returns values based on that.
Names in the input data ending in
*tur
always resolved to the same value so the
r
u
t
subtree was compressed — same with
*fur
. However, there were multiple values for names ending in
*ur
so the tree diverges after
r
u
:
This divergence raises a question: what about names matching
*ur
but neither
*fur
nor
*tur
?
“Sakur”
is one such key. When invoking
trieLookup
the last hit
node
is the
u
node. Since
u
has no value,
null
is returned:
trieLookup
(
trie
,
""Sakur""
)
//
=>
null
If every key in the trie’s input data ending in
*ur
were to resolve to the same value, then
“Sakur”
should resolve to that value. However, not every key ending in
*ur
resolves to the same value — keys ending in
*tur
resolve to one value and keys ending in
*fur
to another.
For a key matching
*ur
but not
*(t|f)ur
, we
could
just pick one of the branches. However, at most one of the branches resolves to the correct value (and in many cases, none of the branches do). The natural conclusion, then, is to
not
return a value.
The compressed trie acts as a sort of suffix-to-value pattern matcher. If a certain suffix in the input data always maps to a certain value, the compressed trie always returns that value for keys matching the suffix. But for “ambiguous” suffix matches, no value is returned.
Since Icelandic names with similar suffixes
tend
to have the same pattern of declension, the theory is that the compressed trie should be able to predict the correct pattern of declension for not-before-seen names. Let’s see how well that theory holds.
Compressing 3,600 names
Of the 4,500 approved Icelandic names, we have declension data for roughly 3,600.
Inserting those names and their suffix encodings into a new trie gives us a trie with 10,284 nodes, 3,638 of which are leaves. Compressing the trie by merging subtrees with common values reduces the total number of nodes to 1,588. Of those, 1,261 are leaves and 327 are not.
Uncompressed
Compressed
Compressed (%)
Total nodes
10,284
1,588
15.4%
Non-leaf nodes
6,646
327
4.9%
Leaf nodes
3,638
1,261
34.6%
Compressing the trie resulted in 6,319 non-leaf nodes being removed, which is
over 95%
.
The removal of non-leaf nodes means shorter paths from the root to the leaves of the trie. Here’s a chart showing the traversal depth of lookups for the keys in the input data for the compressed and uncompressed tries:
Lookup depth correspond to the length of the suffix match needed for a value to be returned. For the majority of names in the original input data, that length is three or lower in the compressed trie.
Testing the trie on not-before-seen names
In testing how well the compressed trie predicts the declension patterns of not-before-seen names, the 800 approved Icelandic names that we don’t have declension data for serve as good test cases.
I wrote a function to pick 100 of those names at random and (manually) categorized the declension pattern returned when looking those names up in the trie:
Result
Count
Perfect (declension applied)
62
Perfect (no declension applied)
12
Should have applied declension
23
Wrong, should not be declined
2
Wrong declension
1
This gives us a rough indication that, for not-before-seen Icelandic names, the compressed trie gives us correct results 74% of the time and wrong results 26% of the time.
The
“Should have applied declension”
case, which constitutes 23% of results, results in
applyCase
not applying declension to the name and returning it as-is. That result
is
wrong, but I consider it a lesser kind of wrong.
Still, these are just 100 random names. Some names are far more common than others. It’d be more interesting to see how well the compressed trie performs for the most common names.
Luckily for us,
Statistics Iceland
publishes data on
how many individuals have specific names
. Using that data, I created the chart below. It shows the number of people holding each name in the approved list of names as a first name. The 3,600 names with declension data available are colored blue. The 800 names without declension data are colored red:
Logarithmic
Note:
Since relatively few names dominate this list, I made the chart logarithmic by default. You can use the toggle in the upper-right corner to make it linear.
363,314 people hold a name from the approved list of Icelandic names as a first name. Of those, 5,833 have names that don’t have declension data available.
As we can see from the chart, the commonality of names is far from evenly distributed. In fact, the top 100 names without declension data are held by 4,990 people. Those 4,990 people constitute 86% of the 5,833 people that hold one of the 800 names without declension data available.
I went ahead and categorized the declension results for those 100 names, multiplying the result by the number of people holding the name:
Result
Number of people
Perfect (declension applied)
3,489
Perfect (no declension applied)
440
Should have applied declension
915
Wrong, should not be declined
101
Wrong declension
45
Total
4,990
1,061 wrong results gives us an error rate of 21%. If we extrapolate that 21% error rate across the 5,833 people holding names without declension data available, we get 1,240 wrong results. Dividing 1,240 wrong results by the 363,314 people holding names in the approved list of Icelandic names gives us an error rate of 0.34%.
If we do the same math with only the names that were
incorrectly
declined, we get an error rate of 0.046%.
Regularity and comprehensiveness
The compressed trie captures the rules of Icelandic name declension to an impressive degree. I attribute this to the
regularity
and
comprehensiveness
of the data on Icelandic name declension, where
regularity
is the degree to which similar key suffixes map to the same values, and
comprehensiveness
is how well the input data captures rules
and
exceptions to them.
Regularity
If the input data were
irregular
— meaning that there’s no significant relationship between suffixes and associated values — the values of leaves in subtrees would frequently differ. That would prevent subtree compression, resulting in a not-very-compressed trie that is similar, if not identical, to the original trie. The less a trie is compressed, the longer the suffix match needs to be for a value to be returned.
The opposite happens as the input data becomes more regular. Subtrees will be more frequently compressed, leading to shorter suffix matches being required for values to be returned.
Comprehensiveness
Subtrees are only ever incorrectly compressed if the original trie lacks a counterexample to the regularity that led to compression. If a counterexample had been present, it would have prevented compression and created an exception to the rule.
If we pick, say, 450 Icelandic names at random, we will capture many of the rules of Icelandic name declension, and some counterexamples to them. Still, 450 names are only about 10% of approved Icelandic names, so we can expect loads of declension rules
not
to be covered by that sample.
But with over 3,600 samples, as in our case, we have over 80% coverage. With data that comprehensive, the compressed trie captures the rules — and exceptions to those rules — to an impressive degree.
Bundle size
I’ve mentioned bundle time a few times — let’s finally measure it!
I measured the size of storing the declension data for the 3,600 names that we have declension data for in the following ways:
List (the
NAME_FORMS
list from before)
Trie (uncompressed)
Trie (compressed)
Here are the results:
List
30.17 kB gzipped (152.48 kB minified)
Trie (uncompressed)
14.47 kB gzipped (66.68 kB minified)
Trie (compressed)
4.01 kB gzipped (14.41 kB minified)
Note:
The trie is serialized to a compact string representation to make its size smaller (see
serializer
and
deserializer
). For comparison, the compressed trie represented as JSON is 4.75 kB.
4.01 kB is very compact, but we can take the compression one step further.
Merging sibling leaves with common suffixes
Take a look at the
r
u
f
subtree from the compressed trie — it represents names matching
*fur
:
Note:
I’ve hidden the full
*lfur
subtree to simplify this view.
The
i
,
ó
,
ú
,
a
sibling leaves following
r
u
f
all resolve to the same value of
""ur,,i,s""
. However, the
l
and
i
subtrees have leaves with different values, which prevented the
r
u
f
subtree from being compressed.
What we can do here is merge sibling leaves with common values. That results in the
i
,
ó
,
ú
,
a
leaves being merged into a single
ióúa
leaf node:
Let’s implement a
mergeLeavesWithCommonValues
function that performs this compression.
function
mergeLeavesWithCommonValues
(
node
:
TrieNode
)
{
// ...
}
Firstly, if the
node
has no children, we can immediately return, otherwise performing the operation recursively on the children:
if
(
!
node
.
children
)
{
return
;
}
for
(
const
child
of
Object
.
values
(
node
.
children
)
)
{
mergeLeavesWithCommonValues
(
child
)
}
For the children of
node
, there are two cases to handle:
The child is a leaf node with a
value
.
The child is a non-leaf node.
We want to merge leaf nodes with the same value, so we’ll group the keys of leaf nodes by their value:
const
keysByValue
:
Record
<
string
,
string
>
=
{
}
;
However, we want to leave non-leaf nodes alone, so we’ll define a new
newChildren
object to place them into as we encounter them:
const
newChildren
:
Record
<
string
,
TrieNode
>
=
{
}
;
With those defined, we’ll iterate through the children, transferring non-leaf nodes immediately and grouping leaf keys by values:
for
(
const
[
key
,
child
]
of
Object
.
entries
(
node
.
children
)
)
{
const
isLeaf
=
!
!
child
.
value
;
if
(
isLeaf
)
{
keysByValue
[
child
.
value
]
??=
[
]
;
keysByValue
[
child
.
value
]
.
push
(
key
)
}
else
{
newChildren
[
key
]
=
child
;
}
}
When looking at this, one could be concerned that a
child
might contain both a value
and
children. In our Icelandic names trie, however, there is no overlap because each name in the input data starts with an uppercase character.
After iteration, we can construct the merged leaves and add them to
newChildren
like so:
for
(
const
[
value
,
keys
]
of
Object
.
entries
(
keysByValue
)
)
{
newChildren
[
keys
.
join
(
""""
)
]
=
{
value
}
;
}
node
.
children
=
newChildren
;
This concludes the implementation. The full implementation is a bit long, so I won’t show it in full here — you can view it in this
gist on GitHub
.
We need to consider merged keys in our
trieLookup
function. To do that, we’ll update the
trieLookup
function to use a new
findChild
function instead of
node
.
children
?.
[
char
]
when finding the next node.
function
trieLookup
(
root
:
TrieNode
,
key
:
string
)
{
let
node
=
root
;
for
(
const
char
of
reverse
(
key
)
)
{
const
next
=
findChild
(
node
,
char
)
;
if
(
!
next
)
{
break
;
}
node
=
next
;
}
return
node
.
value
;
}
Implementing
findChild
is relatively simple: we iterate through the children, returning the current child if its key contains the lookup character:
function
findChild
(
node
:
TrieNode
,
char
:
string
)
{
const
children
=
node
.
children
||
{
}
;
for
(
const
[
key
,
child
]
of
Object
.
entries
(
children
)
)
{
if
(
key
.
includes
(
char
)
)
{
return
child
}
}
}
It’s worth mentioning that, unlike merging subtrees with common values, merging sibling leaves has no functional effect on the trie. This layer of compression is purely to make the trie’s footprint smaller.
Trie after merging sibling leaves
Here is the node count table from before with a new column that shows the results for the trie that has also had its sibling leaves merged:
Uncompressed
Only subtrees merged
Subtrees and sibling leaves merged
Total nodes
10,284
1,588
972
Non-leaf nodes
6,646
327
327
Leaf nodes
3,638
1,261
645
Merging sibling leaf nodes with common values almost cuts the number of leaf nodes in half! Since we’re only touching the leaf nodes, the number of non-leaf nodes stays the same. Lookup depth is also not affected.
One interesting statistic is how many names in the original input data each leaf node now represents. Here are the top 50 leaf nodes by the number of names they represent:
The top node
i
bdfjklmnpstvxðóú
is the result of merging 166 leaf nodes. That indicates that Icelandic names ending in
“i”
exhibit a high degree of regularity in their pattern of declension.
Let’s take a closer look at the
i
subtree. Next to each value node, I’ve added the number of names that the leaf node represents in parentheses.
The
i
subtree is built from 223 names starting with
“i”
. Only four of those names don’t follow the declension pattern of
""i,a,a,a""
. That’s a really high degree of regularity!
Those four names serve as important counterexamples to the general rule that names ending in
“i”
have a suffix encoding of
""i,a,a,a""
. Without them, the
i
subtree would have been compressed to a single value node.
Final bundle size
Here’s what merging sibling leaves with common values did for the bundle size of the trie:
List
30.17 kB gzipped (152.48 kB minified)
Trie (uncompressed)
14.47 kB gzipped (66.68 kB minified)
Trie (subtrees merged)
4.01 kB gzipped (14.41 kB minified)
Trie (subtrees and leaves merged)
3.27 kB gzipped (9.3 kB minified)
It saves us 0.74 kB. That’s a small number in absolute terms, but hey, it’s an 18% improvement!
The beygla library
I use the compressed trie in a declension library for Icelandic names called
beygla
. The library is 4.46 kB gzipped, 3.27 kB of which is the serialized trie. As described, it exports an
applyCase
function that is used to apply grammatical cases to Icelandic names.
The beygla library is used, for example, by the Icelandic judicial system to
decline the names of defendants
in indictments.
The library includes a
""beygla/addresses""
module (
see motivating issue
). It uses the exact same approach, with that module’s trie being built from data on Icelandic addresses.
Trading bundle size for 100% correctness
The indictment example I linked above uses the
strict version
of beygla:
import
{
applyCase
}
from
""beygla/strict""
;
The
""beygla/strict""
module only applies cases to names in the approved list of Icelandic names. I added it after
this issue
was raised:
“We are using beygla in a project within the public sector. Our users care
a lot
about using grammatically correct Icelandic.”
When first developing beygla, I cared
a lot
about the bundle size being as small as possible so that Icelandic web apps could use the library without being concerned about JavaScript bloat. I found the compressed trie really powerful in that it both made the library
tiny
while also applying declension to not-before-seen names with few errors. There’s certainly a cool factor to it.
But still, beygla does occasionally produce a wrong result, which is
not
an appropriate trade-off in contexts such as generating indictments.
""beygla/strict""
is about 15 kB gzipped (10 kB more than the default beygla module), which, honestly, is not that large of a bundle size increase.
Because of that, if I were developing the library again today, I probably would have made
""beygla/strict""
the default. For apps willing to trade 100% correctness for bundle size, they could opt for the less-but-mostly-correct 5 kB variant. Perhaps I’ll publish a new major version of beygla with that change soon.
Note:
The
beygla/strict
module encodes the list of approved Icelandic names in
another
trie using a compact string serialization. The
implementing PR
describes how that trie is serialized, so I won’t cover it here.
Final words
Building beygla was a super fun problem to solve. When I first started the project, I didn’t expect to be able to get the bundle size so low. The compressed trie ended up being really effective for encoding Icelandic declension patterns.
If Icelandic language technology is something that’s interesting to you, I’d suggest checking out
Miðeind
— they have a lot of open source projects around AI and natural language processing for Icelandic.
There are many languages with declension as a language feature (such as Slavic and Balkan languages), so there is an opportunity to apply the ideas explored in this post to those languages. Native speakers of said languages are well suited to explore that.
I’d like to thank
Eiríkur Fannar Torfason
and
Vilhjálmur Thorsteinsson
for reading and providing feedback on draft versions of this post. Vilhjálmur actually identified an optimization opportunity in beygla that reduced the size of the trie from 3.43 kB to 3.27 kB (
see PR
).
Thanks for reading, I hope this was interesting.
— Alex Harri
Mailing list
To be notified of new posts, subscribe to my mailing list.
Subscribe","Aug 2, 2025"
Planes in 3D space,"A plane in 3D space can be thought of as a flat surface that stretches infinitely far, splitting space into two halves.
Loading 3D scene
Planes have loads of uses in applications that deal with 3D geometry. I’ve mostly been working with them in the context of an
architectural modeler
, where geometry is defined in terms of planes and their intersections.
Learning about planes felt abstract and non-intuitive to me.
“Sure, that’s a plane equation, but what do I do with it? What does a plane look like?”
It took some time for me to build an intuition for how to reason about and work with them.
In writing this, I want to provide you with an introduction that focuses on building a practical, intuitive understanding of planes. I hope to achieve this through the use of visual (and interactive!) explanations which will accompany us as we work through progressively more complex problems.
With that out of the way, let’s get to it!
Describing planes
There are many ways to describe planes, such as through
a point in 3D space and a normal,
three points in 3D space, forming a triangle, or
a normal and a distance from an origin.
Throughout this post, the term
normal
will refer to a
normalized direction vector
(unit vector) whose magnitude (length) is equal to 1, typically denoted by
where
.
Starting with the point-and-normal case, here’s an example of a plane described by a point in 3D space
and a normal
:
Loading 3D scene
The normal
describes the plane’s orientation, where the surface of the plane is perpendicular to
, while the point
describes
a
point on the plane.
We described this plane in terms of a single point
, but keep in mind that this plane—let’s call it
—contains infinitely many points.
Loading 3D scene
If
were described by one of those other points contained by
, we would be describing the exact same plane. This is a result of the infinite nature of planes.
This way of describing planes—in terms of a point and a normal—is the
point-normal form
of planes.
We can also describe a plane using three points in 3D space
,
,
forming a triangle:
Loading 3D scene
The triangle forms an implicit plane, but for us to be able to do anything useful with the plane we’ll need to calculate its normal
. Once we’ve calculated the plane’s normal, we can use that normal along with one of the triangle’s three points to describe the plane in point-normal form.
Loading 3D scene
As mentioned earlier, the normal
describing a plane is a unit vector (
) perpendicular to the plane.
We can use
and
as two edge vectors that are parallel to the plane’s surface.
Loading 3D scene
By virtue of being parallel to the plane’s surface, the vectors
and
are perpendicular to the plane’s normal. This is where the cross product becomes useful to us.
The
cross product
takes in two vectors
and
and returns a vector
that is perpendicular to both of them.
For example, given the vectors
and
, their cross product is the vector
, which we’ll label
:
Loading 3D scene
This explanation is simple on purpose. We’ll get into more detail about the cross product later on.
Because the edge vectors of the triangle,
and
, are both parallel to the triangle’s surface, their cross product will be perpendicular to the triangle’s surface. Let’s name the cross product of our two edge vectors
:
Loading 3D scene
has been scaled down for illustrative purposes
points in the right direction, but it’s not a normal. For
to be a normal, its magnitude needs to  equal 1. We can normalize
by dividing it by its magnitude, the result of which we’ll assign to
:
This gives us a normal
where
:
Loading 3D scene
Having found the triangle’s normal
we can use it and any of the points
,
,
to describe the plane containing the three points in point-normal form.
Loading 3D scene
It doesn’t matter which of
,
,
we use as the point in the point-normal form; we always get the same plane.
Constant-normal form
There’s one more way to describe a plane that we’ll look at, which is through a normal
and a distance
.
Loading 3D scene
This is the
constant-normal form
of planes. It makes lots of calculations using planes much simpler.
In the constant-normal form, the distance
denotes how close the plane gets to the origin. Thought of another way: multiplying the normal
by
yields the point on the plane that’s closest to the origin.
This is a simplification. More formally, given a point
on a plane whose normal is
, we can describe all points
on the plane in two forms: the point-normal form
, and the constant-normal form
where
. See
further reading
.
In getting a feel for the difference between the point-normal and constant-normal forms, take this example which describes the same plane in both forms:
Loading 3D scene
The green arrow represents
from the constant-normal form, while the blue point and arrow represent the point
and normal
from the point-normal form.
Translating from the point-normal to the constant-normal form is very easy: the distance
is the
dot product
of
and
.
If you’re not familiar with the dot product, don’t worry. We’ll cover it later on.
The notation for
and
might seem to indicate that they’re of different types, but they’re both vectors. I’m differentiating between points in space (e.g.
and
) and direction vectors (e.g.
and
) by using the arrow notation only for direction vectors.
The normal
stays the same across both forms.
Distance from plane
Given an arbitrary point
and a plane
in constant-normal form, we may want to ask how far away the point is from the plane. In other words, what is the minimum distance
needs to travel to lie on the plane?
Loading 3D scene
We can frame this differently if we construct a plane
containing
that is parallel to
, which we can do in point-normal form using
as the point and
’s normal
as the normal:
Loading 3D scene
With two parallel planes, we can frame the problem as finding the distance between the two planes. This becomes trivial using their constant-normal form since it allows us to take the difference between their distance components
and
.
So let’s find
’s distance using the
equation we learned about:
Loading 3D scene
With two distances
and
from the planes
and
the solution simply becomes:
Loading 3D scene
So, to simplify, given a plane
having a normal
and distance
, we can calculate a point
’s distance from
like so:
The distance may be positive or negative depending on which side of the plane the point is on.
Projecting a point onto a plane
A case where calculating a point’s distance from a plane becomes useful is, for example, if you want to project a point onto a plane.
Given a point
which we want to project onto plane
whose normal is
and distance is
, we can do that fairly easily. First, let’s define
as the point’s distance from the plane:
Multiplying the plane’s normal
by
gives us a vector which when added to
projects it onto the plane. Let’s call the projected point
:
Loading 3D scene
The projection occurs along the plane’s normal, which is sometimes useful. However, it is much more useful to be able to project a point onto a plane along an
arbitrary
direction instead. Doing that boils down finding the point of intersection of a line and a plane.
Line-plane intersection
We can describe lines in 3D space using a point
and normal
. The normal
describes the line’s orientation, while the point
describes a point which the line passes through.
Loading 3D scene
In this chapter, the line will be composed of the point
and normal
, while the plane—given in constant-normal form—has a normal
and a distance
.
Loading 3D scene
Our goal will be to find a distance
that
needs to travel along
such that it lies on the plane.
We can figure out the distance
that we’d need to travel if
and
were parallel, which is what we did when projecting along the plane’s normal.
Let’s try projecting
along
using
as a scalar like so:
We’ll visualize
as a red point:
Loading 3D scene
As
and
become parallel,
gets us closer and closer to the correct solution. However, as the angle between
and
increases,
becomes increasingly too small.
Here, the dot product comes in handy. For two vectors
and
, the dot product is defined as
where
is the angle between
and
.
Consider the dot product of
and
. Since both normals are unit vectors whose magnitudes are 1
we can remove their magnitudes from the equation,
making the dot product of
and
the cosine of the angle between them.
For two vectors, the cosine of their angles approaches 1 as the vectors become increasingly parallel, and approaches 0 as they become perpendicular.
Since
becomes increasingly too small as
and
become more perpendicular, we can use
as a denominator for
. We’ll assign this scaled-up version of
to
:
With
as our scaled-up distance, we find the point of intersection
via:
Loading 3D scene
We can now get rid of
, which was defined as
, giving us the full equation for
:
Putting this into code, we get:
Vector3
LinePlaneIntersection
(
Line
line
,
Plane
plane
)
{
float
denom
=
Vector3
.
Dot
(
line
.
normal
,
plane
.
normal
)
;
float
dist
=
Vector3
.
Dot
(
plane
.
normal
,
line
.
point
)
;
float
D
=
(
plane
.
distance
-
dist
)
/
denom
;
return
line
.
point
+
line
.
normal
*
D
;
}
However, our code is not complete yet. In the case where the line is parallel to the plane’s surface, the line and plane do not intersect.
Loading 3D scene
That happens when
and
are perpendicular, in which case their dot product is zero. So if
, the line and plane do not intersect. This gives us an easy test we can add to our code to yield a result of “no intersection”.
However, for many applications we’ll want to treat being
almost
parallel as actually being parallel. To do that, we can check whether the dot product is smaller than some very small number—customarily called epsilon
float
denom
=
Vector3
.
Dot
(
line
.
normal
,
plane
.
normal
)
;
if
(
Mathf
.
Abs
(
denom
)
<
EPSILON
)
{
return
null
;
// Line is parallel to plane's surface
}
See if you can figure out why Mathf.Abs is used here. We’ll cover it later, so you’ll see if you’re right.
We’ll take a look at how to select the value of epsilon in a later chapter on two plane intersections.
With this, our line-plane intersection implementation becomes:
Vector3
LinePlaneIntersection
(
Line
line
,
Plane
plane
)
{
float
denom
=
Vector3
.
Dot
(
line
.
normal
,
plane
.
normal
)
;
if
(
Mathf
.
Abs
(
denom
)
<
EPSILON
)
{
return
null
;
// Line is parallel to plane's surface
}
float
dist
=
Vector3
.
Dot
(
plane
.
normal
,
line
.
point
)
;
float
D
=
(
plane
.
distance
-
dist
)
/
denom
;
return
line
.
point
+
line
.
normal
*
D
;
}
Rays and lines
We’ve been talking about line-plane intersections, but I’ve been lying a bit by visualizing ray-plane intersections instead for visual clarity.
Loading 3D scene
A ray and a line are very similar; they’re both represented through a normal
and a point
.
The difference is that a ray (colored red) extends in the direction of
away from
, while a line (colored green) extends in the other direction as well:
Loading 3D scene
What this means for intersections is that a ray will not intersect planes when traveling backward along its normal:
Loading 3D scene
Our implementation for ray-plane intersections will differ from our existing line-plane intersection implementation only in that it should yield a result of “no intersection” when the ray’s normal
is pointing “away” from the plane’s normal
at an obtuse angle.
Since
represents how far to travel along the normal to reach the point of intersection, we could yield “no intersection” when
becomes negative:
if
(
D
<
0
)
{
return
null
;
}
But then we’d have to calculate
first. That’s not necessary since
becomes negative as a consequence of the dot product
being a negative number when
and
are at an obtuse angle between 90° and 180°.
If this feels non-obvious, it helps to remember that the dot product encodes the cosine of the angle between its two component vectors, which is why the dot product becomes negative for obtuse angles.
Knowing that, we can change our initial “parallel normals” test from this:
Vector3
LinePlaneIntersection
(
Line
line
,
Plane
plane
)
{
float
denom
=
Vector3
.
Dot
(
line
.
normal
,
plane
.
normal
)
;
if
(
Mathf
.
Abs
(
denom
)
<
EPSILON
)
{
return
null
;
// Line is parallel to plane's surface
}
// ...
}
To this:
Vector3
RayPlaneIntersection
(
Line
line
,
Plane
plane
)
{
float
denom
=
Vector3
.
Dot
(
line
.
normal
,
plane
.
normal
)
;
if
(
denom
<
EPSILON
)
{
// Ray is parallel to plane's surface or pointing away from it
return
null
;
}
// ...
}
The
check covers both the
“line parallel to plane”
case
and
the case where the two normal vectors are at an obtuse angle.
Note:
is the symbol for epsilon.
Plane-plane intersection
The intersection of two planes forms an infinite line.
Loading 3D scene
As a quick refresher: lines in 3D space are represented using a point
and normal
where normal
describes the line’s orientation, while the point
describes a point which the line passes through.
Loading 3D scene
Let’s take two planes
and
whose normals are
and
.
Finding the direction vector of
and
’s intersection is deceptively simple. Since the line intersection of two planes lies on the surface of both planes, the line must be perpendicular to both plane normals, which means that the direction of the intersection is the cross product of the two plane normals. We’ll assign it to
.
The magnitude of the cross product is equal to the
area of the parallelogram
formed by the two component vectors. This means that we can’t expect the cross product to be a unit vector, so we’ll normalize
and assign the normalized direction vector to
.
This gives us the intersection’s normal
. Let’s zoom in and see this close up.
Loading 3D scene
But this is only half of the puzzle! We’ll also need to find a point in space to represent the line of intersection (i.e. a point which the line passes through). We’ll take a look at how to do just that, right after we discuss the no-intersection case.
Handling parallel planes
Two planes whose normals are parallel will never intersect, which is a case that we’ll have to handle.
Loading 3D scene
The cross product of two parallel normals is
. So if
, the planes do not intersect.
As previously mentioned, for many applications we’ll want to treat planes that are
almost
parallel as being parallel. This means that our plane-plane intersection procedure should yield a result of “no intersection” when the magnitude of
is less than some very small number called epsilon.
Line
PlanePlaneIntersection
(
Plane
P1
,
Plane
P2
)
{
Vector3
direction
=
Vector3
.
cross
(
P1
.
normal
,
P2
.
normal
)
;
if
(
direction
.
magnitude
<
EPSILON
)
{
return
null
;
// Roughly parallel planes
}
// ...
}
But what should the value of epsilon be?
Given two normals
and
where the angle between
and
is
, we can find a reasonable epsilon by charting
for different values of
:
Both of the axes are
logarithmic
.
The relationship is linear: as the angle between the planes halves, so does the magnitude of the cross product of their normals.
yields a magnitude of
, and
yields half of that.
So to determine the epsilon, we can ask: how low does the angle in degrees need to become for us to consider two planes parallel? Given an angle
, we can find the epsilon
via:
If that angle is 1/256°, then we get:
With this you can determine the appropriate epsilon based on how small the angle between the planes needs to be for you to consider them parallel. That will depend on your use case.
Finding a point of intersection
Having computed the normal and handled parallel planes, we can move on to finding a point
along the line of intersection.
Since the line describing a plane-plane intersection is infinite, there are infinitely many points we could choose as
.
Loading 3D scene
We can narrow the problem down by taking the plane parallel to the two plane normals
,
and observing that it intersects the line at a single point.
Loading 3D scene
Since the point lies on the plane parallel to the two plane normals, we can find it by exclusively traveling along those normals.
The simplest case is the one where
and
are perpendicular. In that case, the solution is just
. Here’s what that looks like visually:
Loading 3D scene
When dragging the slider, notice how the tip of the parallelogram gets further away from the point of intersection as the planes become more parallel.
We can also observe that as we get further away from the point of intersection, the longer of the two vectors (colored red) pushes us further away from the point of intersection than the shorter (blue) vector does. This is easier to observe if we draw a line from the origin to the point of intersection:
Loading 3D scene
Let’s define
and
as the scaling factors that we apply to
and
(the result of which are the red and blue vectors). Right now we’re using the distance components
and
of the planes as the scaling factors:
To solve this asymmetric pushing effect, we need to travel less in the direction of the longer vector as the planes become more parallel. We need some sort of “pulling factor” that adjusts the vectors such that their tip stays on the line as the planes become parallel.
Here our friend the dot product comes in handy yet again. When the planes are perpendicular the dot product of
and
equals 0, but as the planes become increasingly parallel, it approaches 1. We can use this to gradually increase our yet-to-be-defined pulling factor.
Let’s give the dot product
the name
to make this a bit less noisy:
The perfect pulling factors happen to be the distance components
and
used as counterweights against each other!
Consider why this might be. When
and
are perpendicular, their dot product equals 0, which results in
which we know yields the correct solution.
In the case where
and
are parallel, their dot product equals 1, which results in:
Because the absolute values of
and
are equal, it means that the magnitude of the two vectors—defined as
and
—is equal:
This means that the magnitude of our vectors will become
more
equal as the planes become parallel, which is what we want!
Let’s see this in action:
Loading 3D scene
The vectors stay on the line, but they become increasingly too short as
and
become parallel.
Yet again, we can use the dot product. Since we want the length of the vectors to increase as the planes become parallel, we can divide our scalars
and
by
where
is the dot product of
and
and
is the absolute value of
.
The result of this looks like so:
Loading 3D scene
Using
as the denominator certainly increases the size of the parallelogram, but by too much.
However, notice what happens when we visualize the quadrants of the parallelogram:
Loading 3D scene
As the planes become more parallel, the point of intersection approaches the center of the parallelogram.
In understanding why that is, consider the effect that our denominator
has on the area of the parallelogram. When
, both of the vectors forming the parallelogram double in length, which has the effect of quadrupling the area of the parallelogram.
This means that when we scale the component vectors of the parallelogram by
it has the effect of scaling the area of the parallelogram by:
To instead scale the
area
of the parallelogram by
, we need to square
in the denominator:
Squaring allows us to remove
because the square of a negative number is positive.
With this, our scalars
and
become
which scales the parallelogram such that its tip lies at the point of intersection:
Loading 3D scene
Putting all of this into code, we get:
float
dot
=
Vector3
.
Dot
(
P1
.
normal
,
P2
.
normal
)
;
float
denom
=
1
-
dot
*
dot
;
float
k1
=
(
P1
.
distance
-
P2
.
distance
*
dot
)
/
denom
;
float
k2
=
(
P2
.
distance
-
P1
.
distance
*
dot
)
/
denom
;
Vector3
point
=
P1
.
normal
*
k1
+
P2
.
normal
*
k2
;
Based on code from
Real-Time Collision Detection by Christer Ericson
Which through some mathematical magic can be optimized down to:
Vector3
direction
=
Vector3
.
cross
(
P1
.
normal
,
P2
.
normal
)
;
float
denom
=
Vector3
.
Dot
(
direction
,
direction
)
;
Vector3
a
=
P1
.
distance
*
P2
.
normal
;
Vector3
b
=
P2
.
distance
*
P1
.
normal
;
Vector3
point
=
Vector3
.
Cross
(
a
-
b
,
direction
)
/
denom
;
How this optimization works can be found in chapter 5.4.4 of
Real-Time Collision Detection by Christer Ericson
.
This completes our plane-plane intersection implementation:
Line
PlanePlaneIntersection
(
Plane
P1
,
Plane
P2
)
{
Vector3
direction
=
Vector3
.
cross
(
P1
.
normal
,
P2
.
normal
)
;
if
(
direction
.
magnitude
<
EPSILON
)
{
return
null
;
// Roughly parallel planes
}
float
denom
=
Vector3
.
Dot
(
direction
,
direction
)
;
Vector3
a
=
P1
.
distance
*
P2
.
normal
;
Vector3
b
=
P2
.
distance
*
P1
.
normal
;
Vector3
point
=
Vector3
.
Cross
(
a
-
b
,
direction
)
/
denom
;
Vector3
normal
=
direction
.
normalized
;
return
new
Line
(
point
,
normal
)
;
}
By the way, an interesting property of only traveling along the plane normals is that it yields the point on the line of intersection that is closest to the origin. Cool stuff!
Three plane intersection
Given three planes
,
,
, there are five possible configurations in which they intersect or don’t intersect:
All three planes are parallel, with none of them intersecting each other.
Two of the planes are parallel, and the third plane intersects the other two.
All three planes intersect along a single line.
The three planes intersect each other in pairs, forming three parallel lines of intersection.
All three planes intersect each other at a single point.
Loading 3D scene
When finding the point of intersection, we’ll first need to determine whether all three planes intersect at a single point—which for configurations 1 through 4, they don’t.
Given
,
,
as the plane normals for
,
,
, we can determine whether the planes intersect at a single point with the formula:
When I first saw this, I found it hard to believe this would work for all cases. Still, it does! Let’s take a deep dive to better understand what’s happening.
Two or more planes are parallel
We’ll start with the configurations where two or more planes are parallel:
Loading 3D scene
If
and
are parallel then
is a vector whose magnitude is zero.
And since the dot product is a multiple of the magnitudes of its component vectors:
the final result is zero whenever
and
are parallel.
This takes care of the “all-planes-parallel” configuration, and the configuration where
and
are parallel
Loading 3D scene
With that, let’s consider the case where
is parallel to either
or
but
and
are not parallel to each other.
Let’s take the specific case where
is parallel to
but
is parallel to neither.
Loading 3D scene
Here the cross product
is a vector (colored red) that’s perpendicular to both
and
.
Loading 3D scene
Since
is parallel to
, that means that
is also perpendicular to
. As we’ve learned, the dot product of two perpendicular vectors is zero, meaning that:
This also holds in the case where
is parallel to
instead of
.
Parallel lines of intersection
We’ve demonstrated that two of the three normals being parallel results in
. But what about the configurations where the three planes intersect along parallel lines? Those configurations have no parallel normals.
Loading 3D scene
As we learned when looking at plane-plane intersections, the cross product of two plane normals gives us the direction vector of the planes’ line of intersection.
Loading 3D scene
When all of the lines of intersection are parallel, all of the plane normals defining those lines are perpendicular to them.
Yet again, because the dot product of perpendicular vectors is 0 we can conclude that
for these configurations as well.
We can now begin our implementation. As usual, we’ll use an epsilon to handle the
“roughly parallel”
case:
Vector3
ThreePlaneIntersection
(
Plane
P1
,
Plane
P2
,
Plane
P3
)
{
Vector3
cross
=
Vector3
.
Cross
(
P2
.
normal
,
P3
.
normal
)
;
float
dot
=
Vector3
.
Dot
(
P1
.
normal
,
cross
)
;
if
(
Mathf
.
Abs
(
dot
)
<
EPSILON
)
{
return
null
;
// Planes do not intersect at a single point
}
// ...
}
Computing the point intersection
We want to find the point at which our three planes
,
,
intersect:
Loading 3D scene
Some of what we learned about two-plane intersections will come into play here. Let’s start by taking the line of intersection for
and
and varying the position of
. You’ll notice that the point of intersection is the point at which
intersects the line.
Loading 3D scene
When
’s distance from the origin is 0, the vector pointing from the origin to the point of intersection is parallel to
(and perpendicular to
’s normal).
Loading 3D scene
This vector—let’s call it
—will play a large role in computing the point of intersection.
We can find
through the cross product of two other vectors
,
. The first of those,
, is just
’s normal.
The latter vector can be found via the equation
where
and
are the distances in the constant-normal form of planes
and
.
With
and
defined, we assign their cross product to
:
Let’s see what it looks like:
Loading 3D scene
Hmm, not quite long enough.
certainly points in the right direction, but to make
’s tip lie on the line of intersection, we need to compute some scaling factor for
.
As it turns out, we’ve already computed this scaling factor:
The product of
—let’s call that
—can be thought to represent how parallel
’s normal is to the line intersection of
and
.
approaches
as
’s normal becomes parallel to the line of intersection
, and approaches 0 as they become perpendicular.
We want the
’s magnitude to increase as
decreases, so we’ll make
the scaling factor for
.
Loading 3D scene
Fully expanded, the equation for
becomes:
Bam! The problem is now reduced to traveling along the direction of the line intersection until we intersect with
.
Loading 3D scene
We could use our knowledge of line-plane intersections to solve this, but there is a more efficient approach I want to demonstrate.
It involves finding a scaling factor for the direction vector
that scales it such that it’s tip ends at
. Let’s call this direction vector
.
There’s one observation we can make that simplifies that. Since
is perpendicular to
’s normal, the distance from
’s tip to
along the direction vector
is the same as the distance from the origin to
along that same direction.
Loading 3D scene
With that, consider the vector
where
and
are the normal and distance of
.
Loading 3D scene
If
were parallel to
, then
would be the scaling factor we need, but let’s see what happens with
:
Loading 3D scene
As
and
become less parallel,
becomes increasingly too short.
One thing to note as well is that even when
and
are completely parallel,
is still too short, which is due to
not being a unit vector. If we normalize
prior to multiplying with
that problem goes away.
Loading 3D scene
But we’re getting ahead of ourselves—we won’t need to normalize
. Let’s take a fresh look at how
is defined:
Having defined
as
, we can simplify this to
Earlier I mentioned that we could think of
as a measure of how parallel
’s normal
is to
(the line intersection of
and
). That’s correct, but it’s not the whole truth!
Since the dot product is a multiple of the magnitudes of its component vectors,
also encodes the magnitude of
. Hence, scaling
by
does two things:
it normalizes
, and
it increases the length of
as it becomes less parallel with
.
So
is both the scaling factor we need for
, as well as
:
Loading 3D scene
We’ve got our solution! Let’s do a quick overview.
We define
as:
We’ll redefine
to include
:
Our denominator,
, remains defined as :
With this, we find our point of intersection
by adding
and
together and scaling them by
:
Which fully expanded becomes:
Putting this into code, we get:
Vector3
ThreePlaneIntersection
(
Plane
P1
,
Plane
P2
,
Plane
P3
)
{
Vector3
dir
=
Vector3
.
Cross
(
P2
.
normal
,
P3
.
normal
)
;
float
denom
=
Vector3
.
Dot
(
u
)
;
if
(
Mathf
.
Abs
(
denom
)
<
EPSILON
)
{
return
null
;
// Planes do not intersect at a single point
}
Vector3
a
=
P2
.
normal
*
P3
.
distance
;
Vector3
b
=
P3
.
normal
*
P2
.
distance
;
Vector3
V
=
Vector3
.
Cross
(
P1
.
normal
,
a
-
b
)
;
Vector3
U
=
dir
*
P1
.
distance
;
return
(
V
+
U
)
/
denom
;
}
Parting words
Thanks for reading!
A whole lot of hours went into writing and building the visualizations for this post, so I hope it achieved its goal of helping you build an intuitive mental model of planes.
Massive thanks goes to
Gunnlaugur Þór Briem
and
Eiríkur Fannar Torfason
for providing invaluable feedback on this post. I worked with them at
GRID
; they’re fantastic people to work with and be around.
— Alex Harri
PS: If you’re interested in taking a look at how the visualizations in this post were built, this website is
open source on GitHub
.
Further reading
I highly recommend checking out
Real-Time Collision Detection by Christer Ericson
. If you’re building applications using 3D geometry, it will prove to be an incredibly useful resource. This post would not exist were it not for this book—especially the two chapters on the intersections of planes.
I recently analyzed the edit performance in
Arkio
and noticed that a method for solving three-plane intersections took around half of the total compute time when recalculating geometry. By implementing the more efficient method for three-plane intersections described in the book, we made the method
~500% faster
, increasing Arkio’s edit performance by over
1.6x
. Crazy stuff!
I started writing this post to understand how the three-plane intersection method worked. However, I felt that readers would need a better foundation and understanding of planes for this post to be of any value. In building that foundation, this post ended up quite a bit longer than I intended.
Anyway, it’s a great book.
Check it out
!
Mailing list
To be notified of new posts, subscribe to my mailing list.
Subscribe","Apr 27, 2024"
Why doesn’t TypeScript properly type Object.keys?,"If you’ve written TypeScript for a while, you’ve probably run into this:
interface
Options
{
hostName
:
string
;
port
:
number
;
}
function
validateOptions
(
options
:
Options
)
{
Object
.
keys
(
options
)
.
forEach
(
key
=>
{
if
(
options
[
key
]
==
null
)
{
//
Expression of type 'string' can't be used to index type 'Options'.
throw
new
Error
(
`
Missing option
${
key
}
`
)
;
}
}
)
;
}
This error seems nonsensical. We’re using the keys of
options
to access
options
. Why doesn’t TypeScript just figure this out?
We can somewhat trivially circumvent this by casting
Object.keys(options)
to
(keyof typeof options)[]
.
const
keys
=
Object
.
keys
(
options
)
as
(
keyof
typeof
options
)
[
]
;
keys
.
forEach
(
key
=>
{
if
(
options
[
key
]
==
null
)
{
throw
new
Error
(
`
Missing option
${
key
}
`
)
;
}
}
)
;
But why is this a problem in the first place?
If we visit the type definition for
Object.keys
, we see the following:
// typescript/lib/lib.es5.d.ts
interface
Object
{
keys
(
o
:
object
)
:
string
[
]
;
}
The type definition is very simple. Accepts
object
and returns
string[]
.
Making this method accept a generic parameter of
T
and return
(keyof T)[]
is very easy.
class
Object
{
keys
<
T
extends
object
>
(
o
:
T
)
:
(
keyof
T
)
[
]
;
}
If
Object.keys
were defined like this, we wouldn’t have run into the type error.
It seems like a no brainer to define
Object.keys
like this, but TypeScript has a good reason for not doing so. The reason has to do with TypeScript’s
structural type system
.
Structural typing in TypeScript
TypeScript complains when properties are missing or of the wrong type.
function
saveUser
(
user
:
{
name
:
string
,
age
:
number
}
)
{
}
const
user1
=
{
name
:
""Alex""
,
age
:
25
}
;
saveUser
(
user1
)
;
// OK!
const
user2
=
{
name
:
""Sarah""
}
;
saveUser
(
user2
)
;
//
Property 'age' is missing in type { name: string }.
const
user3
=
{
name
:
""John""
,
age
:
'34'
}
;
saveUser
(
user3
)
;
//
Types of property 'age' are incompatible.
//
Type 'string' is not assignable to type 'number'.
However, TypeScript does
not
complain if we provide extraneous properties.
function
saveUser
(
user
:
{
name
:
string
,
age
:
number
}
)
{
}
const
user
=
{
name
:
""Alex""
,
age
:
25
,
city
:
""Reykjavík""
}
;
saveUser
(
user
)
;
// Not a type error
This is the intended behavior in structural type systems. Type
A
is assignable to
B
if
A
is a superset of
B
(i.e.
A
contains every property in
B
).
However, if
A
is a
proper
superset of
B
(i.e.
A
has
more
properties than
B
), then
A
is assignable to
B
, but
B
is not assignable to
A
.
Note:
In addition to needing to be a superset, property-wise, the types of the properties also matter.
This is all quite abstract, so let’s take a look at a concrete example.
type
A
=
{
foo
:
number
,
bar
:
number
}
;
type
B
=
{
foo
:
number
}
;
const
a1
:
A
=
{
foo
:
1
,
bar
:
2
}
;
const
b1
:
B
=
{
foo
:
3
}
;
const
b2
:
B
=
a1
;
const
a2
:
A
=
b1
;
//
Property 'bar' is missing in type 'B' but required in type 'A'.
They key takeaway is that when we have an object of type
T
, all we know about that object is that it contains
at least
the properties in
T
.
We do
not
know whether we have
exactly
T
, which is why
Object.keys
is typed the way it is. Let’s take an example.
Unsafe usage of
Object.keys
Say that we’re creating an endpoint for a web service that creates a new user. We have an existing
User
interface that looks like so:
interface
User
{
name
:
string
;
password
:
string
;
}
Before we save a user to the database, we want to ensure that the user object is valid.
name
must be non-empty.
password
must be at least 6 characters.
So we create a
validators
object that contains a validation function for each property in
User
:
const
validators
=
{
name
:
(
name
:
string
)
=>
name
.
length
<
1
?
""Name must not be empty""
:
""""
,
password
:
(
password
:
string
)
=>
password
.
length
<
6
?
""Password must be at least 6 characters""
:
""""
,
}
;
We then create a
validateUser
function to run a
User
object through these validators:
function
validateUser
(
user
:
User
)
{
// Pass user object through the validators
}
Since we want to validate each property in
user
, we can iterate through the properties in
user
using
Object.keys
:
function
validateUser
(
user
:
User
)
{
let
error
=
""""
;
for
(
const
key
of
Object
.
keys
(
user
)
)
{
const
validate
=
validators
[
key
]
;
error
||=
validate
(
user
[
key
]
)
;
}
return
error
;
}
Note:
There are type errors in this code block which I’m hiding for now. We’ll get to them later.
The problem with this approach is that the
user
object might contain properties not present in
validators
.
interface
User
{
name
:
string
;
password
:
string
;
}
function
validateUser
(
user
:
User
)
{
}
const
user
=
{
name
:
'Alex'
,
password
:
'1234'
,
email
:
""
[email protected]
""
,
}
;
validateUser
(
user
)
;
// OK!
Even though
User
does not specify an
email
property, this is not a type error because structural typing allows extraneous properties to be provided.
At runtime, the
email
property will cause
validator
to be
undefined
and throw an error when invoked.
for
(
const
key
of
Object
.
keys
(
user
)
)
{
const
validate
=
validators
[
key
]
;
error
||=
validate
(
user
[
key
]
)
;
//
TypeError: 'validate' is not a function.
}
Luckily for us, TypeScript emitted type errors before this code had a chance to run.
for
(
const
key
of
Object
.
keys
(
user
)
)
{
const
validate
=
validators
[
key
]
;
//
Expression of type 'string' can't be used to index type '{ name: ..., password: ... }'.
error
||=
validate
(
user
[
key
]
)
;
//
Expression of type 'string' can't be used to index type 'User'.
}
We now have our answer for why
Object.keys
is typed the way it is. It forces us to acknowledge that objects may contain properties that the type system is not aware of.
With our newfound knowledge of structural typing and its pitfalls, let’s take a look at how we can effectively use structural typing to our benefit.
Making use of structural typing
Structural typing provides a lot of flexibility. It allows interfaces to declare exactly the properties which they need. I want to demonstrate this by walking through an example.
Imagine that we’ve written a function that parses a
KeyboardEvent
and returns the shortcut to trigger.
function
getKeyboardShortcut
(
e
:
KeyboardEvent
)
{
if
(
e
.
key
===
""s""
&&
e
.
metaKey
)
{
return
""save""
;
}
if
(
e
.
key
===
""o""
&&
e
.
metaKey
)
{
return
""open""
;
}
return
null
;
}
To make sure that the code works as expected, we write some unit tests:
expect
(
getKeyboardShortcut
(
{
key
:
""s""
,
metaKey
:
true
}
)
)
.
toEqual
(
""save""
)
;
expect
(
getKeyboardShortcut
(
{
key
:
""o""
,
metaKey
:
true
}
)
)
.
toEqual
(
""open""
)
;
expect
(
getKeyboardShortcut
(
{
key
:
""s""
,
metaKey
:
false
}
)
)
.
toEqual
(
null
)
;
Looks good, but TypeScript complains:
getKeyboardShortcut
(
{
key
:
""s""
,
metaKey
:
true
}
)
;
//
Type '{ key: string; metaKey: true; }' is missing the following properties from type 'KeyboardEvent': altKey, charCode, code, ctrlKey, and 37 more.
Ugh. Specifying all 37 additional properties would be super noisy, so that’s out of the question.
We could resolve this by casting the argument to
KeyboardEvent
:
getKeyboardShortcut
(
{
key
:
""s""
,
metaKey
:
true
}
as
KeyboardEvent
)
;
But that could mask other type errors that may be occuring.
Instead, we can update
getKeyboardShortcut
to only declare the properties it needs from the event.
interface
KeyboardShortcutEvent
{
key
:
string
;
metaKey
:
boolean
;
}
function
getKeyboardShortcut
(
e
:
KeyboardShortcutEvent
)
{
}
The test code now only needs to satisfy this more minimal interface, which makes it less noisy.
Our function is also less coupled to the global
KeyboardEvent
type and can be used in more contexts. It’s much more flexible now.
This is possible because of structural typing. A
KeyboardEvent
is assignable to
KeyboardShortcutEvent
because it is a superset, even though
KeyboardEvent
has 37 unrelated properties.
window
.
addEventListener
(
""keydown""
,
(
e
:
KeyboardEvent
)
=>
{
const
shortcut
=
getKeyboardShortcut
(
e
)
;
// This is OK!
if
(
shortcut
)
{
execShortcut
(
shortcut
)
;
}
}
)
;
This idea is explored in this fantastic post by Evan Martin:
Interfaces generally belong with users
. I highly recommend giving it a read! It changed how I write and think about TypeScript code.
This post generated
a lot of interesting discussions on Hacker News
. If this post was interesting, I recommend taking a look.
Mailing list
To be notified of new posts, subscribe to my mailing list.
Subscribe","June 24, 2023"
The Engineering behind Figma’s Vector Networks,"Adobe Illustrator introduced the pen tool back in
1987
as a tool for creating and modifying paths. Since then the pen tool has become incredibly widespread, so much so that is has become the de facto icon of the graphic design industry.
The pen tool’s functionality hasn’t changed significantly in the 30 years since its introduction. Just click and drag to create smooth curves. Designers have learned to work with it, and around its idiosyncrasies.
The pen tool
But Figma felt like they could improve some aspects of how the pen tool worked, so they had a go at redesigning it. Instead of it being used to work with traditional paths, they improved the pen tool by creating what they call Vector Networks.
In this post we will go through what Vector Networks are and what problems they try to solve. After we’ve defined what Vector Networks are, we will take a look at some of the engineering challenges you would face if you were to take a stab at implementing them.
This post can be thought of as an introduction to a really interesting problem space, and as a resource for people interesting in making use of some aspects of Vector Networks for future applications. I hope it succeeds in providing value to both developers being introduced to new concepts and ideas, and to designers interesting in learning more about the tool they know and love.
I will start off by laying out the core concepts behind the pen tool, and from there we will move onto Figma’s Vector Networks.
Paths
The pen tool is used to create and manipulate paths.
If you’ve every worked with graphics software like
Illustrator
before, you’ve worked with paths. Paths are a series of lines and curves that may or may not form a loop.
Some paths
The path to the left loops, while the path to the right doesn’t. Both of these are valid paths.
The main characteristic of paths is that they form a single continuous unbroken chain. This means that each node can only be connected to one or two other nodes.
Not valid paths
However, you could construct these shapes from multiple paths if you position them correctly together.
Multiple paths are used to create more complex shapes
From a combination of paths, you can create any shape imaginable.
This beer glass, for example, is just a combination of five different paths positioned and scaled a certain way.
The building blocks of paths
A path is made up of two things, points and lines.
Points and lines
The points are known as
nodes
(or vertices) and the lines are called
edges
.
Together, they make a path
Any path can be described as a list of nodes and edges.
This path can be described as the series of nodes
(0, 1, 2, 3, 4)
. It could also be thought of as the series of the edges that composed it. That list of edges would be
(0, 1)
,
(1, 2)
,
(2, 3)
,
(3, 4)
,
(4, 0)
.
You can think of this like the
dot to dot puzzles
that you used to do as a kid: Draw the edges of the path in the order that the points lay out.
But instead of a kid drawing lines between numbered points on a paper, a cold calculating machine does it along the cartesian coordinate system.
Edges
An edge is a connection between a pair of nodes. Visually, edges are a line from node
a
to node
b
.
But that line can be drawn in a lot of different ways. How do you describe those different types of lines?
Edges fall into two categories, straight and curvy.
Straight edges are as simple as they seem, just a line from
a
to
b
. But how are those curvy edges defined?
Bezier curves
Curvy edges are
bezier curves
. Bezier curves are a special type of curve defined by four points.
The positions of the two nodes in our edge make up the start and end points of the curve. Each of the two nodes has a
control point
.
In most applications, these control points are shown as
handles
that extend from their respective node. These handles are used to control the shape of the curve.
Bezier curves can be chained to make more complex shapes that a single curve can’t draw on its own. They can also be combined with straight lines to make some cool designs.
But what exactly are the handles doing? How do the handles tell the computer to draw the curve like it does?
Computers draw curves by splitting them into straight lines and drawing the individual lines.
The more lines you split a curve into, the smoother the curve becomes.
So to draw the curve we need to know how to get the different points that make up the curve. If we compute enough of them, we get a smooth curve.
Computing a point on a bezier curve
Let’s compute the point at 25% point of the curve. We can start by connecting the control points with a third blue line.
Then for each blue line, we draw a blue dot at the 25% point of the line.
Next, draw two green lines between the three blue dots.
And we repeat the same step as we did with the blue dots. Draw green points at the 25% points of the green lines.
And then one more red line between the newly created green points.
Then we add a red point at the 25% point of the red line.
And just like that, we’ve computed the point at the 25% point of the curve.
From now on we’ll refer to points on curves through a
t
value, where
t
is a number from
0
to
1
. In the above example, the point would be at
t=0.25
(25%).
t=0.25, t=0.5 and t=0.75
This way of computing the point at
t
is called
De Casteljau’s algorithm
and can also be used to subdivide a bezier curve. Using the points we created along the way, we can also subdivide the bezier curve into two smaller bezier curves.
Bezier curves are pretty amazing things. Shaping the curve by adjusting the handles feels surprisingly natural, and chaining them together allows you to create detailed and complex shapes.
And for computers, they’re stable and inexpensive to compute. For this reason they’re used for everything from
vector graphics
to
animation curves
and
automobile bodies
.
You can see an interactive demo of bezier curves at
Jason Davies’ site
. It’s fascinating to watch a series of straight lines trace out a smooth curve.
From
https://jasondavies.com/animated-bezier
The creative constraints of paths
Earlier in this post, paths were defined as a continuous series of lines and curves that may or may not form a loop.
The fact that paths are a single continuous chain is a pretty big limitation.
It means three way intersections are not possible using a single path. To create a three way intersection, two or more paths will have to be used. This means dealing with positioning and grouping different paths together. It also means that changes to a single path can lead to changes to multiple other paths.
But that’s simply the routine. Seasoned designers know how paths behave, they can plan around it without really thinking about it. For a static design it doesn’t really matter how many paths and layers you have to create if the piece is planned properly upfront.
But for some situations the constraints that paths impose cause a lot of friction.
Vector Networks
In 2016, Figma
introduced Vector Networks
. They lift the “single continuous” limitation by allowing any two nodes to be joined together without restrictions.
“A vector network improves on the path model by allowing lines and curves between any two points instead of requiring that they all join up to form a single chain.”
Source:
https://www.figma.com/blog/introducing-vector-networks/
The cube is the quintessential example for demonstrating Vector Networks.
Via traditional paths, you would have to create at minimum 3 different paths to describe this shape.
This creates a lot of friction for a seemingly simple and common shape. To modify the cube, you would have to modify two or three different paths. But with Vector Networks you can simply grab an edge and move it around, and the shape behaves like you would expect.
So if you would want to increase the extrusion of the cube, you could just grab the two appropriate edges and move them together.
This is the big selling point for Figma’s Vector Networks. Ease of use.
Vector Networks don’t enable you to create something that you couldn’t create with other tools, but it does remove a lot of the friction in the process of creating things.
And you can take this even further. Say you want to add a hole to the side of the cube.
Just start off by selecting and copying the sides of the cube. You can then duplicate those edges and scale them to the size you want them to be.
And just like that, you have a cube with a hole.
And to make this hole believable, you just need the inner edge.
Again, Vector Networks may not allow you to create something you couldn’t otherwise. Instead, they enable workflows that weren’t previously possible.
Creating Vector Networks
With an understanding of what Vector Networks are, we can now take a look at how we would go about implementing them.
Graph
The main data structure behind Vector Networks is a graph. A graph can be thought of as a collection of nodes and edges.
A graph
Nodes
A graph may have any number of nodes. For our purposes nodes have two properties, a unique
id
and a
position
.
Edges
Edges are the connection between two nodes. Each edge is a composed of two
edge parts
. An edge part contains a node’s id and an optional control point.
The labels
n0
and
n1
will be used to refer to the nodes at the start and end of an edge, respectively. The control points will be labeled
cp0
and
cp1
.
If the control points of the edge are omitted, the edge becomes a straight line.
Filling the holes
Source:
https://www.figma.com/blog/introducing-vector-networks/
When working with vector networks, the Fill tool allows you to “toggle” the fill of different “areas” of the graph.
These areas can be defined as a sequence of node
id
s that go in a circle, a loop, if you will.
This loopy sequence is referred to as a
cycle
. In the above example, the cycle would consist of the nodes
n0
,
n1
,
n3
,
n4
,
n5
,
n6
and
n7
. These cycles will be written like
(0, 1, 3, 4, 5, 6, 7)
.
If you were to count the different visually distinct “areas” of the cycle your answer would probably be three, but you could easily find more than three cycles.
What makes this correct or incorrect?
The sequence
(0, 1, 2, 3, 4, 5, 6, 7)
is a cycle and it loops, but it is not what we’re looking for. The problem can be illustrated with the “how many triangles” puzzle you might have seen on Facebook.
How many triangles are in this image?
You should be able to count 24 different triangles depending on which areas you choose to include.
But that’s not what we want. What we need to find are the 16 small areas.
We need a way to find the
“small cycles”
in the graph.
Minimal cycle basis
This
paper on Minimal Cycle Basis
is a bit less dense than most others academic papers (and it has pictures!). Its goal is:
…to compute a minimal number of cycles that form a cycle basis for the graph.
What does “Minimal Cycle Basis” mean?
It’s just a fancy way to refer to all of the “small areas” of a graph. You can think of these as the “visually distinct” areas of a graph. Enclosed areas.
Left or right?
The main tool for finding the “minimal cycle basis” will be determining which edge to choose based on left- or rightness.
Should we go to
a
or
b
?
We’ll think of this in terms of clockwise and counter clockwise.
curr
for current,
prev
for previous
When traveling left, we choose the counter clockwise most edge (CCW) relative to the previous one.
CCW
When traveling right, we choose the clockwise most edge (CW) relative to the previous one.
CW
The algorithm
We will be finding the minimal cycle basis for the graph we saw earlier.
The first step is choosing the leftmost node in the graph.
When traveling from the first node, we want to go clockwise (CW). But relative to which edge?
For the first node, we imagine that the previous edge is “below” the current one. We then pick the CW edge relative to that.
In this case
a
is more CW relative to
prev
than
b
, so we’ll walk to
a
.
After the first walk, we start picking the CCW edge.
In this case, that’s
b
. We repeat the previous step and keep selecting the CCW edge until we reach the original node.
When we reach the original node again, a cycle is found.
We now have the first small cycle in the graph.
When a cycle has been found, the first edge of the cycle is then removed from the graph.
The first edge,
(n0 n1)
, is removed
Then, the
filaments
of the first two nodes in the cycle are removed.
In this case, we only have a single filament
Filaments are nodes that only have one adjacent edge. Think of these as dead ends. When a filament is found, we also check whether or not the single adjacent node is a filament. This ensures that the first node of the next cycle has two adjacent nodes. We’ll see an example of this later.
Now we pick the first node in the next cycle. In our graph, there are two equally left most nodes.
When this happens, we pick the bottom node,
n1
in this case.
We then repeat the process from before. CW from the bottom for the first node, then CCW from the previous node until we find the first node.
We find the cycle
(1, 2, 3)
.
Now we have the cycles
(0, 1, 3, 4, 5, 6, 7)
and
(1, 2, 3)
.
Then we remove the first edge of the cycle and filaments like before. We start by removing the filaments connected to the first two nodes of the cycle.
We keep going until there aren’t any filaments left.
Finding the next cycle is pretty obvious.
CW then CCW
We now have all the cycles of the graph.
This is the minimal cycle basis of our graph! Now we can toggle the fills of these cycles as we please.
The math
I want to dig into how the clockwise-ness of an edge relative to another edge is determined.
The only prerequisite for understanding this section are
vectors
; arrows pointing from one point of a 2D coordinate system to another.
i = (1, 0), j = (0, 1)
With two vectors sitting at the origin,
i
and
j
, we can create a square like so.
For the unit vectors
(1, 0)
and
(0, 1)
the square has an area of 1.
We can do this with any two vectors.
This shape is called a
parallelogram
. Parallelograms have one property that we care about, which is that their area is equal to the absolute value of their determinant.
That may sound like jargon, but the determinant happens to be really useful for us. Take a look at what happens when we move the vectors of the one-by-one square closer together.
When the vectors get closer, their area gets smaller. And when the vectors are parallel, the determinant and area become 0.
At this point the natural question to ask is what happens when we keep going and the blue arrow is to the right of the green arrow?
The determinant becomes negative!
When the blue vector
j
is to the left of the green vector
i
the determinant of the parallelogram becomes negative. When the opposite is true it becomes positive.
The implication for our use case is that we can check whether the determinant of two vectors is positive or negative to determine whether or not a vector is to the left or right of another vector.
And we can do this no matter the direction because the area of a parallelogram does not change depending on the orientation of the vectors that create it.
The determinant changes when the orientation of the vectors change
relative to each other
.
With this knowledge as our weapon, we can create a function,
det(i, j)
, that takes in two vectors and returns the determinant.
The function will return a positive value when
j
is to the left (CCW) of
i
.
Applying the math
Say we’re in the middle of the finding a cycle and we’re deciding whether or not to move to
n0
or
n1
.
Let’s move this into the coordinate system.
We’ll start off with
a
.
We want to get the vector from
curr
to
a
, which we do by subtracting
curr
from
a
. We’ll call this new vector
da
.
We can do the same for
curr
using
prev
.
Now we can determine whether
a
is left of
curr
by computing the determinant of the parallelogram that
da
and
dcurr
form.
Note that the order is important. If we use
da
as
i
the area is negative. If we use it as
j
it becomes positive.
We can do the same with
b
.
With this information as our weapon, we know whether or not
a
,
b
and
curr
are left or right of each other.
What do we do with this information?
The green zone
We will be focusing on determining whether
da
is more CCW than
db
relative to
curr
. Simply put, is
da
left of
db
?
If
da
is more CCW than
db
relative to
dcurr
,
da
can be said to be
better
than
db
.
The first step is to determine whether the angle between
dcurr
and
db
is convex.
This “convexity” can more easily visualized by shifting
dcurr
back and imagining an arc like so:
The angle is convex
If the angle is convex, we we use the following expression to check whether
da
is better than
db
.
The ∨ symbol represents the logical OR operator in math.
Let’s take a look at the individual parts of this expression.
Is
da
CCW of
dcurr
?
Is
da
CCW of
db
?
I find that it’s pretty hard to visualize this mentally, so I think of the two different expressions creating a “green zone” where
da
is better than
db
.
For the first part of the expression (is
da
left of
dcurr
), the green area looks like so.
The second part of the expression asks if
da
is left of
db
. The green area look looks like so.
And since it’s an OR expression, either of these sub-expressions being true would result in
a
being better than
b
. Thus, the green area looks like this:
Is
a
better than
b
?
We use this to determine the better-ness of
a
when the angle is convex.
But what if the angle from
dcurr
to
db
is concave?
Then the expression looks like so:
The only thing that changed here is that the logical OR operator (∨) changed to the logical AND operator (∧).
Let’s take a look at what happens with the green zones using this expression.
Is
da
left of
dcurr
?
Is
da
left of
db
?
And since these sub-expressions are joined by logical AND, the green zone looks like so:
Using this method, we can always get the CCW or CW most node. And the great thing is that this method is independent of rotation and really cheap to compute.
Computing the determinant
Given two vectors, the
determinant
can be computed with this formula:
Intersections in the graph
Let’s go back to our graph for a bit.
This graph is the simplest, most optimistic case. This graph only has straight lines, and no two lines cross each other.
This box shape has an intersection. The edge
(0, 2)
crosses the edge
(1, 3)
.
With the intersection, the above area looks fillable. But defining the “filled area” is pretty difficult.
What makes defining this area so difficult? Consider this rectangle and line.
There are two intersections with the edge
(4, 5)
intersecting
(0, 1)
and
(2, 3)
.
Say the area left of the line is filled. What happens if we move the line left?
Obviously the area shrinks, but what if we keep going and move the line outside of the rectangle? Which of these outcomes below should be the result, and why?
In this case kinda feels like the rectangle should be empty. But what if we move the line right?
Should it then be filled? Sure, but what if we move the line up or down instead? Should the rectangle fill or empty when the line is no longer separating the two sections?
Expanding the graph
This is how I believe Figma solves this problem. I call it “expanding the graph”, but the engineers at Figma probably use a different vocabulary to describe it.
Expanding the graph means taking each intersection, creating a node at the point of the intersections, and then splitting the edges that intersected each other at that point.
This is the original graph:
The edge
(0, 2)
intersects the edge
(1, 3)
. When expanded, the graph would look like so:
A new node,
5
would be added at the point of the intersection.
The edges
(0, 2)
and
(1, 3)
have been removed and replaced by the edges
(0, 5)
,
(5, 2)
,
(1, 5)
, and
(5, 3)
.
The structure of the graph has been changed
Here’s a graphic that should illustrate this a bit more clearly.
Expanding an intersection
Multiple intersections
These steps are pretty simple for line edges with a single intersections. But each edge can have multiple other edges intersecting it, and two cubic bezier curves can create 9 intersections.
This complicates things a bit. Let’s take a look at a bezier-line intersection.
The best way to go about this is to treat the intersections for an edge as separate from the edge that intersected it.
The
t
values go from 0 at the start of the curve to 1 at the end of it
The line has two intersections at
t = 0.3
and
t = 0.7
. The bezier has two intersections, but at
t = 0.25
and
t = 0.75
.
Before we move on with this example, I want to introduce a different way of thinking about edges since I believe it will help with the overall understanding of the problem.
Duplicate edges
Two nodes may be connected multiple times by different edges.
In this graph, an edge represented by the node pair
(2, 3)
could represent either of the two edges that connect
n2
and
n3
.
To get around this problem, we will give each edge a unique
id
.
For most future examples, I will still refer to edges by the nodes they connect since I feel it’s easier to think about. But for the next example it’s better to separate nodes and edges.
Intersection map
We can structure the data for the intersections of the edges like so:
Creating nodes at the intersection points of edges
When we encounter an intersection, we create a node whose position is at the intersection. We then add intersections to an
intersection map
that will contain the intersections for each edge with a corresponding
t
value and a
nodeId
. These intersections are sorted by the
t
value.
For the intersection with the lowest
t
value, we create an edge with the first
edge part
having the
nodeId
of the first edge part of the original edge. The second edge part should contain the
nodeId
of the intersection. This creates the edge
(2, 4)
.
Subsequent edges will have the first edge part’s
nodeId
be the
nodeId
of the previous intersection and the second
nodeId
be the
nodeId
of the current intersection. In this example, that edge is
(4, 5)
.
One additional edge will be created for each edge with any intersections.
The first edge part’s
nodeId
will be the
nodeId
of the last intersection and the second edge part’s
nodeId
will be the
nodeId
of the second edge part of the original edge.
This was a bit of a mouthful, so hopefully this graphic helps a bit with understanding that alphabet soup.
Separating the intersections of an edge from the edges that created those intersections makes it easier to think about. It alleviates some of the complexity that might arise from multiple edges intersecting with each other.
Self-intersection
Cubic beziers can self-intersect.
This, unfortunately, means that every single cubic bezier edge has to be checked for self-intersection. It’s an interesting problem that involves finding the two different
t
values that the bezier intersects itself at, but I won’t be covering how to find those values here.
Once you have the
t
values, a self-intersecting bezier can be expanded like so:
The blue node should be invisible to the user
We insert
n3
since having a node with an edge that has itself on both ends of the edge is problematic, but it should be hidden from the user.
Intersecting the loop of a self-intersecting bezier
Removing n3 at the first opportunity
Curvy edges
Earlier we covered the CW - CCW graph traversal algorithm to find the minimal cycle basis (small areas).
Finding the better (counter clockwise most) point adjacent to
curr
But the algorithm described in the paper was designed to work with nodes connected by straight lines that don’t intersect. Introducing edges defined by cubic beziers introduces significant complexity.
Which edge to choose, blue or green?
In the example above, we can find out that the blue edge is better than the green one by using the determinant. We are stilling defining better to mean the CCW most edge.
When working with cubic bezier curves, the naive solution would be to just convert the bezier to a line defined by the points at the start and end of the curve.
But that idea breaks down as soon as one edge curves over the other.
Oops
Let’s take a fresh look at a bezier curves and try to work from there.
Looking at this, we notice that the tangent at the start of the curve,
n0
, is parallel to the line from
n0
to
cp0
. So to get the direction at the start of the edge we can use the line
(n0, cp0)
.
For clarity, the start of our edge,
n0
, is the same node as
curr
.
So by converting edges defined by cubic beziers into a line defined by
(n0, cp0)
, we get the
initial
angle of the curve.
This seems like a good solution when looking at the “curve around” case.
Looks like we’ve solved the problem. Right?
No intersections
Before we move on to further edge cases, it helps to understand that any solutions assume that no two edges may intersect when deciding which edge to travel.
This is not allowed
The edges of the graph we’re traversing must not have any intersections when we compute the cycles (minimal cycle basis) of the graph.
We can only operate on an
expanded graph
.
Like we covered earlier, an expanded graph is a graph that has replaced all intersections with new nodes and edges. So if the original, user-defined graph has any intersections, they would have to be expanded before we can find the graph’s cycles.
The same edges as above, but expanded
Parallel edges
The next edge case is two edges being parallel (pointing in the same direction).
If the lines go in the same direction, determining which is better is impossible without more information.
Here are a few possible solutions for the cases where the control points of the curves are parallel.
Point at
t
What if we just take the point on the curve at, for example,
t = 0.1
?
This produces the correct result for curves of a similar length, but we can easily break this with one curve being significantly bigger than the other.
This is effectively the same problem as the “curve around” case we saw earlier.
Point at length
Instead of taking a point at a fixed
t
value, we could take a point at some length along the curve. The length would be determined by some point on the smaller curve, e.g. at
t=0.1
.
I have not tried implementing this since I have another working solution, but this could possibly be a viable and performant solution if it works for all edge cases.
Lasers!
The next solution is a bit esoteric but produces the correct result. This is the solution I’m currently using.
We begin by splitting each bezier at
t = 0.05
(image above is exaggerated). We then tesselate each part into n points.
Then, for each point of the tesselated bezier, we check whether a line from
n0
to that point intersects the other edge.
It’s pretty hard to see what’s going on at this scale, so let’s zoom in a bit.
When a point intersects the other edge, we use the point before it.
Found an intersection
Let’s zoom in a bit.
The intersection close up
For the other edge, we have no intersection.
In that case, we just use the end of the edge as the direction line.
With this method we’ve produced lines that seem to represent their respective curves.
And this also works for the “curve around” case.
But it fails for a “curve behind” case.
This would produce the green edge as the more CCW edge, which is wrong.
My solution to this problem is to shoot an infinite laser in the direction of the previous edge.
We then check whether the points of the tesselated bezier intersect this laser.
But a line from
n0
to the points would never intersect the laser.
Passes right through
Instead, we can create a line from the current point to the previous point and use that for the intersection test.
When we intersect the laser, we use the previous point. The previous point will always be on the correct side of the laser.
The point we use
And like that, we have a solution.
Parallel, but in reverse!
It could also be the case that the blue or green edges,
a
and
b
respectively, could be parallel to the edge from
curr
to
prev
.
a
is parallel to
prev
The process for finding the better edge follows a process similar to the one described above so we will cover this very quickly.
There are two cases:
A or B are parallel to
Prev
, but not both
If either
a
or
b
, but not both, are parallel to
prev
, we can simply compare the parallel edge to
prev
.
If the parallel edge is CW of
prev
, the parallel edge is better.
If the parallel edge is CCW of
prev
, the other edge is better.
Think a bit about why this is true.
If one edge is parallel to
prev
and curves CW, and the other is not parallel to
prev
, then the parallel edge is as CCW as can be. This means that the green zone for the other edge is completely empty.
The reverse is true if the parallel edge curves CCW, since it would be as CW as possible. This means that the green zone for the other edge is the whole circle.
Both A and B are parallel to Prev
Using the same laser solution as before, this case is covered.
Cycles inside of cycles
Now we’re going to look at fills for a bit.
Let’s take a look at a basic example of a graph with a cycle inside of another cycle.
You would expect the graph’s areas to be defined like so:
But as it stands, if you hover over the outer area you get a different, unsatisfactory result.
But this makes sense. Let’s take a look at the nodes of the graph.
The cycle
(0, 1, 2, 3)
describes the outer boundary of the area we want, but we aren’t describing the “inner boundary” of the area yet.
Let’s take a look at how we can do that.
Even-odd rule
Telling a computer to draw the outline of a 2D shape is simple enough. But if you want to fill that shape, how do you tell the computer what is “inside” and what is “outside”?
One way of finding out whether a point is inside a shape or not is by shooting an infinite laser in any direction from that point and counting how many “walls” it passes through.
If the laser intersects an odd number of walls, it’s inside of the shape. Otherwise it is outside of the shape.
Intersects 1 wall, we’re inside of the shape
Intersects 4 walls, we’re outside of the shape
This works for any 2D shape, no matter which point you choose and which direction you shoot the laser in.
This also helps in the case of nested paths.
This gives us an idea for how we can define the “inner boundary” of a shape.
Reducing closed walks
Let’s look at a graph with a cycle nested inside of another cycle, but with an edge connecting two nodes of the cycles.
This will lead back to how we can think about nested cycles and give us a deeper understanding on how to think about them.
Let’s find the cycles. We use the same CW-CCW method as usual.
With this method, we go on what looks like a small detour around the inner cycle.
When we reach the node we started at, this is what the cycle looks like.
This is the first cycle we’ve seen where we cross a node twice (both
n3
and
n4
). Something interesting appears when we take a look at the direction that the cycle takes throughout the graph.
We start off traveling CCW, but when we cross the edge from the outer cycle to the inner cycle the orientation we travel seems to flip.
I will state for now that we want to separate the outer cycle from the inner cycle and treat the edge between them as if it didn’t exist. I will go into the
why
later and explain the
how
here.
We take all repeated nodes, in this case
n3
, and remove them from the cycle. We also remove any nodes that are between the two repeated nodes.
You might notice that
n4
is also repeated, but since it’s “inside” of the part of the cycle that
n3
removes, we can ignore it.
We leave one instance of the repeated node, and then we have the cycle that would have been found if the
crossing
didn’t exist.
We then mark the edge that connected the outer cycle from the inner cycle. I call these marked edges
crossings
.
It could also be the case that an outer-inner cycle combo has multiple crossings.
In that case, we mark all edges adjacent to the node connected to the outer cycle as a crossing.
And after all this is done, our cycles look like so:
Subcycles
Instead of referring to “inner” and “outer” cycles, I will refer to subcycles and parent cycles. This will make it easier to think about multiple cycles relative to each other.
Having said that, let’s introduce a third cycle.
When we hover over the outermost cycle, what do you expect to happen?
Because of the even-odd rule, the innermost cycle is filled too!
To fix this, we can introduce the concept of
direct subcycles
.
Parent cycles (blue) and their direct subcycles (green)
A parent cycle may have multiple direct subcycles. But due to the non-intersection rule, a subcycle may only have a single parent cycle.
Let’s take a look at how this works.
This graph has a a rectangle, our outermost cycle, which has two direct subcycles: a diamond and an hourglass. The diamond has two direct subcycles of its own, and the hourglass has three direct subcycles.
We will begin with the rectangle and its direct subcycles. We will name them,
c0
,
c1
and
c2
.
The user has decided to fill some of these cycles, and leave some of them empty.
c0
and
c1
are filled, and
c2
is empty
Let’s draw the graph without a stroke and with a gray fill. When drawing this graph we start with the outermost cycle,
c0
.
The graph to the left with the render to the right
Since
c0
is filled, we draw it. If it were not filled we could skip drawing it. We can shoot a laser out of the rectangle and see that it intersects the walls of the rectangle once, so we can expect it to be filled considering the even-odd rule.
This may seem really obvious, but it’s good to have the rules of the game laid out clearly before we move on.
Next we want to draw
c1
, the diamond in our graph. It was filled, just like the rectangle so we should draw it as well. But if we try to draw the diamond as well, we get the wrong result.
Our laser is intersecting two walls as a result of drawing both of the shapes when the have the same fill setting.
We intersect an even number of walls, so we’re “outside” of the shape
So to draw the image the user wanted we can simply skip drawing the diamond since the parent cycle implicitly draws direct subcycles with the same fill setting.
The hourglass,
c2
, is supposed to be empty. With that being the case, just not drawing it seems like a reasonable conclusion. But since the parent cycle (rectangle) has already drawn the hourglass as if it were filled we need to “flip” the fill by drawing the hourglass.
And again, if we try to use the laser intersection method we see that the number of intersections is 2, an even number. And with the even-odd rule, an even number of walls means you’re “outside” of the shape.
Now that we’ve drawn the rectangle and its direct subcycles, we can move onto the direct subcycles of those.
When working with
c3
and
c4
, the direct subcycles of
c1
, we can treat them as if they’re direct subcycles of
c0
since
c1
had the same fill setting.
For
c3
, we want to “flip” the fill setting so we draw it. But
c4
has the same fill setting as its parent cycle so we don’t draw it.
Even number of intersections so we’re outside of the shape
And we can think of
c5
,
c6
and
c7
in the same way. We don’t care whether they’re filled or empty when rendering them. We care whether or not they have the same fill as their parent cycle.
We only need to draw cycles if their parent cycle has the opposite “fill setting” as themselves. If they have the same fill setting, we don’t have to draw them.
This means that when drawing cycles, start by drawing the outermost “filled” cycle and then look at that cycle’s subcycles. If a subcycle has the same fill setting as its parent cycle, it should not be drawn.
Contiguous cycles
A graph may have multiple “clusters” of cycles.
I use the phrase
contiguous cycles
to describe the “togetherness” of the cycles, if you will. I often think of these contiguous groups of cycles as being in different colors.
Finding these contiguous cycles can be done with a depth-first traversal:
Start at the first node of the cycle
Color each node you find
But remember the
crossings
? In the search, you may not crawl to adjacent nodes by edges marked as crossings.
So in the end, our colors actually look like this:
Take this group of contiguous cycles nested inside another group of contiguous cycles:
Because of the non-intersection rule we know that if one of the nodes in a group of contiguous cycles is inside of a cycle not in the group, all of them are.
This “contiguous cycles” idea is maybe not the most interesting part of this post on the surface, but I’ve found it to be useful when working on Vector Networks.
Partial expansion
When hovering an area defined by intersections, we are showing a cycle of the expanded graph.
Take this triangle as an example.
If we hover over one of its areas, we see an area defined by nodes that don’t exist yet.
What the blue striped area represents is the area whose fill state would be “toggled” if the user clicks the left mouse button. This area does not exist on the graph as the user defined it. It exists as a cycle on the expanded version of the original graph.
The expanded graph
When the user clicks to toggle the fill state of the area, we would first have to expand the graph for the nodes and edges that make up that area to exist.
The expanded graph
But by doing that we’ve expanded two intersections that we didn’t need to expand to be able to describe the area. These expansions are destructive in nature and should be avoided when possible.
Instead, we can
partially expand
the graph by only expanding the intersections that define the selected cycle.
Partially expanded graph
This allows us to maintain as much of the original graph as possible while still being able to define the fill.
Implementing partial expansions
The basic implementation is reasonably simple. When you create the expanded graph, just add a little metadata to each expanded node that tells you which two edges of the original graph were used to create it and at what
t
values those intersections occurred.
Then when the cycle is clicked, iterate over each node. If the node exists in the expanded graph but not the original graph, add it to a new partially expanded graph.
There are edge cases, but I will not be covering them here.
Omitted topics
Here are some of the topics that I decided to omit for this post. Go have a stab at them yourself!
Joins
Figma offers three types of joins. Round, pointy and square. How could these different types of joins be implemented?
Stroke align
Figma also offers three ways to align the stroke of a graph: center, inside and outside.
How do you determine inside- or outside-ness and what happens when the graph has no cycles?
Boolean operations
Figma, like most vector graphics tools, offers
boolean operations
. How could those be implemented?
Paper.js
is open source and has boolean operations for paths, maybe you can start there?
Future topics
These are some of the more open-ended features and ideas I want to explore in the future.
A different way of working with fills
There are alternatives to how Figma allows the user to work with fills.
One possible solution I’m interested in exploring is multiple different “fill layers” that use one vector object as a reference. This would solve the “
one graph, multiple colors
” problem without having to duplicate the layer and keep multiple vector objects in sync if you want to make changes later on.
Animating the graph
Given an
expression
and reference based system similar to After Effects, what could you achieve when you combine it with Vector Networks?
Or maybe we could make use of a node editor similar to
Blender’s shader editor
or
Fusion’s node based workflow
?
There’s a lot of exploration to be done here and I’m really excited to dive into this topic.
In closing
Thanks for reading this post! I hope it served as a good introduction to what I think is a really interesting problem space. I’ve been working on this problem alongside school and work for a good while. It’s part of an animation editor plus runtime for the web I’m working on. I intend for a modified version of Vector Networks to be the core of a few features.
I’ve been working on implementing Vector Networks for a bit over half a year now. The vector editor is pretty robust when it comes to creating, modifying and expanding the graph. But the edge cases when modifying the fill state have been stumping me for quite a while now.
I wanted to have a fully working demo before publishing this post, but it’s going to be a few months until it’s stable enough for it to be usable for people that are not me.
The big idea behind the project is to be a piece of animation software that’s tailor-made for creating and running dynamic animations on the web. I’ll share more about this project at a later date.
I also just think that Figma’s Vector Networks are super cool and it’s really hard to find material about it online. I hope this post helps fix the lack of information that I encountered when attempting to find information about Vector Networks.
Mailing list
To be notified of new posts, subscribe to my mailing list.
Subscribe","Nov 24, 2019"
"Sharing changes, visuals first","Over the past year, I’ve shared much of my work at
Arkio
internally through so-called “release comics”. Here are some examples:
Examples of release comics I’ve shared within Arkio.
1
/
6
These release comics have been an effective medium for communicating changes. Their visual nature makes them really easy to understand at a glance.
The feedback I’ve gotten has been very positive.
In this post, I’ll explore this visual-first approach to sharing changes and discuss what makes it so effective. There’ll definitely be some ideas for you to take and apply to your own communication!
Prior state
To effectively evaluate and reason about a new feature, or a change to an existing one, you’d need to understand what motivated the addition of the feature in the first place. Was it added to work around some problem, or does it make some process more efficient? It helps to know.
So when communicating a change, present the state of affairs
prior
to your change. If you’re restructuring a key workflow, explain why the workflow exists and what wasn’t working about it before. It gives the audience a framework to reason about your changes.
In the release comics, I often present the prior state
—
and contrast it to the current state
—
via a before-after comparison.
I love using before-after comparisons
—
they’re such a simple model for communicating change.
Here’s how the thing didn’t work.
Here it is now, working!
Although the contrast is effective, before-after images don’t always provide enough context on their own. For that reason I usually share a short text description alongside the images, providing context and clarifying the scope of the change.
Still, the visuals are key. They make the context easier to grasp, so less text is needed. Glancing at an image is far more effortless than reading a text description.
Introducing new behavior
A before-after comparison is an obvious fit when changing existing behavior, and it can also be used to effectively present new behavior. Take the example below, which shows the addition of guide alignment under specific circumstances.
The prior image shows the user experience without the feature (guide alignment). Without guides, the user can try his best to align to the geometry, but will usually be slightly off. Quite frustrating.
The after image then shows how guides make aligning to existing geometry a breeze. When contrasted to the prior state, the value of the new behavior is easily understood.
Show, don’t tell
A few months after joining, I profiled editing in Arkio and noticed that calculating three-plane intersections constituted around 52% of the time spent when editing large geometries (geometry in Arkio is defined by planes and their intersections). Implementing the fast algorithm for three-plane intersections from
Real-Time Collision Detection
(chapter 5.4.5) resulted in those calculations becoming ~500% faster, which resulted in editing becoming ~72% faster.
One way of sharing the change would be to just state the raw numbers. Telling people that the change improves edit performance by ~72% certainly
sounds
technically impressive.
But what does that mean for users? Does the performance improvement translate to a better user experience?
To make the change palpable, I recorded a before/after video showing how the change nearly doubled the framerate when editing large objects.
Look at how much smoother the ‘After’ experience is!
I did share the numbers alongside the video, but without the video demonstrating the impact the numbers would have felt abstract.
Use multiple examples
Earlier this year I made a fairly simple change which was to scale measurement labels down when they were too large to fit the line that they describing (and fully hiding them when too small). It produced useful results in an array of circumstances, so I created multiple pictures to demonstrate:
1
/
3
The takeaway is fairly simple
—
if you’re presenting a change that is useful in multiple circumstances, demonstrate that using multiple distinct examples.
Annotations & illustrations
Last summer, I spent some weeks improving Arkio’s guide system. A big part of that work was reducing false-positive guides, i.e. not providing guides that are unhelpful.
One of the concrete changes I made was to disable guides whose origins are occluded. A person reading a description of that change
—
“Disabled guides whose origin is occluded.”
—
would reasonably ask what the “origin of a guide” is and what it means for it to be occluded. So when sharing that change, I illustrated the idea:
I think this quick and simple annotated image demonstrates the idea more efficiently than any text description can.
Using real screenshots is preferable, but those screenshots often benefit from augmentation
—
adding annotations to highlight areas, or diagrams to demonstrate an idea. Here are some more examples from my work on the guide system:
1
/
3
I frequently use annotations for emphasis. The annotations in the example below are not necessary to understand the idea, but they help emphasize it and make it incredibly effortless to understand.
These visuals make the changes immediately understood at a glance, whereas textual descriptions require more effort from readers. Most people will not need a deep technical understanding of your changes
—
they’ll appreciate being able to take a cursory glance at an image to get the general idea.
Actions
I represent actions by connecting the start and end states using an arrow. Here I contrast two start states and their respective end states using arrows:
I frequently pair actions with before-after comparisons. Here are some examples of before-after actions from my work on the wall tool for Arkio’s 2.0 release:
1
/
3
This is just one way to represent actions, but it’s worked quite well for me!
Other mediums
This “release comic” idea is tailored to a distributed working culture. However, many of the ideas at work translate well to other forms of communication, like my favorite, live demos!
In live demos, I find that presenters sometimes spend far too little time (if any) explaining the prior state, or explaining the context of what they’re presenting. When presenters go straight to showing off exactly how the thing they built works, it can leave the audience lost.
Side note: as an audience member, even if you have the full context, it can be helpful to ask prodding questions like
“Under what circumstances would this be used?”
. Getting the presenter to provide context is useful for everyone involved, and makes any post-demo discussions much more productive.
I also think that people should use far more annotations and diagrams than they currently do, whether in design documents or traditional presentations. Less text, more visuals!
—
They make absorbing ideas so much easier.
Final words
I’m hoping that me writing this will influence some people out there to take a more visual-first approach to communication.
I’ve found the release comics to aid other people’s understanding of my work, and the changes I’m making. They’re quick and fun to make, save other people effort, and they act as a very portable artifact for a piece of work!
Sharing changes visually will fit some projects and roles better than others. Still, see if you don’t find an opportunity to present your work visually!
—
Alex Harri
Mailing list
To be notified of new posts, subscribe to my mailing list.
Subscribe","Nov 9, 2024"
Searching for and navigating Git commits,"I sometimes encounter code that puzzles me. When that happens, I try to find the commit that added it. Perhaps the code is that way because of a bug fix that’s not obvious at a glance, or maybe there’s some constraint I’m not aware of. Either way, more context is needed.
The obvious solution is to use
Git blame
to view the commit (and associated pull request) that added the code.
The pull request often has a description (or a link to an issue with one) that clarifies the change, or discussions added during code review
—
those are super valuable! When that fails, the commit itself frequently contains related changes that provide context to the code.
But it’s not always that straightforward. Sometimes the commit that Git blame points to is not the change that introduced the behavior
—
like a refactor or formatting change. I used to solve this by repeatedly
git blame
ing and reading diff after diff, but that could become terribly laborious and time-consuming.
I recently encountered a particularly tough case where I got fed up and decided to find a better way. In this post, I’ll share the tools I found for effectively searching for and navigating through Git commits.
Running Git blame on a piece of code
Let’s say we have a mysterious piece of code whose intent is not clear:
const
{
MPP_ACTIVE
}
=
process
.
env
;
if
(
MPP_ACTIVE
===
""true""
)
{
doSomeFunkyStuff
(
)
;
}
What does “MPP” stand for? And what does it mean for it to be active? Let’s use
git blame
to see the commit that added this code:
▶
git blame example.js
-s -L 7,9
1edd8004
7)
if
(
MPP_ACTIVE
===
""true""
)
{
c457405a
8)
doSomeFunkyStuff
(
)
;
c457405a
9)
}
Note:
The
-s
option strips author and date information.
-L
selects specific lines.
Let’s look at the diff of
1edd8004
, the commit for line 7, that last touched the
MPP_ACTIVE
check:
Hmm, no, that’s not it
—
that’s just making the comparison more specific. We need to go further back to find the change that introduced the if statement itself.
To do that, we might repeat the process and run
git blame
again on the prior version of the file. Let’s do that and see what we get.
What we find is a tweak...
...a refactoring change...
...and a change just moving things around.
We don’t care about these changes. What we care about is the commit where the
MPP_ACTIVE
condition was introduced. Ideally, we’d be able to search for commits that mention
MPP_ACTIVE
and just look at the earliest one.
That is exactly what
git log -S
lets us do.
Searching for commits by code
By default,
git log
lists every commit in your branch. The
-S
option lets us pass a string used to filter out commits whose diff doesn’t include that specific string.
# Show commits that include ""getUser"" in the diff
git log
-S
""getUser""
Note:
The string passed to
-S
is case-sensitive.
getUser
will not match
GetUser
.
More specifically, the
-S
option is used to match code that was added or deleted in that commit. If no match is found, the commit is not included in the output.
As a mental model, you can imagine the
-S
option being implemented like so:
if
(
typeof
args
.
S
===
""string""
)
{
commits
=
commits
.
filter
(
commit
=>
(
commit
.
additions
.
includes
(
args
.
S
)
||
commit
.
deletions
.
includes
(
args
.
S
)
)
)
;
}
It’s worth emphasising that the string we’re searching for needs to have been added or deleted
—
not just moved
—
for the commit to be included. Moving lines of code that include our search string around does
not
constitute a match. This filters out
“just moving things around”
commits that would’ve just added noise.
Let’s try running
git log -S
with
""MPP_ACTIVE""
and see what we get:
▶
git log
-S
""MPP_ACTIVE""
commit
33a8b6ea050963e452b1d16165f64a77df3ff054
Author: johndoe42 <
[email protected]
>
Date:   Tue Sept 14 14:05:52 2022 +0000
refactor
commit
8fed03eadf2afc5efe91ddf0cf7a7837c8b680fe
Author: aliceb76 <
[email protected]
>
Date:   Mon Jan 19 10:44:19 2021 +0000
do funky stuff if MPP_ACTIVE is set
I find the default output format far too verbose so I almost always use the
--oneline
flag to compact the output:
▶
git log
-S
""MPP_ACTIVE""
--oneline
33a8b6e
refactor
8fed03e
do funky stuff if MPP_ACTIVE is set
The commits returned from
git log
are ordered from newest to oldest, which means that
8fed03e
is the first commit in the codebase that mentioned
MPP_ACTIVE
. It turns out that
8fed03e
is exactly the commit we’re looking for!
Let’s move past this toy example and try
git log -S
on a larger codebase. I’ll use the Next.js codebase as an example and try finding the commit that implemented a specific feature.
Using
git log -S
in larger codebases
The
vercel/next.js codebase
has over 25,000 commits added over 8 years, so it’s a fairly large and mature codebase!
Next.js has a
distDir
option
that allows the user to specify a custom build directory. Let’s try finding the commit that added this option.
As a first step, let’s run
git log -S
with
""distDir""
and see what we get:
▶
git log
-S
""distDir""
--oneline
5c1828bdd6
Handle source map requests for Turbopack client chunks
(#71168)
d8c0539b08
fix: allow custom app routes for metadata conventions
(#71153)
490704430b
Add source map support for
[...]
in the browser
(#71042)
13f8fcbb6b
[...]
Implement support for webpack’s `stats.json`
(#70996)
3b9889e1d8
[Turbopack] add new backend
(#69667)
...over 400 more commits
Hmm... these are all very recent commits. As we touched on earlier,
git log
orders commits from newest to oldest by default. Since we want to find the earliest mentions of
distDir
we can use the handy
--reverse
flag to get the oldest commits first:
▶
git log
-S
""distDir""
--oneline --reverse
acc1983f80
Don't delete `.next` folder before a replacement is built
(#1139)
141ab99888
build on tmp dir
(#1150)
9347c8bdd0
Specify a different build directory for #1513
(#1599)
8d2bbf940d
Refactor the build server to remove tie to fs
(#1656)
dec85fe6c4
Add CDN support with assetPrefix
(#1700)
...over 400 more commits
Nice! This gives us the first commits mentioning
distDir
, though it’s not necessarily obvious which one we care about.
We could look through the diffs to figure that out, but that would be a lot of work. Let’s instead explore some tools that we can use to analyze these commits at a high level so that we can quickly figure out which commits we care about.
Commits at a glance
A quick way to get a feel for a commit is to view the files that it touched, which we can do via
git show <commit> --stat
. Let’s try that on the first commit in the list:
▶
git show
acc1983f80
--stat --oneline
acc1983f80
Don't delete `.next` folder before a replacement is built
(#1139)
.gitignore
|
3
++
-
server/build/clean.js
|
4
++
--
server/build/gzip.js
|
4
++
--
server/build/index.js
|
19
+++++++++++
--------
server/build/replace.js
|
18
++++++++++++++++++
server/build/webpack.js
|
4
++
--
server/hot-reloader.js
|
2
+
-
7 files changed, 38 insertions(
+
), 16 deletions(
-
)
Note:
The
--oneline
option works the same as in
git log
, compacting the commit log.
show --stat
gives us a great overview of the files that the commit touches, and to what extent.
Still, we can narrow this down even further with the
-S
option. Using
-S ""distDir""
in conjunction with
show --stat
shows us only the touched files whose diff includes
distDir
:
▶
git show
acc1983f80
--stat -S
""distDir""
--oneline
acc1983f80
Don't delete `.next` folder before a replacement is built
(#1139)
server/build/replace.js
|
18
++++++++++++++++++
1 file changed, 18 insertions(
+
)
That certainly narrows it down! Let’s view the diff for that specific file via
show <commit> -- <file>
:
▶
git show
acc1983f80
-- server/build/replace.js
+++
b/server/build/replace.js
@@ -0,0 +1,18 @@
+
+
const
distDir
=
path
.
resolve
(
dir
,
distFolder
)
;
+
const
buildDir
=
path
.
resolve
(
dir
,
buildFolder
)
;
+
I’ve shortened the output for clarity.
Hmm,
distDir
is just a local variable name in this commit. Let’s keep looking.
The next commit of interest seems to be
9347c8bdd0
, which talks about specifying a build directory:
▶
git log
-S
""distDir""
--oneline --reverse
acc1983f80
Don't delete `.next` folder before a replacement is built
(#1139)
141ab99888
build on tmp dir
(#1150)
9347c8bdd0
Specify a different build directory for #1513
(#1599)
...
As a first step, let’s look at a summary of the changes in
9347c8bdd0
via
show --stat
:
▶
git show
9347c8bdd0
--stat --oneline
9347c8bdd0
Specify a different build directory for #1513
(#1599)
.gitignore
|
2
++
bin/next-build
|
5
+++
--
bin/next-dev
|
5
+++
--
bin/next-start
|
9
++++++
---
readme.md
|
13
++++++++++++
-
server/build/clean.js
|
4
+++
-
...9 more files
15 files changed, 128 insertions(
+
), 34 deletions(
-
)
We can shorten this by only showing files whose diff includes
distDir
via the
-S
option:
▶
git show
9347c8bdd0
--stat -S
""distDir""
--oneline
9347c8bdd0
Specify a different build directory for #1513
(#1599)
bin/next-start
|
9
++++++
---
readme.md
|
13
++++++++++++
-
server/build/clean.js
|
4
+++
-
server/build/index.js
|
19
++++++++++++
-------
server/build/replace.js
|
9
++++++
---
server/build/webpack.js
|
2
+
-
...4 more files
10 files changed, 68 insertions(
+
), 30 deletions(
-
)
This looks promising! Let’s start looking at some diffs to see if this is the commit we’re looking for. We can do that in two ways:
Look at the diff for a specific file via
show <commit> -- <file>
, or
look at diffs for all files that mention
distDir
via
show <commit> -S <code>
.
Since we don’t know which file to look at, let’s use the latter option and browse through files mentioning
distDir
. After a bit of scrolling, this addition to
readme.md
crops up:
▶
git show
9347c8bdd0
-S
""distDir""
--oneline
+++
b/readme.md
@@ -644,6 +644,17 @@
+
####
Setting a custom build directory
+
+
You can specify a name to use for a custom build directory. For
+
example, the following config will create a `build` folder instead
+
of a `.next` folder. If no configuration is specified then next
+
will create a `.next` folder.
+
+
```javascript
+
// next.config.js
+
module
.
exports
=
{
+
distDir
:
'build'
+
}
+
```
Looks like
9347c8bdd0
was the commit that added the
distDir
option! Opening the commit on GitHub shows us the
associated Pull Request
which also links to the
issue requesting the feature
.
The issue provides us with the original motive for adding
distDir
as an option:
I am trying to deploy next to Firebase functions, and it looks like the .next build directory is ignored by Firebase CLI.
Firebase CLI seems to ignore all hidden files, so I want to use a differently named directory.
The PR also contains a
design decision
where the option was renamed from
options.dist
to
distDir
.
It didn’t us long to track down the commit that added the
distDir
option!
Effective use of
-S
Our usage of the
-S
option was quite simplistic
—
we were just looking for a single term. But that term was distinct enough that we got useful results.
The usefulness of the results produced by
-S
is proportional to how distinct the search term is. So when searching for common terms it can be helpful to make your query more distinct. For example:
Given a function called
createContext
, you could use
-S ""createContext(""
to find invocations of that function.
To find code referencing a property called
numInstances
, you could search for
-S "".numInstances""
.
If you have a React component called
SmallNote
, you could look for usage of that component via
-S ""<SmallNote""
.
I’ve found it quite useful to try multiple surrounding syntaxes. For example, if looking for a property called
foo
, I might try the following:
-S "".foo""
to find property accesses,
-S ""foo =""
to find variable assignments,
-S ""foo: ""
to find object literal assignments,
-S ""foo,""
for passing as an argument, or assignments using the
shorthand syntax
, or
destructuring assignments
,
-S "" foo ""
to find standalone destructuring assignments.
For example, when we were looking for
distDir
in the Next.js codebase, searching for
"".distDir""
or
""distDir:""
would have returned the commit we were looking for as the first commit.
You can also search for entire lines of code:
▶
git log
-S
""[key, str] = part.split(""="").map(s => s.trim());""
If you try searching for multiple lines of code using
-S
, keep in mind that the
-S
option is sensitive to whitespace.
There are tons of ways to make effective use of the
-S
option. Try experimenting and see what works for you!
One option that I’ve yet to try is
-G
, which works like
-S
except that it accepts a regex for matching instead of a literal string.
See docs
.
Performance
git log
shows commits as soon as it finds them. So if you’re looking for a relatively recent commit,
git log
will surface it pretty much instantly. But if the commit you’re looking for is really far from the starting point of your search (which the
--reverse
flag affects), you might need to wait a while.
Searching through the entire commit history of the Next.js codebase takes 60 seconds on my M1 MacBook Air:
▶
time git --no-pager log -S
""distDir""
--reverse --oneline
60.63s
user 1.93s system 95% cpu 1:05.43 total
If your codebase is significantly larger, you may run into performance bottlenecks. If you do, I’d love to hear how you work around them!
Final words
Until recently, I wasn’t aware of the
-S
option, and neither was a colleague I showed this to who has been writing software since before Git was created. There are probably a ton of developers who would benefit from being aware that Git has this capability!
I’ve used the
-S
option a few times since discovering it, and it’s made searching for commits much more enjoyable. Go ahead and try the
-S
option the next time you need to search a commit history. I hope it proves useful!
—
Alex Harri
Mailing list
To be notified of new posts, subscribe to my mailing list.
Subscribe","Oct 20, 2024"
"2024 Icelandic Developer Survey: Compensation, Technologies, and more","A survey for Icelandic developers was conducted earlier this year by
Kolibri
. This survey was comprehensive, gathering data on compensation, programming language use, CI/CD practices, company size, industry, and so on alongside demographic information such as age, experience, and gender.
No large developer survey like this has been conducted in Iceland before—this survey is the first of its kind.
The results from this survey offer us unique insights into the Icelandic software industry. Which technologies are developers using? How are developers compensated? What cloud providers are popular? These are just some of the questions we’ll explore in this post.
There’s loads of data to look at, so let’s get to it!
Demographics
425 developers responded to the survey. With only a few thousand software developers in Iceland, this constitutes a significant chunk of our developers.
Age
Most respondents were aged 25 to 54. This chart shows the age distribution of the respondents.
Gender
Of the respondents who specified their gender (397), 86.1% were men, 13.1% were women, and 0.8% were non-binary.
Despite the seemingly low proportion of women at 13.1% of respondents, this percentage is still significantly higher than in other global developer surveys I’ve looked at.
JetBrains’ 2023 developer ecosystem survey
respondents were 5% women, with
State of JS 2023
at 4%, and
Stack Overflow’s 2022 developer survey
at ~5%.
Nationality
Of the 396 respondents who specified their nationality, 384 were Icelandic (96.9%). This low number of non-Iceland respondents is likely due to the survey primarily being circulated through an Icelandic Facebook group for software developers. I would estimate the real proportion of non-Icelandic software developers to be much higher than just 3%.
Experience
The following chart shows the distribution of the respondents’ years of experience in software development.
This gets more interesting when we group the data on experience by age cohort. The below chart shows years of experience, grouped by age.
Normalize
PS: Try hitting the ‘Normalize’ toggle on the top right. It allows you to switch from viewing the absolute counts to viewing percentages within each group. Every chart that groups data has this button.
Most developers aged 45 or above have over 20 years of experience, indicating that most older developers started their careers in their 20s. Looking at the younger age cohorts we can see that most of them started their career in their 20s as well, with a smaller percentage starting in their 30s or 40s.
Developer types
Respondents were asked which type of developer they consider themselves to be. This was a multi-choice question, so they could pick more than one type.
Perhaps the most immediately obvious fact that jumps out is how many developers classify themselves as full-stack developers. Definitely more than I would have expected! I made one notable change to the data which contributed to that:
If a developer classified themselves as both a front-end and back-end developer, I classified them as a full-stack developer (in case they had not done so themselves).
After that, if a developer is classified as a full-stack developer, they are
not
classified as a front-end or back-end developer.
This change means that front-end, back-end, and full-stack are
mutually exclusive
developer types. I feel that this gives a better sense of the real numbers of front-end vs back-end vs full-stack developers.
Back-end programming languages
The survey asked which back-end programming languages respondents had used within the last year. Only respondents who classified themselves as back-end or full-stack developers were asked this question.
Note:
The languages colored blue were provided as default options in the survey, while the languages colored green were typed in the “Other” field. Languages used by fewer than 3 respondents are not included.
The top back-end programming language in Iceland is C#, with 46.1% of Icelandic developers using it. After C#, we get TypeScript (40.4%), Python (38.6%), and JavaScript (32.6%). The next two languages, Go and Java, come in at 17.9% and 15.4% respectively.
Some observations:
SQL at 1.3% usage is
obviously
not accurate. I would expect most back-end and full-stack developers to have reported using it had it been provided as a default option.
C++ at 3.4% is far too low as well. I would guesstimate that C++ would be in the 8-15% range had it been included in the default options.
Aside from those obvious anomalies, the data seems accurate to me. C# is heavily used in Icelandic companies, with it being the go-to back-end development language for most Icelandic companies.
TypeScript, as the data shows, has been widely adopted in Iceland. In my experience, TypeScript is generally strongly preferred over plain JavaScript, though not universally. In this survey, 74% of those who use JavaScript also reported using TypeScript, while 60% of those using TypeScript reported also using JavaScript.
Python being heavily used is no surprise to me, and the usage of Rust is in line with what I would have expected. Go is used more than I would have thought.
Comparison to Stack Overflow’s survey
Let’s compare this to the results of
Stack Overflow’s 2023 Developer Survey
:
One obvious issue with this comparison is that the State of Iceland survey specifically asked about
back-end
languages, while Stack Overflow’s survey did not make that distinction. This may be part of the wide gap in usage between JavaScript in Iceland vs globally, and also why the percentages are generally higher in Stack Overflow’s survey
Still, a few key things stand out to me:
C# is super popular in Iceland. Perhaps as a direct consequence, Java is much less used in Iceland than globally.
TypeScript is more popular than JavaScript in Iceland, which is not the case globally.
PHP is much less used in Iceland than globally.
Programming languages used by years of experience
I was curious whether there would be a significant difference between the languages that experienced developers are using compared to less experienced ones, but that does not seem to be the case. The following chart shows language use by years of experience.
Normalize
We can glean
some
patterns from this data, such as Java being used more by experienced developers. Still, I don’t see any dramatic differences that couldn’t be explained away by the small sample size.
Salary
Icelandic developers are compensated well. Respondents were asked about their monthly salary in Icelandic króna (ISK), with the possible answers being one of six salary brackets:
ISK
EUR
USD
0 - 800,000
0 - 5,360
0 - 5,760
800,000 - 1,000,000
5,360 - 6,700
5,760 - 7,200
1,000,000 - 1,200,000
6,700 - 8,040
7,200 - 8,640
1,200,000 - 1,400,000
8,040 - 9,380
8,640 - 10,080
1,400,000 - 1,600,000
9,380 - 10,720
10,080 - 11,520
Over 1,600,000
Over 10,720
Over 11,520
Note:
The EUR and USD figures are using an exchange rate of ISK 1 = EUR 0.0067 and ISK 1 = USD 0.0072, measured on the 2nd of July 2024.
In Iceland, we generally discuss monthly salaries instead of yearly. But in the US, and other countries, yearly salary figures are more common. Here is the same table with yearly salary figures.
ISK
EUR
USD
0 - 9,600,000
0 - 64,320
0 - 69,120
9,600,000 - 12,000,000
64,320 - 80,400
69,120 - 86,400
12,000,000 - 14,400,000
80,400 - 96,480
86,400 - 103,680
14,400,000 - 16,800,000
96,480 - 112,560
103,680 - 120,960
16,800,000 - 19,200,000
112,560 - 128,640
120,960 - 138,240
Over 19,200,000
Over 128,640
Over 138,240
The below chart shows monthly salaries for developers in Iceland, split by age bracket.
Normalize
As a freshly minted developer, you can expect to earn under or around ISK 800K. Even though the first salary bracket goes to zero, I wouldn’t expect many developers to be earning less than 650K unless they’re entering the field without a degree.
With a few years of experience, most developers move from the <800K to the 800K-1.0M bracket. At 6 or more years of experience, a lot of developers move into the >1.0M brackets.
Summarizing this:
Developers starting their careers can expect to earn under or around ISK 800K monthly (USD 70K yearly).
Developers with 3-10 of experience generally earn ISK 800K to 1.2M monthly (USD 70K to 100K yearly).
Developers with over 10 of experience generally earn ISK 1.0M to 1.4M monthly (USD 85K to 120K yearly).
A significant number of highly experienced developers (10 to 20+ years of experience) earn 1.4M to >1.6M monthly (USD 120K to >140K yearly).
TL;DR: the typical developer in Iceland earns around USD 85K to 120K yearly.
Here is a different view of the same compensation data, which I feel shows the story of how developers move into the higher salary brackets as they gain more experience.
Normalize
Salary by programming language
The following chart shows monthly salary grouped by language:
Normalize
There is not a great deal of difference across languages, though salaries for developers using PHP and JavaScript developers seem to skew lower. The handful of Scala developers are raking in cash.
Salary by developer type
As mentioned earlier, developers were asked to select their developer type, such as whether they’re a front-end or a back-end developer. The following chart shows monthly salary, grouped by developer type.
Normalize
Gender differences in pay
I was curious as to whether there would be visible disparities in salaries across genders, but I can’t see any notable difference from the survey data. Still, here is the salary chart from earlier split by gender as well as years of experience so that you can see for yourself.
Normalize
Note:
For information on the gender pay gap in Iceland, see
“Unadjusted gender pay gap 9.1% in 2022”
from Statistics Iceland
Putting context to the salary numbers
Salary numbers are interesting, but there are other important factors that cannot be captured in raw salary numbers. The following chapters will discuss taxes, employer-provided benefits, and work-life balance in Iceland.
Taxes
We’ve been looking at gross salaries so far. In figuring out net salaries we need to look at Icelandic taxes. In 2024, Iceland had three tax brackets:
Income, per month
Tax rate
ISK 0 - 446,136
31.48%
ISK 446,137 - 1,252,501
37.98%
Over ISK 1,252,501
46.28%
Source:
https://www.skatturinn.is/english/individuals/tax-liability/
There is a personal tax credit of ISK 64,926 per month, which lowers the effective tax rate. There are also other factors, such as the mandatory pension fund, union membership fees, and voluntary pension insurance premiums.
To take a rough example, a developer earning a monthly gross salary of ISK 1.2M (~104K USD, yearly) is likely to have a net salary of around 780K-800K ISK (~USD 67K-70K, yearly). Don’t take this number too seriously, it depends on a lot of factors.
Employer-provided benefits
Developers in Iceland often receive employer-provided benefits. Common ones include:
Subsidies for physical and/or mental wellness (e.g. gym membership or counseling)
Home internet and phone plans
Lunch and snacks
Transportation subsidies (e.g. bus pass)
Mobile phones
Conferences (e.g. pick one yearly)
This of course varies by company, but most companies provide at least some of these. Every company I’ve worked for in Iceland has provided me with the first three benefits listed.
Work-life balance and parental leave
With the obvious caveat of work-life balance varying by company, work-life balance for developers in Iceland is generally very good.
A notable factor is Iceland’s generous paid parental leave, which is 6 months for each parent with 2 of those months transferrable to the other parent. This corresponds to about 26 weeks of parental leave for each parent.
Payments during parental leave are 80% of the person’s salary, capped at ISK 700K. This means that payments during parental leave max out when earning ISK 875K or more, which applies to most developers in Iceland.
Note:
For more information on paternal leave in Iceland, see
https://island.is/en/life-events/having-a-baby
Salaries in Iceland
Icelandic developer salaries fall on the higher end of the salary spectrum. The following chart shows the distribution of total compensation in Iceland using data from Statistics Iceland:
Source:
https://statice.is/statistics/society/wages-and-income/wages/
Converting this from monthly compensation in ISK to yearly compensation in USD, we get a chart that’s more easily understood by a global audience:
Industries
The survey asked developers which industry they worked in. Here are the results.
Salaries by industry
Here is the monthly salary data split by industry:
Normalize
We can see that salaries in the public sector skew lower and salaries in banking and finance skew higher. Not terribly surprising.
Programming language usage by industry
Respondents could pick multiple languages, but they could only pick a single industry. The following chart shows, for each language, which industry the respondent using the language works in.
Normalize
We can see some patterns emerge:
Developers working in banking, finance, and the public sector mostly use C#.
Rust, TypeScript, Python, and Go are popular in startups.
Startups
15.9% of developers—including myself—reported working in startups. Quite a high percentage!
Much of that can be attributed to Iceland’s strong support system for startups.
Klak
runs multiple startup accelerators like
Gulleggið
and
Startup SuperNova
. There are many notable venture capital funds like
Brunnur
,
Frumtak
, and
Crowberry Capital
, in addition to the
Technology Development Fund
which provides free capital for early-stage startups.
In addition to that, companies may receive up to a 20% tax deduction for expenses related to research and innovation for expenses up to ISK 1,100M each year, or around USD 7.9M.
Source:
https://www.skatturinn.is/atvinnurekstur/framtal-og-alagning/fradrattur-vegna-nyskopunar/
Company size
With a population of around 380,000 people, Icelandic companies are generally small to medium-sized. Very few Icelandic companies, outside of municipalities and healthcare, reach over 1,000 employees.
The following chart shows the distribution of company sizes at which the respondents work.
A lot of Icelandic developers working at companies with more than 300 people! Here we can see the same data on company sizes, grouped by industry:
Normalize
As one might expect, developers working in the public sector or banking/finance work at larger companies, while developers in startups tend to work at smaller companies.
Technology stacks
We’ll now take a look at the technologies that Icelandic developers are using. We’ll cover front-end libraries, cloud providers, CI/CD, and developers’ OS of choice.
Front-end libraries
The following chart shows the front-end libraries which respondents used in the last year.
Note:
Like before, front-end libraries colored blue were provided as a default option in the survey, while the front-end libraries colored green were typed in the “Other” field.
React dominates the front-end scene in Iceland, with Vue and Angular in a distant second and third place. In my experience, this data is representative—React is incredibly popular here.
Some other observations:
Next.js is very popular in Iceland. Had it been included as a default option it would likely have been
much
higher. I would personally estimate that over 50% of developers in Iceland using React also use Next.js.
The survey only included JavaScript libraries as default options. With C# being as popular as it is in Iceland, a fair number of respondents mentioned C# front-end solutions in the “Other” field, of which Blazor seems to be most popular. Perhaps more people would have selected C#-related technologies had C# libraries been included as default options.
Cloud providers
Note:
Default survey options are colored blue, while options typed in the “Other” field are colored green. Origo, Advania, and 1984.is are local Icelandic cloud providers.
AWS at 52.5% is the most popular cloud provider in Iceland, with Azure in second place at 36.5%. Vercel and Cloudflare are also used by a significant number of developers, coming in at 22.6% and 17.6% respectively. Google Cloud is relatively far behind AWS and Azure with 16.2% of Icelandic developers using GCP.
Digital Ocean is the most notable cloud provider not included as a default option. Perhaps it would have ranked higher had it been one of the default options.
Programming language usage by cloud provider
The following chart shows the usage of programming languages by cloud providers. In other words: for developers using a given cloud provider, how many of them are using a given programming language?
Normalize
Developers using Azure, Origo, and Advania are
much
more likely to use C# than developers using other cloud providers. Developers using Azure are around 2.5 times more likely to use C# compared to developers using AWS.
Usage of TypeScript and Python seems inversely correlated to the usage of C#.
Continuous integration and continuous delivery (CI/CD)
The chart below shows which CI/CD providers developers reported using.
Note:
Default survey options are colored blue, while options typed in the “Other” field are colored green.
Most respondents use GitHub actions for CI/CD (52.5%). GitLab and Azure are also fairly popular with 19.1% and 17.4% respectively.
Code editors
A whopping 75.6% of Icelandic developers use Visual Studio Code for editing code.
Visual Studio (26.8%), Vim (22.7%) and IntelliJ (17.2%) see respectable usage. All other code editors are used by less than 10% of Icelandic developers.
Operating system
Which operating systems are Icelandic developers using?
macOS, apparently! A lot are using Linux as well. I would have expected Windows to take the top spot.
Operating system by industry
Normalize
Grouping the use of operating systems by industry, we see that Windows is most used within the public sector and finance/banking, while macOS is more popular in startups, the private sector, and with contractors.
Final words
I want to thank
Telma Guðbjörg Eyþórsdóttir
and
Jóhann Guðmundsson
(both software developers at Kolibri) for kickstarting and driving this survey! Additional thanks go to
Anna Signý Guðbjörnsdóttir
(CEO at Kolibri) and the other people at
Kolibri
that helped make this happen.
Kolibri is one of Iceland’s foremost digital agencies, providing services related to creating digital experiences, such as product and software development and design. I’m not formally affiliated with them in any way, but I have friends there.
Kolibri held an event where they presented the results of the study, which sparked lively discussions. The house was packed and it was a blast!
Getting to write up the results of the survey has been awesome! I hope I have the opportunity to do so again in the future.
Thanks for reading! I hope this was interesting.
— Alex Harri
Mailing list
To be notified of new posts, subscribe to my mailing list.
Subscribe","July 13, 2024"
Introducing Arkio’s Pin Tool,"I enjoyed the privilege of leading the design and development of Arkio’s Pin Tool, released in Arkio 1.7.
Following is an archived version of the post I wrote to announce the Pin Tool. It was originally posted on
community.arkio.is
.
Arkio’s new Pin Tool enables you to pin and unpin objects and sections in your model, saving you from making changes that you didn’t intend to make. Pinning an object in your model prevents it from being moved, deleted, or modified—by you or any other editors in your meeting.
The Pin Tool is the top-left tool in the quick menu
Using the Pin Tool is easy—just point at the objects in your model that you want to be pinned and hit the trigger to pin them. While the Pin Tool is active, all of the pinned objects in your model will have an orange box drawn around them, making it obvious what’s pinned and what’s not. Whether you’re working at a small or large scale, the tool enables you easily to pin objects at any distance.
Pinning objects in the scene using the Pin Tool
The orange boxes would be a distraction during normal editing, so instead the editing tools will let you know if an object is pinned by showing you the Pin icon. A gray box is also shown around the object, indicating that it cannot be modified.
This object is pinned, you can’t modify it
Pinning sections of your model
If you’re done modeling a room—or perhaps an entire building—the thought of individually pinning every object in that room may seem like a daunting task. “Do I have to pin every single thing in that darn room?” Luckily, for all of us, that’s not the case.
When designing the Pin Tool, we wanted to make it possible to pin and unpin large sections of your model with ease. For this reason, we made it so that pinning a room will also pin every object inside of it. The same goes for unpinning.
Pinning a room in a single action
Even better, if you want to modify a single object in a pinned room, you don’t need to unpin the room itself. Just unpin the object that you want to modify, make your changes, and pin it again.
Pinning a room does not prevent you from creating new objects inside of that room. Pinning an object only prevents modifications to the object itself.
What about skyscrapers?
Pinning every object in a room individually would be a tedious task, and so would individually pinning every floor of a 20-story skyscraper individually. Even though the floors of the skyscraper aren’t contained in one another, we felt that a skyscraper should be pinnable in a single action.
For this reason, we designed the Pin Tool such that it also pins/unpins objects that are resting on top of the object-to-be-pinned:
Pinning a skyscraper in a single action
This means that pinning the bottom floor of a skyscraper will also pin every floor above it, and all of the rooms and objects inside of all of the floors.
Making Arkio a better modeler
These two design decisions—including contained and attached objects in your pin selection—make pinning and unpinning sections of your model and groups of objects a breeze!
We at Arkio are working hard these days on making Arkio a more powerful, stable, and easy-to-use modeler. In doing so, there are a lot of interesting decisions and trade-offs that we have to make. We hope you enjoyed learning about the new Pin Tool and the decisions we made in creating it.
We intend to share more details on the development process here on the community site, so join to the @InsideArkio group to receive notifications about posts from the Arkio team.
Anyway, thanks so much for reading. We hope the new Pin Tool in Arkio 1.7 is of use to you and your team!
— Alex Harri, Senior Software Engineer at Arkio
Mailing list
To be notified of new posts, subscribe to my mailing list.
Subscribe","Apr 29, 2024"
JSDoc as an alternative TypeScript syntax,"As web development has embraced static typing during the past decade, TypeScript has become the default language of choice. I think this is great—I love working with TypeScript!
But what if you can’t use TypeScript? You may encounter circumstances where you need to work in plain JavaScript, be it tooling constraints or a team member who does not like static typing.
Under these circumstances, look to JSDoc for salvation:
/**
*
@param
{
number
}
a
*
@param
{
number
}
b
*
@returns
{
number
}
*/
function
add
(
a
,
b
)
{
return
a
+
b
;
}
I was surprised when I learned that the TypeScript compiler actually understands JSDoc comments. This fact allows you to type your entire codebase without creating a single
.ts
file.
Think of this post as your crash course in using JSDoc as an alternative syntax for TypeScript. We’ll cover all the important TypeScript-related features JSDoc has to offer—and their limitations.
JSDoc
JSDoc is expressed through block comments in the form
/** */
, which may contain
block tags
such as
@param
and
@type
. Normal
//
and
/* */
comments don’t work:
//
@type
{
number
}
let
a
;
// Doesn't work
/*
@type
{
number
}
*/
let
b
;
// Doesn't work
/***
@type
{
number
}
*/
let
c
;
// Doesn't work
/**
@type
{
number
}
*/
let
d
;
// Works!
The majority of your JSDoc block tags will be used for typing variables, arguments, and return types. The block tags for those are
@type
,
@param
, and
@returns
.
/**
*
@param
{
string
}
message
*
@returns
{
number
}
*/
function
len
(
message
)
{
return
message
.
length
;
}
/**
@type
{
{
name
:
string
,
age
:
number
}
}
*/
const
user
=
{
name
:
""Alex""
,
age
:
26
,
}
;
Type casting
Type casting in TypeScript can be done using
expression as T
or
<T>expression
:
function
example
(
arg
:
unknown
)
{
const
num
=
arg
as
number
;
const
str
=
<
string
>
arg
;
}
Type casting in JSDoc is done by wrapping the expression in parentheses and adding a preceding
@type
comment:
/**
@param
{
number
}
num
*/
const
square
=
(
num
)
=>
num
*
num
;
/**
@param
{
unknown
}
arg
*/
function
example
(
arg
)
{
const
num
=
/**
@type
{
number
}
*/
(
arg
)
;
return
square
(
num
)
;
// OK!
}
The parentheses are required. If they are missing the cast will not work:
/**
@param
{
number
}
num
*/
const
square
=
(
num
)
=>
num
*
num
;
/**
@param
{
unknown
}
arg
*/
function
example
(
arg
)
{
const
num
=
/**
@type
{
number
}
*/
arg
;
return
square
(
num
)
;
//
Argument of type 'unknown' is not assignable to parameter of type 'number'.
}
Missing parentheses are a really easy mistake to make, which can easily lead to bugs when casting from
any
. Be careful with casts in JSDoc!
Const assertions
TypeScript supports
const assertions
, which can be quite useful.
function
resize
(
options
:
{
size
:
1
|
2
}
)
{
// ...
}
const
a
=
{
size
:
1
as
const
}
;
const
b
=
{
size
:
2
}
;
resize
(
a
)
;
// OK
resize
(
b
)
;
//
Types of property 'size' are incompatible.
//
Type 'number' is not assignable to type '1 | 2'.
You can also use const assertions in JSDoc, they’re just a type cast:
/**
*
@param
{
{
size
:
1
|
2
}
}
options
*/
function
resize
(
options
)
{
// ...
}
const
a
=
{
size
:
/**
@type
{
const
}
*/
(
1
)
}
;
const
b
=
{
size
:
2
}
;
resize
(
a
)
;
// OK
resize
(
b
)
;
//
Types of property 'size' are incompatible.
//
Type 'number' is not assignable to type '1 | 2'.
Declaring types
In TypeScript, you can declare types using the
type
or
interface
keywords:
type
Value
=
string
|
number
;
interface
Store
{
value
:
Value
;
set
(
value
:
Value
)
:
void
;
}
In JSDoc, types are declared using the
@typedef
keyword:
/**
*
@typedef
{
string
|
number
}
Value
*/
/**
*
@typedef
{
{
value
:
Value
,
set
(
value
:
Value
)
:
void
}
}
Store
*/
Having declared a type with
@typedef
, you can reference it like any other TypeScript type:
/**
@type
{
Value
}
*/
const
value
=
5
;
/**
@type
{
Store
}
*/
const
store
=
{
value
,
set
(
value
)
{
this
.
value
=
value
;
}
,
}
;
An alternative way to declare the properties of an object type is using
@property
:
/**
*
@typedef
{
object
}
Store
*
@property
{
Value
}
value
*
@property
{
(
value
:
Value
)
=>
void
}
set
*/
Nested properties can be specified using
.
as a separator:
/**
*
@typedef
{
object
}
User
*
@property
{
object
}
name
*
@property
{
string
}
name.first
*
@property
{
string
}
name.last
*/
/**
@type
{
User
}
*/
const
user
=
{
name
:
{
first
:
""Jane""
,
last
:
""Doe""
}
,
}
;
Exporting types
There’s no syntax for exporting types in JSDoc. Instead, types defined using
@typedef
are
exported by default
. This auto-exporting applies to all types declared at the top level of a module.
As someone who cares a lot about the interfaces of modules, I strongly dislike this feature.
You can avoid the auto-exporting by declaring types in the scope that they’re needed in:
// 'Foo' is declared at the top level and can thus be imported by
// other modules.
/**
@typedef
{
string
}
Foo
*/
{
// 'Bar' is declared in a block scope: it cannot be imported by
// other modules.
/**
@typedef
{
string
}
Bar
*/
}
function
example
(
)
{
// 'Baz' is declared in a function: it cannot be imported by
// other modules.
/**
@typedef
{
string
}
Baz
*/
}
One thing worth mentioning is that types declared in JavaScript modules using JSDoc can be imported from TypeScript modules.
Importing types
In TypeScript, you can reference types from other modules via
import
statements or
import(""./path"").Type
:
import
{
Foo
}
from
""./module""
;
let
foo
:
Foo
;
let
bar
:
import
(
""./module""
)
.
Bar
;
Note:
In TypeScript modules you can declare that the import is for a type via
import type { Foo }
or
import { type Foo }
JSDoc allows you to use
import(""./path"")
, like in TypeScript:
/**
@type
{
import
(
""./module""
)
.
Foo
}
*/
let
foo
;
That can get quite verbose for long module paths and type names. You can instead import types via the
@import
tag
introduced in TypeScript 5.5
:
/**
@import
{
Foo
}
from
""./module""
*/
/**
@type
{
Foo
}
*/
let
foo
;
If you’re using an older version of TypeScript, you can instead “fake” normal imports using
@typedef
:
/**
@typedef
{
import
(
""./module""
)
.
Foo
}
Foo
*/
/**
@type
{
Foo
}
*/
let
foo
;
But keep the auto-exporting footgun in mind! As mentioned in
Exporting types
, types defined via
@typedef
are auto-exported, which means that the type is re-exported.
// This...
/**
@typedef
{
import
(
""./module""
)
.
Foo
}
Foo
*/
// ...is equivalent to this
import
{
Foo
}
from
""./module""
;
export
{
Foo
}
from
""./module""
;
Non-null assertions
We’ve arrived at my largest gripe with JSDoc:
it doesn’t support non-null assertions
.
Take the
Map<K, V>
data structure as an example. The return type of
Map<K, V>.get
is
V | undefined
, which can be frustrating when you know for certain that a value is non-null.
const
map
=
new
Map
<
string
,
number
>
(
[
[
""a""
,
1
]
,
[
""b""
,
2
]
,
]
)
;
const
a
:
number
=
map
.
get
(
""a""
)
;
//
Type 'number | undefined' is not assignable to type 'number'.
In TypeScript, you can use
!
after an expression to assert that it is non-nullable.
const
a
:
number
=
map
.
get
(
""a""
)
!
;
// OK!
There is no equivalent
@nonnull
tag or syntax in JSDoc.
One possible workaround is to use a type cast like so:
/**
@type
{
number
}
*/
const
a
=
/**
@type
{
number
}
*/
(
map
.
get
(
""a""
)
)
;
The problem with type casts is that they can become incorrect as the code evolves. Imagine that
map
is updated to store
string | number
instead of just
number
:
/**
@type
{
Map
<
string
,
number
|
string
>
}
*/
const
map
=
new
Map
(
[
...
]
)
;
/**
@type
{
number
}
*/
const
a
=
/**
@type
{
number
}
*/
(
map
.
get
(
""a""
)
)
;
Type casting
string | number | undefined
to
number
is valid, so we get no type error.
The type cast masks the type error
, which would have not happened using non-null assertions.
const
map
=
new
Map
<
string
,
number
|
string
>
(
[
...
]
)
;
const
a
:
number
=
map
.
get
(
""a""
)
!
;
//
Type 'string | number' is not assignable to type 'number'.
There is one safe way to express non-nullability in JSDoc, which is using the
NonNullable
type in conjunction with
typeof
. Any expression
expr
can be declared non-nullable by casting it to
NonNullable<typeof expr>
, though this can be quite verbose.
/**
@type
{
Map
<
string
,
number
>
}
*/
const
map
=
new
Map
(
[
...
]
)
;
/**
@type
{
number
}
*/
const
a
=
/**
@type
{
NonNullable
<
ReturnType
<
typeof
map
.
get
>>
}
*/
(
map
.
get
(
""a""
)
)
;
We can make this more readable like so:
const
aNullable
=
map
.
get
(
""a""
)
;
/**
@type
{
number
}
*/
const
a
=
/**
@type
{
NonNullable
<
typeof
aNullable
>
}
*/
(
aNullable
)
;
But this is still terribly noisy! This would be much cleaner if
@nonnull
were supported:
/**
@type
{
number
}
*/
const
a
=
/**
@nonnull
*/
(
map
.
get
(
""a""
)
)
;
This issue is being tracked in
#23405 in microsoft/TypeScript
. Let us pray that
@nonnull
will be added at some point.
Optional parameters
Parameters can be marked as optional in TypeScript using
?
:
function
foo
(
a
:
number
,
b
?
:
boolean
)
{
// ...
}
foo
(
1
)
;
// OK
In JSDoc, you can mark parameters as optional by wrapping their name in
[]
:
/**
*
@param
{
number
}
a
*
@param
{
boolean
}
[b]
*/
function
foo
(
a
,
b
)
{
// ...
}
foo
(
1
)
;
// OK
A parameter can also be implicitly marked as optional by providing a default argument, just like in TypeScript:
/**
*
@param
{
number
}
a
*
@param
{
boolean
}
b
*/
function
foo
(
a
,
b
=
false
)
{
// ...
}
foo
(
1
)
;
// OK
There is an alternative syntax for marking parameters as optional where
=
is placed after the type:
/**
*
@param
{
number
}
a
*
@param
{
boolean
=
}
b
*/
function
foo
(
a
,
b
)
{
// ...
}
foo
(
1
)
;
// OK
I find this syntax a bit weird, but hey, it’s supported.
Generic type parameters
Declaring a generic type parameter is done using
@template
:
/**
*
@template
T
*
@param
{
T
}
value
*
@returns
{
{
value
:
T
}
}
*/
function
box
(
value
)
{
return
{
value
}
;
}
// Equivalent TypeScript
function
box
<
T
>
(
value
:
T
)
:
{
value
:
T
}
{
return
{
value
}
;
}
Expressing an
extends
constraint is done like so:
/**
*
@template
{
string
|
number
}
T
*
@param
{
T
}
value
*
@returns
{
{
value
:
T
}
}
*/
function
box
(
value
)
{
return
{
value
}
;
}
// Equivalent TypeScript
function
box
<
T
extends
string
|
number
>
(
value
:
T
)
:
{
value
:
T
}
{
return
{
value
}
;
}
The
@template
block tag can also be used for type definitions, classes, methods, and more.
// Declaring a generic type
/**
*
@template
T
*
@typedef
{
{
value
:
T
}
}
Box
*/
// Referencing a generic type
/**
@type
{
Box
<
number
>
}
*/
const
box
=
{
value
:
5
}
;
// Creating a generic class
/**
*
@template
T
*/
class
Box
{
/**
*
@param
{
T
}
value
*/
constructor
(
value
)
{
this
.
value
=
value
;
}
}
Class properties
In TypeScript, you can declare class properties using the
public
/
private
keywords for constructor arguments or by explicitly declaring the properties.
class
Vector2
{
// Use 'public' keyword to declare 'x', 'y' and
// automatically assign them.
constructor
(
public
x
:
number
,
public
y
:
number
)
{
}
}
class
Vector2
{
// Explicitly declare properties
public
x
:
number
;
public
y
:
number
;
constructor
(
x
:
number
,
y
:
number
)
{
// Manually assign to properties
this
.
x
=
x
;
this
.
y
=
y
;
}
}
Since JavaScript does not support the
public
/
private
keywords, we need to take the latter approach and assign manually:
class
Vector2
{
/**
*
@param
{
number
}
x
*
@param
{
number
}
y
*/
constructor
(
x
,
y
)
{
this
.
x
=
x
;
this
.
y
=
y
;
}
}
Unlike TypeScript, we don’t need to explicitly declare
x
and
y
as properties in JavaScript modules. They are implicitly declared by assigning to them in the constructor.
However, I would argue that it’s good practice to explicitly declare the types of class properties to avoid possible implicit
any
s.
class
Vector2
{
/**
@type
{
number
}
*/
x
;
/**
@type
{
number
}
*/
y
;
/**
*
@param
{
number
}
x
*
@param
{
number
}
y
*/
constructor
(
x
,
y
)
{
this
.
x
=
x
;
this
.
y
=
y
;
}
}
Class
implements
In TypeScript you can declare that a class
implements
a certain interface:
interface
IEventEmitter
{
emit
(
type
:
string
)
:
void
;
subscribe
(
type
:
string
,
callback
:
(
)
=>
void
)
:
void
;
}
class
EventEmitter
implements
IEventEmitter
{
// ...
}
It won’t come as a surprise to hear that JSDoc has
@implements
for this purpose:
/**
*
@typedef
{
object
}
IEventEmitter
*
@property
{
(
type
:
string
)
=>
void
}
emit
*
@property
{
(
type
:
string
,
callback
:
(
)
=>
void
)
=>
void
}
subscribe
*/
/**
*
@implements
{
IEventEmitter
}
*/
class
EventEmitter
{
// ...
}
Public and private properties and methods
Properties and methods can be declared as
public
and
private
via
@public
and
@private
:
class
Example
{
/**
*
@public
*
@type
{
number
}
*/
foo
;
/**
*
@private
*
@type
{
string
}
*/
bar
;
}
// Equivalent TypeScript
class
Example
{
public
foo
:
number
;
private
bar
:
string
;
}
Typing
this
TypeScript enables you to type the
this
argument for a function or method:
interface
Context
{
scale
:
number
;
}
function
foo
(
this
:
Context
,
value
:
number
)
{
// ...
}
JSDoc contains an
@this
keyword for this purpose:
/**
*
@typedef
{
{
scale
:
number
}
}
Context
*/
/**
*
@this
{
Context
}
*
@param
{
number
}
value
*/
function
foo
(
value
)
{
// ...
}
@ts-*
comments
All of your normal
@ts-*
comments, such as
@ts-ignore
, work as expected:
/**
@type
{
string
}
*/
//
@ts-ignore
let
x
=
5
;
Practical matters
We’ve now gone through all the major (in my opinion) TypeScript-related features in JSDoc. They should cover the vast majority of TypeScript features you’ll ever need in JSDoc.
We’ll now cover some practical things to know if you intend to use JSDoc with TypeScript.
Enable
checkJs
As we’ve seen, type annotations in JSDoc comments are used as type information in
.js
files.
/**
*
@param
{
string
}
message
*/
function
log
(
message
)
{
// ...
}
log
(
12
)
;
//
Argument of type 'number' is not assignable to parameter of type 'string'.
However,
checkJs
needs to be enabled in your
tsconfig.json
for type errors to be emitted. If you don’t enable
checkJs
, your JSDoc comments will only be used for IDE annotations—not type checking. Be sure to enable it!
TypeScript interop
If you type a function using JSDoc in a
.js
module, you can import that function in a
.ts
module without any issues. This also works the other way: you can import things from
.ts
modules and use them in
.js
modules.
Generally, interop between
.js
modules using JSDoc and
.ts
modules “just works”.
JSDoc does not work in TypeScript modules
You can’t use JSDoc for type annotations in
.ts
modules. This can make migrating from JSDoc to TypeScript a bit frustrating, especially for larger modules.
Conclusion
I worked in a JSDoc codebase for a significant amount of time, and have gone through the process of migrating a lot of that codebase to TypeScript. JSDoc definitely has flaws, such as its clunky and verbose syntax, but it’s still a perfectly viable way to go about typing your codebase.
If you’re not able to use TypeScript for some reason, then consider giving JSDoc a shot. It’s better than no types.
Mailing list
To be notified of new posts, subscribe to my mailing list.
Subscribe","Feb 24, 2024"
Iterating over Bit Sets quickly,"Welcome to part 2 of my 2-part series on bit sets! If you’re not very familiar with bit manipulation — or don’t know what bit sets are — I recommend reading part 1 first:
Bit Sets: An introduction to bit manipulation
.
If you know your bit manipulation, then you can freely skip part 1.
Bit sets
— also known as bit arrays or bit vectors — are a highly compact data structure that stores a list of bits. They are often used to represent a set of integers or an array of booleans.
In
part 1
we started writing a
BitSet
class, and implemented a few basic methods:
class
BitSet
{
private
words
:
number
[
]
;
add
(
index
:
number
)
:
void
;
remove
(
index
:
number
)
:
void
;
has
(
index
:
number
)
:
boolean
}
The bits of our bit set are stored in a
number[]
called
words
. Since JavaScript only
supports 32-bit integers
, each
word
stores 32 bits (the first word stores bits 1-32, the second word stores bits 33-64, and so on).
In this post, we’ll tackle
BitSet.forEach
. We’ll start off implementing the naive approach where we iterate over the bits and see how far we can optimize that approach.
We’ll then learn about
two’s complement
and
Hamming weights
, and how exploiting those lets us iterate over bit sets
really
quickly.
Implementing BitSet.forEach
The
BitSet.forEach
method should invoke a callback for every bit that is set to 1, with the index of that bit.
class
BitSet
{
forEach
(
callback
:
(
index
:
number
)
=>
void
)
{
// ...
}
}
To start, we’ll iterate over every word in
words
:
const
words
=
this
.
words
;
for
(
let
wordIndex
=
0
;
wordIndex
<
words
.
length
;
wordIndex
++
)
{
const
word
=
words
[
wordIndex
]
;
// ...
}
For each word, we’ll run through the bits in ascending order:
for
(
let
i
=
0
;
i
<
WORD_LEN
;
i
++
)
{
// ...
}
WORD_LEN
is set to 32: the number of bits in each
word
We can check whether the bit is set via
(word & (1 << i)) !== 0
:
const
bitIsSetToOne
=
(
word
&
(
1
<<
i
)
)
!==
0
;
If the bit is non-zero, we’ll want to invoke
callback
with the index of the bit:
for
(
let
i
=
0
;
i
<
WORD_LEN
;
i
++
)
{
const
bitIsSetToOne
=
(
word
&
(
1
<<
i
)
)
!==
0
;
if
(
bitIsSetToOne
)
{
callback
(
index
)
//
Cannot find name 'index'.
}
}
We can compute the bit’s
index
in the bit set like so:
const
index
=
(
wordIndex
<<
WORD_LOG
)
+
i
;
WORD_LOG
is set to 5: the base 2 logarithm of 32
The expression
wordIndex << WORD_LOG
is equivalent to
wordIndex * WORD_LEN
because left shifting by one is equivalent to multiplying by 2 (and
2 ** WORD_LOG
equals
WORD_LEN
).
1
<<
WORD_LOG
//
=>
32
3
<<
WORD_LOG
//
=>
96
And so, we have a basic implementation.
class
BitSet
{
forEach
(
callback
:
(
index
:
number
)
=>
void
)
{
const
words
=
this
.
words
;
for
(
let
wordIndex
=
0
;
wordIndex
<
words
.
length
;
wordIndex
++
)
{
const
word
=
words
[
wordIndex
]
;
for
(
let
i
=
0
;
i
<
WORD_LEN
;
i
++
)
{
const
bitIsSetToOne
=
(
word
&
(
1
<<
i
)
)
!==
0
;
if
(
bitIsSetToOne
)
{
const
index
=
(
wordIndex
<<
WORD_LOG
)
+
i
;
callback
(
index
)
;
}
}
}
}
}
Optimizing
BitSet.forEach
We’ve now got a working implementation for
BitSet.forEach
. Can we optimize it further?
The first thing that pops out to me is that we always iterate over every bit in every word. We can skip words with no set bits with a cheap
word === 0
check.
for
(
let
wordIndex
=
0
;
wordIndex
<
words
.
length
;
wordIndex
++
)
{
const
word
=
words
[
wordIndex
]
;
if
(
word
===
0
)
continue
;
// Skip if all bits are 0
// ...
}
This won’t do much for dense sets where most words have some bits set, but this skips a lot of work for sparse sets.
// Sparse set
[
00000000
,
01000000
,
00000000
,
00000000
,
0000001
]
// Dense set
[
11101101
,
01110001
,
10110101
,
11010001
,
0101101
]
But how significant are the performance gains from this optimization? Let’s figure it out by running some benchmarks.
We’ll run our benchmarks for bit sets with various densities:
// From 100% dense (all 1s) to 0.1% dense (mostly 0s)
const
densities
=
[
1
,
0.75
,
0.5
,
0.25
,
0.1
,
0.05
,
0.01
,
0.001
]
;
For each density, we’ll create a bit set with 100 million bits.
const
bitsetsAndDensities
=
densities
.
map
(
(
density
)
=>
(
{
density
,
bitset
:
makeBitSet
(
100_000_000
,
density
)
,
}
)
)
;
The
makeBitSet
method is implemented like so:
function
makeBitSet
(
size
:
number
,
density
:
number
)
{
const
bitset
=
new
BitSet
(
)
;
for
(
let
i
=
0
;
i
<
size
;
i
++
)
{
if
(
Math
.
random
(
)
<
density
)
{
bitset
.
add
(
i
)
;
}
}
return
bitset
;
}
Now that we’ve created our bit sets, we’ll run the
forEach
method for each of them and log out how long it takes.
for
(
const
{
bitset
,
density
}
of
bitsetsAndDensities
)
{
profile
(
(
)
=>
bitset
.
forEach
(
(
)
=>
{
}
)
,
(
time
)
=>
console
.
log
(
`
${
percentage
(
density
)
}
density:
${
time
}
`
)
,
)
;
}
For the unoptimized version, we get:
100.0% density:     95.2 ms
75.0% density:    250.7 ms
50.0% density:    343.3 ms
25.0% density:    221.8 ms
10.0% density:    141.6 ms
1.0% density:     78.5 ms
0.1% density:     66.7 ms
With the
ìf (word === 0) continue;
optimization, we get:
100.0% density:     95.4 ms
75.0% density:    245.5 ms
50.0% density:    336.3 ms
25.0% density:    213.9 ms
10.0% density:    132.4 ms
1.0% density:     34.6 ms
0.1% density:      5.6 ms
Let’s put this into a table and compare the performance:
Unoptimized (baseline)
Skip 0s
Density
Runtime
Speed *
Runtime
Speed *
100.0%
95.2 ms
1.0x
95.4 ms
1.0x
75.0%
250.7 ms
1.0x
245.5 ms
1.0x
50.0%
343.3 ms
1.0x
336.3 ms
1.0x
25.0%
221.8 ms
1.0x
213.9 ms
1.0x
10.0%
141.6 ms
1.0x
132.4 ms
1.0x
5.0%
114.5 ms
1.0x
95.9 ms
1.2x
1.0%
78.5 ms
1.0x
34.6 ms
2.3x
0.1%
66.7 ms
1.0x
5.6 ms
11.9x
* Speed compared to baseline
We observe no significant difference in performance for densities above 10%, but once we reach densities of ≤5% we start to see significant performance improvements:
>2x faster
at 1% density and
>10x faster
at 0.1% density.
Skipping halves
We can take this method of optimization further by skipping
each half
of a word if it’s all 0s. We’ll create bitmasks for each half of a word:
// '0x' is the hexadecimal prefix (base 16).
//
// Each '0' and 'f' denotes four 1s or 0s
export
const
WORD_FIRST_HALF_MASK
=
0x0000ffff
;
export
const
WORD_LATTER_HALF_MASK
=
0xffff0000
;
console
.
log
(
WORD_FIRST_HALF_MASK
)
;
//
=>
0b00000000000000001111111111111111
console
.
log
(
WORD_LATTER_HALF_MASK
)
;
//
=>
0b11111111111111110000000000000000
Using them, we want to
only iterate over bits 1-16 if there are any set bits in the first half, and
only iterate over bits 17-32 if there are any set bits in the latter half.
We can determine whether to iterate over the halves like so:
const
iterFirstHalf
=
(
word
&
WORD_FIRST_HALF_MASK
)
!==
0
;
const
iterLatterHalf
=
(
word
&
WORD_LATTER_HALF_MASK
)
!==
0
;
Which we use to determine the range of bits we iterate over:
const
start
=
iterFirstHalf
?
0
:
WORD_LEN_HALF
;
const
end
=
iterLatterHalf
?
WORD_LEN
:
WORD_LEN_HALF
;
for
(
let
i
=
start
;
i
<
end
;
i
++
)
{
// Check bit...
}
Let’s see the difference this makes:
Unoptimized (baseline)
Skip 0s
Skip 0s and halves
Density
Runtime
Speed *
Runtime
Speed *
Runtime
Speed *
100.0%
95.2 ms
1.0x
95.4 ms
1.0x
99.2 ms
1.0x
75.0%
250.7 ms
1.0x
245.5 ms
1.0x
246.3 ms
1.0x
50.0%
343.3 ms
1.0x
336.3 ms
1.0x
346.3 ms
1.0x
25.0%
221.8 ms
1.0x
213.9 ms
1.0x
215.5 ms
1.0x
10.0%
141.6 ms
1.0x
132.4 ms
1.0x
133.6 ms
1.1x
5.0%
114.5 ms
1.0x
95.9 ms
1.2x
93.7 ms
1.2x
1.0%
78.5 ms
1.0x
34.6 ms
2.3x
28.5 ms
2.8x
0.1%
66.7 ms
1.0x
5.6 ms
11.9x
5.7 ms
11.7x
* Speed compared to baseline
We receive a tiny performance penalty for high-density sets, but we see a slight performance boost for sets at a sweet spot of roughly 1% density.
This optimization may or may not be worth it depending on your average set density, but it doesn’t move the needle all that much.
It was at this point in my bit set journey that I discovered a different approach for iterating over bits that yields significantly better results across all set densities.
Two’s complement
Iterating over individual bits is expensive and requires an
if
statement at each iteration to check whether to invoke the callback or not. This
if
statement creates a
branch
that further degrades performance.
If we were able to somehow “jump” to the next set bit, we would eliminate the need to iterate over 0 bits and perform a bunch of
if
statements.
As it turns out, there’s a very cheap method to find the least significant bit set to 1, which looks like so:
word
&
-
word
When I first saw this, it made no sense to me. I thought:
“Doesn’t making a number negative just set the sign bit to 1?
If so, then
x & -x
just yields
x
.”
That would be true if signed integers were represented using
sign-magnitude
, where the leftmost bit is the sign bit and the rest of the bits denote the value (magnitude).
Numbers represented using sign-magnitude
Positive
Negative
Bits
Value
Bits
Value
00000000
0
10000000
-0
00000001
1
10000001
-1
00000010
2
10000010
-2
00000011
3
10000011
-3
00001001
9
10001001
-9
01111111
127
11111111
-127
But as I learned, signed integers are most commonly represented using
two’s complement
.
Two’s complement is different from sign-magnitude (and
one’s complement
) in that it only has one representation for 0 (there’s no -0).
Numbers represented using two's complement
Positive
Negative
Bits
Value
Bits
Value
00000000
0
00000001
1
11111111
-1
00000010
2
11111110
-2
00000011
3
11111101
-3
00001001
9
11110111
-9
01111111
127
10000001
−127
10000000
−128
The two’s complement of an integer is computed by:
inverting the bits (including the sign bit), and
adding 1 to the number.
00010011
// 19
// Invert bits
11101100
// Add 1
11101101
// -19
Note:
This also works in the opposite direction (from negative to positive)
The binary representation of
19
has a 1 as the least-significant bit. Inverting makes the least significant bit become 0, so adding one will always make the first bit 1. This makes
x & -x
yield the 1st set bit for any number where the least-significant bit is 1.
Let’s take a look at a number with some leading 0s:
00110000
// 48
// Invert bits
11001111
// Add 1
11010000
// -48
Here we observe that all the bits before the least-significant set bit become 1 when inverted. When 1 is added to the number, the 1s are carried until they reach the least-significant 0 (which was the least-significant 1 pre-inversion). This makes
x & -x
yield the 1st set bit for any number with leading 0s.
So when iterating over the bits of a word, we can always find the least significant set bit via
word & -word
. What’s neat is that we can then use bitwise XOR to unset the bit:
while
(
word
!==
0
)
{
const
lsb
=
word
&
-
word
;
word
^=
lsb
;
// Unset the least-significant bit
// With the least-significant bit unset, the next iteration
// will yield the next least-significant set bit.
}
We can now iterate over the set bits of a word, but we’ve got a small problem. We want to invoke the callback with the
index of
the set bits, not the set bits themselves.
We’ll find the index of the set bit through the use of
Hamming weights
.
Hamming weight
Given an integer with one set bit, we want to be able to quickly find the index of said bit:
indexOfFirstSetBit
(
0b00000100
)
//
=>
2
indexOfFirstSetBit
(
0b00000001
)
//
=>
0
indexOfFirstSetBit
(
0b00100000
)
//
=>
5
The brute-force approach would be to walk over the bits one by one, but then we’re back to iterating over bits. That’s a no-go.
One observation to make is that the index of the set bit is equal to the number of leading 0s.
// The index of the set bit is 5, and there are 5 leading 0s
0b00100000
Consider what happens when we subtract 1. The leading 0s turn into 1s, and the set bit becomes unset.
0b00100000
-
1
//
=>
0b00011111
This transforms the problem from finding the index of the set bit in
x
into computing the number of set bits in
x - 1
. The number of non-zero bits is known as the
Hamming weight
, and it turns out that we can
compute the Hamming weight
of an integer very cheaply:
// Returns the number of non-zero bits in `n`
function
hammingWeight
(
n
:
number
)
:
number
{
n
-=
(
n
>>
1
)
&
0x55555555
;
n
=
(
n
&
0x33333333
)
+
(
(
n
>>>
2
)
&
0x33333333
)
;
return
(
(
(
n
+
(
n
>>>
4
)
)
&
0xf0f0f0f
)
*
0x1010101
)
>>
24
;
}
How this works, precisely, is something that we won’t get into. We’ll just trust that this works.
We now have all the pieces we need.
Making BitSet.forEach go fast
As before, we iterate over each word:
class
BitSet
{
forEach
(
callback
:
(
index
:
number
)
=>
void
)
{
const
words
=
this
.
words
;
for
(
let
wordIndex
=
0
;
wordIndex
<
words
.
length
;
wordIndex
++
)
{
let
word
=
words
[
wordIndex
]
;
// ...
}
}
}
While
word
is non-zero, we find the least-significant bit
lsb
:
while
(
word
!==
0
)
{
const
lsb
=
word
&
-
word
;
// ...
}
Using
lsb
we can compute the index using the hamming weight of
lsb - 1
:
const
index
=
(
wordIndex
<<
WORD_LOG
)
+
hammingWeight
(
lsb
-
1
)
;
callback
(
index
)
;
Before the next iteration, we unset the least significant bit via
word XOR lsb
, making
word
ready for the next iteration:
word
^=
lsb
;
The full implementation looks like so:
forEach
(
callback
:
(
index
:
number
)
=>
void
)
{
const
words
=
this
.
words
;
for
(
let
wordIndex
=
0
;
wordIndex
<
words
.
length
;
wordIndex
++
)
{
let
word
=
words
[
wordIndex
]
;
while
(
word
!==
0
)
{
const
lsb
=
word
&
-
word
;
const
index
=
(
wordIndex
<<
WORD_LOG
)
+
hammingWeight
(
lsb
-
1
)
;
callback
(
index
)
;
word
^=
lsb
;
}
}
}
But how fast is this optimized version? Let’s run our benchmark and compare.
Unoptimized (baseline)
Skip 0s
Optimized
Density
Runtime
Speed *
Runtime
Speed *
Runtime
Speed *
100.0%
95.2 ms
1.0x
95.4 ms
1.0x
53.4 ms
1.8x
75.0%
250.7 ms
1.0x
245.5 ms
1.0x
91.9 ms
2.7x
50.0%
343.3 ms
1.0x
336.3 ms
1.0x
68.4 ms
5.0x
25.0%
221.8 ms
1.0x
213.9 ms
1.0x
44.4 ms
5.0x
10.0%
141.6 ms
1.0x
132.4 ms
1.0x
30.1 ms
4.7x
5.0%
114.5 ms
1.0x
95.9 ms
1.2x
24.8 ms
4.6x
1.0%
78.5 ms
1.0x
34.6 ms
2.3x
10.0 ms
7.8x
0.1%
66.7 ms
1.0x
5.6 ms
11.9x
4.0 ms
16.7x
* Speed compared to baseline
For densities of 5-50%, we receive a
~5x increase in performance
. Higher densities of 75% and above receive a notable speedup of >2x, while the densities below 5% see a
5-17x increase in performance
.
A full BitSet implementation
I’ve recently published a performant and feature-complete
BitSet
package
on npm
.
If you want to explore the full implementation, take a look at the
GitHub repo
.
Further reading
Daniel Lemire
has written
lots
of
posts
about bit sets. His
FastBitSet
implementation
is where I discovered this trick for optimizing over set bits. If you’re into software performance, he’s written
a lot
on that topic.
Parting thoughts
Any given piece of code can be optimized, but taking a different approach will often outperform those local optimizations.
Different algorithms will often favor some inputs over others, as we saw with low vs high-density sets in this post. It’s useful to keep these sorts of trade-offs in mind when considering which way to go. Benchmark when possible!
Anyway, thanks for reading this short series on bit set! If you haven’t read part 1 yet, you can find it here:
Bit Sets: An introduction to bit manipulation
.
I may write a part 3, taking an in-depth look at bit set performance for boolean operations (and, or, xor, andNot, etc), but I’ve thought about bit sets quite enough for now.
— Alex Harri
Mailing list
To be notified of new posts, subscribe to my mailing list.
Subscribe","Jan 6, 2024"
Bit Sets: An introduction to bit manipulation,"Bit sets
— also known as bit arrays or bit vectors — are a highly compact data structure that stores a list of bits. They are often used to represent a set of integers or an array of booleans.
In addition to their memory-compactness, bit sets support extremely performant boolean operations like
unions
and
intersections
, achieved through the use of
bitwise operations
.
In this 2-part series on bit sets, we’ll walk through implementing a
BitSet
from scratch in JavaScript.
This post covers the basics of bitwise operators and bit manipulation. We’ll use that knowledge to implement a basic
BitSet
class.
In part 2
we’ll add the ability to iterate over bit sets extremely quickly by exploiting
two’s complement
and
Hamming weights
.
The post assumes that you’re somewhat familiar with
binary numbers
, so refresh your memory if you haven’t used them for a while.
With that out of the way, let’s get started!
Bit masks
Bit masks
allow us to compactly store multiple booleans in a single number. You may know bit masks as
bit flags
or
bit fields
.
// This binary number...
00001001
// ...is equivalent to this array of booleans
[
true
,
false
,
false
,
true
,
false
,
false
,
false
,
false
]
Binary numbers are read right-to-left, following
bit ordering
from least-significant to most-significant
Each bit in the bit mask corresponds to a single boolean — 1 representing true, and 0 representing false.
In the following example, we’ll represent a user’s permissions using a bit mask. Certain positions in the bit mask correspond to specific permissions (e.g.
READ
or
WRITE
). If the corresponding bit is set to 1, the user has the permission, otherwise, they don’t.
// The '0b' prefix denotes a binary numbers
const
READ
=
0b0001
;
const
UPDATE
=
0b0010
;
const
CREATE
=
0b0100
;
const
DELETE
=
0b1000
;
function
canRead
(
permissions
:
number
)
{
return
(
permissions
&
READ
)
!==
0
;
}
function
canUpdate
(
permissions
:
number
)
{
return
(
permissions
&
UPDATE
)
!==
0
;
}
canRead
(
0b1100
)
;
//
=>
false
canRead
(
0b0101
)
;
//
=>
true
&
is the
bitwise AND operator
. It returns a new number where the bits are set to 1 if both of the input bits are 1.
Input
0101
0101
0101
Bit
mask
&
0001
&
0010
&
0100
--
--
--
--
--
--
--
--
--
--
--
--
--
--
--
--
--
--
Output
0001
0000
0100
If the input numbers have no bits in common with the bit mask, the
&
operation will yield 0.
const
BIT_MASK
=
0b0010
;
function
secondBitIsSetToOne
(
input
:
number
)
{
return
(
input
&
BIT_MASK
)
!==
0
;
}
|
is another operator, representing
bitwise OR
. It returns a new number where the bits are set to one if either of the input bits is 0.
Input
0101
0101
0101
Bit
mask
|
0001
|
0010
|
0100
--
--
--
--
--
--
--
--
--
--
--
--
--
--
--
--
--
--
Output
0101
0111
0101
We can use it to, for example, set specific bits to one.
const
READ
=
0b0001
;
function
addReadPermission
(
permissions
:
number
)
{
return
permissions
|
READ
;
}
addReadPermission
(
0b0010
)
;
//
=>
0b0011
We can now add permissions, but what about removing them?
We can set bits to 0 through the use of the
bitwise NOT
operator
~
, a
unary
operator that flips all of the bits in the number:
Unary means that it takes a single operand, as opposed to two.
Input
~
0101
~
1000
~
0001
--
--
--
--
--
--
--
--
--
--
--
--
--
--
--
-
Output
1010
0111
1110
We can use NOT to create an
inverse bit mask
that passes through all but one bit:
const
READ
=
0b0001
;
const
UPDATE
=
0b0010
;
console
.
log
(
~
READ
)
//
=>
0b1110
console
.
log
(
~
UPDATE
)
//
=>
0b1101
Using this in conjunction with AND, we can set specific bits to zero:
const
READ
=
0b0001
;
function
removeReadPermission
(
permissions
:
number
)
{
return
permissions
&
~
READ
;
}
removeReadPermission
(
0b0011
)
;
//
=>
0b0010
We can also create groups of permissions using OR:
const
OWNER
=
READ
|
UPDATE
|
CREATE
|
DELETE
;
// 0b1111
const
EDITOR
=
READ
|
UPDATE
|
CREATE
;
// 0b1011
const
VIEWER
=
READ
;
// 0b0001
And use them to see if a user has a set of permissions, or provide a user with a set of permissions:
function
isEditor
(
permissions
:
number
)
{
return
(
permissions
&
EDITOR
)
===
EDITOR
;
}
function
addEditorPermissions
(
permissions
:
number
)
{
return
permissions
|
EDITOR
;
}
We can also see which permissions users have in common:
function
commonPermissions
(
a
:
number
,
b
:
number
)
{
return
a
&
b
;
}
Limits of bit masks
Bit masks are great, but their capacity is limited. JavaScript only
supports 32-bit integers
, so a bit mask can only store 32 bits.
This is where bit sets come in. Once you need to store more than 32 booleans (or 64, depending on the language) you can use an array of integers to make the number of bits
arbitrarily
large.
[
0b00010011
,
0b01100000
,
...
]
Implementing a bit set
The integers that store the bits of our bit set are called
words
, so we’ll store a
words
array in our
BitSet
class.
class
BitSet
{
private
words
:
number
[
]
;
}
Any set data structure will need a few basic operations:
Add an element
Remove an element
Check for the presence of an element
The elements of a bit set are non-negative integers that correspond to a bit index. If the bit at index
N
is set to 1, then
N
is considered to be
in
the set.
Considering that, we can create a skeleton for our
BitSet
class:
class
BitSet
{
private
words
:
number
[
]
;
add
(
index
:
number
)
{
// Set some bit to '1'
}
remove
(
index
:
number
)
{
// Set some bit to '0'
}
has
(
index
:
number
)
{
// Return true if some bit is set to '1'
}
}
Each bit will be stored in some individual
word
in
words
. Consider how the
words
array is structured:
[
00000000
,
00000000
,
00000000
,
00000000
]
// The `0b` prefix is omitted for clarity, and we're using
// 8 bits instead of 32 for readability
We can map each bit to an absolute index:
[
00000000
,
00000000
,
00000000
,
00000000
]
│││││││└
0
│││││││└
8
│││││││└
16
│││││││└
24
││││││└─
1
││││││└─
9
││││││└─
17
││││││└─
25
│││││└──
2
│││││└──
10
│││││└──
18
│││││└──
26
││││└───
3
││││└───
11
││││└───
19
││││└───
27
│││└────
4
│││└────
12
│││└────
20
│││└────
28
││└─────
5
││└─────
13
││└─────
21
││└─────
29
│└──────
6
│└──────
14
│└──────
22
│└──────
30
└───────
7
└───────
15
└───────
23
└───────
31
Each word is indexed right-to-left, following
bit ordering
from least-significant to most-significant
But to find a single bit in a specific
word
, we need to convert the input index into two indices:
The index of the
word
in
words
.
The index of the bit in
word
.
//   word 0    word 1    word 2    word 3
[
00000000
,
00000000
,
00000000
,
00000000
]
// 76543210  76543210  76543210  76543210
Parsing an input index
Since JavaScript only supports
32-bit integers
, we’ll define a
WORD_LEN
constant with the value 32.
const
WORD_LEN
=
32
;
Because
WORD_LEN
is a power of two, the bit index within the
word
will be the
log2(WORD_LEN)
least significant bits of
index
, which yields a value of 5.
Math
.
log2
(
WORD_LEN
)
//
=>
5
0b00000
//
=>
0 (1st bit)
0b11111
//
=>
31 (32nd bit)
The rest of the bits in
index
(leftmost) specify the word index.
00000000000
// word index
~
~
~
~
~
~
~
~
~
~
~
0000000000000000
// input index
~
~
~
~
~
00000
// bit index
When all of the bits in the bit index region are set to 1, we get a word index of 0 and a bit index of 31, corresponding to the 32nd bit.
00000000000
=
0
// word index
~
~
~
~
~
~
~
~
~
~
~
0000000000011111
=
31
// input index
~
~
~
~
~
11111
=
31
// bit index
// 32nd bit
If we increment the input index by 1, we get a word index of 1 and a bit index of 0, corresponding to the 33rd bit.
00000000001
=
1
// word index
~
~
~
~
~
~
~
~
~
~
~
0000000000100000
=
32
// input index
~
~
~
~
~
00000
=
0
// bit index
// 33rd bit
This works for any input index. An input
index
of 100 corresponds to
0b1100100
in binary. Broken down, we get a word index of 3 and a bit index of 4, corresponding to the 101st bit.
00000000011
=
3
// word index
~
~
~
~
~
~
~
~
~
~
~
0000000001100100
=
100
// input index
~
~
~
~
~
00100
=
4
// bit index
// 101st bit
We can verify this by computing
(3 * 32) + 4
:
const
wordIndex
=
3
;
const
bitIndex
=
4
;
(
wordIndex
*
32
)
+
bitIndex
//
=>
100
So to compute the word index, we need to shift the bits in the input index right by 5 (i.e.
log2(WORD_LEN)
) so that the word index bits become the rightmost (least-significant) bits.
We can do this with the
>>
operator.
const
wordIndex
=
index
>>
5
;
>>
is the
bitwise right shift
operator. It returns the input number with its bits shifted right by N places:
const
input
=
0b01100100
;
input
>>
5
//
=>
0b00000011
This can be illustrated like so:
// This expression...
0b01100100
>>
5
// ...corresponds to the following
01100100
011
>>>
>>
>>>
>>
011
00000011
As we learned earlier, the number 5 corresponds to the base 2 logarithm of 32.
Math
.
log2
(
32
)
//
=>
5
Let’s put it in a
WORD_LOG
constant for readability.
const
WORD_LEN
=
32
;
const
WORD_LOG
=
Math
.
log2
(
WORD_LEN
)
;
Computing the bit index is quite simple: we take the 5 least-significant bits from
index
using bitwise AND:
const
bitIndex
=
index
&
0b11111
;
This sets any bits left of the 5 least significant bits to zero.
And with that, we know how to parse an input
index
into word and bit indices:
const
wordIndex
=
index
>>
WORD_LOG
;
const
bitIndex
=
index
&
0b11111
;
We can now get to implementing some of the methods of
BitSet
!
BitSet.add
The
add
method should set the bit at
index
to 1. This bit will live in some individual
word
, which we can access via
wordIndex
:
class
BitSet
{
add
(
index
:
number
)
{
const
wordIndex
=
index
>>
WORD_LOG
;
const
bitIndex
=
index
&
0b11111
;
// ...
}
}
Given an integer, we can set the bit at a specific index to 1 like so:
function
setBitAtIndexToOne
(
input
:
number
,
index
:
number
)
{
return
input
|
(
1
<<
index
)
;
}
setBitAtIndexToOne
(
0b00000000
,
2
)
;
//
=>
0b00000100
setBitAtIndexToOne
(
0b00000000
,
5
)
;
//
=>
0b00100000
<<
is the
bitwise left shift
operator, which returns the input number with its bits shifted left by N places.
The expression
1 << index
creates a bit mask with the bit at
index
set to one.
1
<<
2
;
//
=>
0b00000100
1
<<
0
;
//
=>
0b00000001
1
<<
6
;
//
=>
0b01000000
Applying this bit mask to our word using bitwise OR will set the bit at
bitIndex
to 1.
this
.
words
[
wordIndex
]
|=
(
1
<<
bitIndex
)
;
With that, we have our implementation:
class
BitSet
{
add
(
index
:
number
)
{
const
wordIndex
=
index
>>
WORD_LOG
;
const
bitIndex
=
index
&
0b11111
;
this
.
words
[
wordIndex
]
|=
(
1
<<
bitIndex
)
;
}
}
However, there is one simplification we can make. Because the bitwise shift operators
<<
and
>>
operate on 32-bit integers, the maximum shift possible is 31 (from 32nd to 1st bit, or 1st to 32nd bit).
The
ECMAScript standard states
:
Let shiftCount be ℝ(rnum) modulo 32.
In other words, only read the 5 least-significant bits which represent 0 to 31; all other bits are dismissed. This means that we don’t need to compute
bitIndex
and can left shift on
index
directly.
class
BitSet
{
add
(
index
:
number
)
{
const
wordIndex
=
index
>>
WORD_LOG
;
this
.
words
[
wordIndex
]
|=
(
1
<<
index
)
;
}
}
BitSet.remove
In implementing
BitSet.remove
, we want to set a specific bit to zero. We’ve already seen how this was done in a previous example:
const
READ
=
0b0001
;
function
removeReadPermission
(
permissions
:
number
)
{
return
permissions
&
~
READ
;
}
removeReadPermission
(
0b0011
)
;
//
=>
0b0010
As we did in
BitSet.add
, we’ll use
1 << index
to create a bit mask for a specific bit.
1
<<
4
//
=>
0b00010000
We then invert that bit mask using bitwise NOT:
~
(
1
<<
4
)
//
=>
0b11101111
And then apply this inverse bit mask via bitwise AND:
const
word
=
0b01111100
;
word
&
~
(
1
<<
4
)
//
=>
0b01101100
With that, our implementation of
BitSet.remove
looks like so:
class
BitSet
{
remove
(
index
:
number
)
{
const
wordIndex
=
index
>>
WORD_LOG
;
this
.
words
[
wordIndex
]
&=
~
(
1
<<
index
)
;
}
}
BitSet.has
The
BitSet.has
method should return true if a specific bit is set to 1, and false otherwise.
We saw how this is done earlier in this post:
const
READ
=
0b0001
;
function
canRead
(
permissions
:
number
)
{
return
(
permissions
&
READ
)
!==
0
;
}
As before, we create a bit mask using left shift and apply it using bitwise AND.
const
word
=
0b11011100
;
word
&
(
1
<<
4
)
//
=>
0b00010000
If the result is non-zero, the bit is set to 1.
class
BitSet
{
has
(
index
:
number
)
{
const
wordIndex
=
index
>>
WORD_LOG
;
return
(
this
.
words
[
wordIndex
]
&
(
1
<<
index
)
)
!==
0
;
}
}
Handling edge cases
One easy edge case to run into is
wordIndex
being out-of-bounds. That problem can be resolved by adding a
resize
method that ensures that the
words
array encompasses
wordIndex
:
class
BitSet
{
set
(
index
:
number
)
{
const
wordIndex
=
index
>>
WORD_LOG
;
this
.
resize
(
wordIndex
)
;
// ...
}
private
resize
(
wordIndex
:
number
)
{
// Make 'this.words' encompass 'wordIndex'
}
}
I won’t cover other edge cases in this post. If you’re interested, feel free to explore
my full implementation of
BitSet
on GitHub
.
Next up: Iteration
We covered a lot of ground in this post!
Next up in our bit set journey is iterating over bits. We’ll learn how exploiting
two’s complement
and
Hamming weights
enables us to make our iteration extremely fast!
See you in part 2:
Iterating over Bit Sets quickly
— Alex Harri
Mailing list
To be notified of new posts, subscribe to my mailing list.
Subscribe","Jan 6, 2024"
Making GRID’s spreadsheet engine 10% faster,"GRID’s product sports a feature-complete spreadsheet engine running in the browser, with advanced features such as
spilling
,
iterative calculation
, and the
QUERY
function
. It’s a beaut.
The Engine Team regularly handles customer care requests relating to bugs and performance issues in spreadsheets. Last June, I took a look at a particularly large and complicated spreadsheet where a write to a single cell caused ~12.000 cells to be recalculated. The recalculation took >700ms to execute on my machine (M1 Pro).
Profiling the recalculation, about 12.5% of the time was spent in a method called
_makeCalcCellEvaluationContext
.
In this post, we’ll explore the techniques I used to take this time to near zero.
GRID’s Spreadsheet Engine
Spreadsheets have
a lot
of use cases, ranging from budget management and attendance sheets, all the way to complex financial models. At the heart of the more complex models are dependencies. Cells depending on other cells.
A mortgage calculator may have cells depending, directly or indirectly, on a cell representing an
Interest Rate
.
In a spreadsheet to calculate marketing spend, you might instead have
Cost-per-Click
and
Conversion Rate
variables.
An example of what the inputs to a mortgage calculator might look like
Different scenarios are modeled by adjusting the inputs and seeing how the model reacts.
How high do the payments become when I reduce the loan term by X?
What if the interest rate rises to 9%?
For the model to “react” to changes in an input cell:
Cells depending on the changed input cell need to be recalculated.
To find the cell’s dependents, the model employs a dependency graph.
This cycle of recalculating dependents occurs recursively. A cell’s value changing when recalculated causes cells depending on it to be recalculated, and so forth. In the following example, every cell — except the first cell — depends on the preceding cell, forming a chain of calculations.
What you’re looking at is a GRID document, containing a graph powered by this underlying spreadsheet:
While this spreadsheet is small, more complex models often contain tens or hundreds of thousands of cells.
A single output cell is often the product of calculations encompassing dozens of thousands of cells. And the reverse: A single input cell is often used — directly or indirectly — in the majority of calculations in a spreadsheet.
The cost of recalculation
The cost of recalculation can be split into two distinct parts:
Determining which cells to recalculate, and in which order.
Recalculating cells.
The recalculation of cells can further be split up into the
fixed cost
associated with recalculating a cell, and the
variable cost
associated with recalculating a cell.
The variable cost is more immediately obvious: A cell invoking an expensive function like
QUERY
on a large dataset will take longer to recalculate than a cell adding two numbers together.
# This will take a while
=QUERY(A:E, ""select Name, Age where Age > 18 order by Name desc"");
# This will take no time at all
=SUM(A1, B1)
For the most part, the variable cost is derived from how expensive the cell’s user-written formula is.
The fixed cost arises from setting up the context needed to evaluate the formula. For example, when evaluating a reference like
A1
, the engine needs a bit of context to know which workbook and sheet to resolve the reference to.
Given that the following formulas are written in
Sheet1
in
workbook.xlsx
:
# Resolves to '[workbook.xlsx]Sheet1!A1'
=A1
# Resolves to '[workbook.xlsx]Sheet2!A1'
=Sheet2!A1
# Resolves to '[wb2.xlsx]Sheet3!A1'
=[wb2.xlsx]Sheet3!A1
In addition to the current workbook and sheet, there’s other contextual information that the engine
may
require during recalculation. For example:
When using structured references without a table name such as
[[#This row], [Value]]
, the engine needs to resolve the table encompassing the cell.
Because Excel and Google Sheets implement some (
a lot
) of functions differently, GRID has Excel and Google Sheets modes for compatibility. Spreadsheet functions need to be able to resolve the current mode to match mode-specific behaviors.
To provide this contextual information, the engine constructs an object called the
evaluation context
in a method called
_makeCalcCellEvaluationContext
. This is what we see taking 12.5% of recalculation time.
Constructing the evaluation context is done once for each cell, and the cost of doing so is the same for every cell, which constitutes the fixed cost associated with recalculating a cell.
The proportion of the total work that is spent constructing the evaluation context depends on how high the variable cost (formula evaluation) is. In workbooks with fewer, more expensive formulas, the variable cost dominates over the fixed cost.
Evaluating the fixed cost
When recalculating a cell, the evaluation context is created and passed to a function that evaluates the cell’s formula (more specifically, evaluates the formula’s
AST
).
const
ctx
=
this
.
_makeCalcCellEvaluationContext
(
cell
,
ref
,
...
)
;
const
value
=
evaluateAST
(
cell
,
ctx
)
;
The
_makeCalcCellEvaluationContext
method exists on the
Workbook
class, with the implementation along the lines of:
class
Workbook
implements
EvaluationContext
{
_makeCalcCellEvaluationContext
(
cell
:
Cell
,
ref
:
Reference
,
...
)
{
// These properties and methods read the
// arguments 'cell', 'ref', etc.
const
property1
=
...
;
const
property2
=
...
;
const
method1
=
(
)
=>
{
...
}
;
const
method2
=
(
)
=>
{
...
}
;
// ...
const
evaluationContext
:
EvaluationContext
=
{
...
this
,
property1
,
property2
,
method1
,
method2
,
// ...
}
;
return
evaluationContext
}
}
A key observation is that not all of the properties and methods are necessarily used.
Whether a piece of information is used during evaluation depends entirely on the cell’s formula, and the functions it invokes. By computing all properties ahead of time, we expend a fixed amount of effort for a variable amount of benefit.
In addition, the
Workbook
class is quite large, containing >30 methods and properties. Assigning those to a new object is costly.
Eliminating the fixed cost
As with any performance optimization, the solution is doing less work.
The first way to do less work is to lazily compute information, which we implemented through the use of getters.
const
method1
=
...
;
const
method2
=
...
;
const
evaluationContext
:
EvaluationContext
=
{
...
this
,
get
property1
(
)
{
...
}
,
get
property2
(
)
{
...
}
,
method1
,
method2
,
// ...
}
;
return
evaluationContext
Now we only compute properties if they’re actually used.
To avoid assigning
this
into a new object over and over, we created a single shared evaluation context object, encapsulated in a new
CellEvaluator
class.
class
CellEvaluator
{
private
evaluationContext
:
EvaluationContext
;
private
cell
:
Cell
;
private
ref
:
Reference
;
// ...
constructor
(
workbook
:
Workbook
)
{
const
self
=
this
;
this
.
evaluationContext
=
Object
.
freeze
(
{
...
workbook
,
// The getters and methods access `cell`, `ref` (etc)
// via `self.{key}`
get
property1
(
)
{
...
}
,
get
property2
(
)
{
...
}
,
method1
(
)
{
...
}
,
method2
(
)
{
...
}
,
}
)
;
}
evaluate
(
cell
:
Cell
,
ref
:
Reference
,
...
)
{
this
.
cell
=
cell
;
this
.
ref
=
ref
;
// ...
return
evaluateAST
(
cell
,
this
.
evaluationContext
)
;
}
}
The dynamic portion of the evaluation context (
cell
,
ref
, etc) is placed into private properties on
CellEvaluator
, accessible via the
self
reference. By mutating those properties, we effectively create a new evaluation context without creating a new object instance.
By only creating a single shared evaluation context object, we avoid spreading the workbook into a new object repeatedly — which also creates less work for the garbage collector.
As a small side benefit, the code for recalculation became a
tad
simpler:
// Before
const
ctx
=
this
.
_makeCalcCellEvaluationContext
(
cell
,
ref
,
...
)
;
const
value
=
evaluateAST
(
cell
,
ctx
)
;
// After
const
value
=
this
.
cellEvaluator
.
evaluate
(
cell
,
ref
,
...
)
;
Evaluating the impact
The Engine Team has developed a performance and regression testing suite for its spreadsheet engine. It runs on real public GRID documents, on which it performs a series of tests measuring:
Initialization time
Write duration (recalculation performance)
Discrepancies (expected vs actual output)
This suite enables the Engine Team to evaluate the performance impact of changes and detect discrepancies that our unit tests might fail to detect.
Running GRID’s performance tests on this change shows that it yields, roughly, a 10% performance boost.
Proportional differences from baseline
Median -9.92%
Weighted geometric mean -9.58%
74.9% decreased to <0.97x, 0.92% increased to >1.03x
59.8% decreased to <0.93x, 0 increased to >1.08x
0.34% decreased to <0.71x, 0 increased to >1.4x
0.04% decreased to <0.5x, 0 increased to >2x
1% -24.3% | 10% -17.6% | 90% -0.153% | 99% +2.93%
Extremes:
-70.5% (from 148 ms to 43.5 ms)
-52.6% (from 589 ms to 279 ms)
+5.94% (from 55.4 ms to 58.7 ms)
+6.60% (from 89.7 ms to 95.6 ms)
Conclusion
Aside from the positive effect this change had on GRID’s performance, I think it serves as a useful example to think about performance:
Which information do we need to evaluate now, and which can we evaluate later?
What is the fixed cost associated with performing this operation?
Do we need to do this work in the first place?
Can we cache the result of this operation? How does that impact memory usage?
Bear in mind that changes yielding a performance boost in some cases might cause degraded performance in others. Consider the worst case scenario and the circumstances under which it might occur.
As an example, the change from static properties to getters creates a worst-case scenario in which formulas repeatedly evaluate the same piece of information. This is the likely cause of the degraded performance we saw in a few documents (aside from noise). Maybe that could be mitigated with caching!
Anyway, I hope this served as an interesting read. Maybe you got some ideas that you can apply to your own code!
— Alex Harri
Big thank you to
Gunnlaugur Þór Briem
and
Hjálmar Gíslason
for reading the draft of this post and providing feedback!
PS: Check out
GRID
! It’s a fantastic tool for, amongst other things, building interactive documents on top of your spreadsheets.
Mailing list
To be notified of new posts, subscribe to my mailing list.
Subscribe","Oct 11, 2023"
"Moving to a monorepo: Yes, but how?","Monorepos have been a hot topic in the JavaScript community for a while now. I’ve heard quite a bit about their pros and cons, and you probably have too.
However, if you’ve decided to move to a monorepo it’s not necessarily obvious how to go about it. There are lots of boilerplate examples online, which is great. But what if you want to move existing repositories?
This post is intended as a rough playbook for migrating your existing repositories to a monorepo. Having done that at two different companies, I’ve found a pretty good approach.
Merging repositories
Instead of creating a new repository for the monorepo, I would recommend picking one of your existing repositories as the monorepo destination. The other repositories will then be merged into it, one by one.
Taking this approach, the first step in establishing the monorepo will be merging a different repository (
B
) into the repository that will become the monorepo (
A
).
Reusing an existing repository minimizes disruptions to in-flight pull requests for that repository, and avoids having to set up the processes and settings for the repo again.
For this reason, I would advise picking the most active repository as the monorepo destination.
Directory structure
Before the merge, decide what you want the directory structure to look like once the repositories have been merged.
Most standalone repositories tend to have a directory structure along these lines:
# Application code
src/
# External dependencies
package.json
# Various config files
tsconfig.json
In a multi-app monorepo, the two main differences are that:
You have multiple apps, each in their own directory.
There is likely a directory containing shared code libraries.
# Application code (and app-specific config files)
apps/
[
app-name
]
/
# Shared code libraries
packages/
[
package-name
]
/
# External dependencies
package.json
# Various config files
tsconfig.json
The
packages/
directory will naturally be created as you extract common logic from your applications into shared code libraries.
However, we’ll need to merge the other categories of files when moving to the monorepo. Let’s take a look at how we can go about merging each of them.
The source code directory
External dependencies
Config files
The source code directory
Most repositories hve a single directory, containing the application code for the project, while the configuration and build files typically live in the root (or root-level directories). We’ll call the application code directory
src/
.
The
src/
directory is the easiest to handle. The
src/
directory for each repository is moved to
apps/[app-name]/src/
.
As a rule of thumb, we can consider each directory under
apps
to be an independently deployed project.
Some repositories may have multiple directories containing application code (e.g. Next.js projects with
pages/
and
components/
directories), but those are migrated in the same manner as the
src/
directory in the example above.
External dependencies
There are two ways to go about external dependencies in a monorepo.
A single-version policy
A per-app version policy
Single-version policy
Migrating to a single-version policy is harder up-front. It involves merging the list of dependencies for each project into a single list of dependencies.
This can be difficult if your repositories are using different versions of the same dependency.
Per-app version policy
Under a per-app policy, each app specifies its own dependencies via its
package.json
file. This means that the
package.json
files can mostly be migrated as-is in the same manner as the
src/
directory.
But you also need to consider the versions of external dependencies that your shared code in
packages/
will use.
If packages don’t specify their dependencies, then the interface and behavior of those dependencies will be determined by the app that imports the package. That’s a recipe for disaster, so your packages will also need to specify dependencies
This introduces some problems for the apps making use of shared packages.
Bundle size
When different packages can specify different versions of dependencies, multiple versions of dependencies may be included in the JS bundle sent to the client. This can easily go undetected.
Singletons
A lot of libraries export singletons with shared state, for example, the
Router
class in Next.js.
Singletons imported from such libraries are no longer guaranteed to be singletons globally. Each version of the library instantiates and exports its own singletons. This leads to very tricky bugs.
Tech debt accumulation
When developers need to upgrade a dependency in one project, it’s tempting to skip upgrading the dependency for all projects.
This inevitably leads to the dependencies of some projects slowly drifting out of date.
TL;DR: Use a single-version policy
In addition to eliminating the aforementioned problems, there are numerous benefits to a single-version policy.
External dependencies work the same in every project, making working across projects easier.
Common logic in your applications can more easily be extracted to shared packages.
In being able to make more assumptions, tooling and infrastructure can be simplified.
The main drawback of a single-version policy is that upgrading dependencies becomes harder. Every app and package making direct use of the dependency being upgraded will need to be updated.
However, the difficulty of upgrades can be circumvented by creating packages that abstract away the API of external dependencies. Using this approach, only the package that is abstracting away the dependency needs to be touched.
Config files
One of the core reasons for moving to a monorepo tends to be reducing friction and making cross-project work easier. A developer moving from one project to another should be able to get up to speed and be productive quickly.
This becomes easier when differences across projects are minimal.
In a monorepo, project-specific configuration should be as minimal as possible. For your monorepo, create config files in the root and extend those in project-specific config files.
{
""extends""
:
""../../tsconfig.base.json""
,
""compilerOptions""
:
{
""rootDir""
:
""./""
,
}
,
""include""
:
[
""src/**/*.ts""
]
}
The project-specific config files should be kept as small and simple as possible.
Before merging the repositories, each repository will contain its own config files. We will want to combine config files that exist in both repositories into common config files in the root.
There will be some differences, which you can resolve by creating project-specific config files that extend the root and override as needed.
You can try to resolve minor differences, but don’t go overboard. Trying to resolve every difference will suck up a lot of time and make it harder for the merge to pass review. Be practical and override where needed. The configs can be unified over time.
Merging the repositories
We have two standalone repositories,
A
and
B
, which we intend to move to a monorepo.
A
has been designated to become the monorepo destination, so we will be merging
B
into
A
.
Create a branch in each repository where the directory structure is “as-if” the repositories were already merged. Make sure that everything still works (CI is green, scripts work as expected).
Once the directory structure is ready, we have two “pre-merge” branches ready:
prepare-merge-b
in repo
A
merge-into-a
in repo
B
Let’s zoom out and take a look at the next steps.
The process can be described like so:
Create pre-merge branches for
A
and
B
.
Create a branch from the pre-merge branch in
A
and merge
B
into it (we’ll get to how later).
Resolve the differences and get everything working.
Separating these stages makes the code review phase easier by making the changes made in each phase independently reviewable.
Diff 1 and 2 enable reviewing the changes made when changing the directory structure.
Diff 3 enables reviewing the changes made in connecting
A
and
B
and getting everything working.
Merging repositories is quite noisy, and reviewing a single “big-bang” PR is very hard. Even though the changes will all be merged into
A
at the same time, we can still review them separately.
Retaining Git history
Copy-paste is not the way to go because the Git history of
B
would be lost. Git has a way to merge repositories without losing history.
Given that you are in repository
A
, you can merge
B
into
A
like so:
git
checkout merge-b
git
remote
add
app-b
<
URL of repo B
>
git
fetch app-b
git
merge app-b/merge-into-a
--allow-unrelated-histories
We can break this down like so:
# Go to the branch that we want to merge B into
git
checkout merge-b
# Add repository B as a remote. In this example, we're
# adding B as a remote under the name `app-b`.
git
remote
add
app-b
<
URL of repo B
>
# Fetch the branches in B
git
fetch app-b
# Merge the branch named `merge-into-a` from B (`app-b`)
# into the current branch
git
merge app-b/merge-into-a
# The `--allow-unrelated-histories` option is a way to
# make Git allow us to merge A and B, despite them
# sharing no history
--allow-unrelated-histories
After the merge
The
merge-b
branch now contains the files from
B
’s pre-merge branch. The next step is getting everything hooked up and working. Before doing that, create a
connect-b
branch from the
merge-b
branch to be able to review those changes separately, as mentioned earlier.
Most notably, you will need to get the existing CI/CD pipelines for both projects working together. Once the CI pipelines are green and you’ve got everything working, we can put your changes up for review.
CI/CD in a monorepo
The hardest technical challenge for monorepos is the CI/CD pipeline. Over time, things will slow to a crawl under a
“run everything, always”
approach.
You can test and build the apps in parallel to speed things up. However, this can get very expensive in CI minutes. At some point, monorepos have to start only running CI/CD for the apps affected by the change.
But be practical. While there are only two projects in the monorepo, running the CI pipelines for both apps while getting the monorepo up and running is perfectly fine. But as the monorepo grows, this becomes untenable.
Monorepo tooling
You don’t need a monorepo tool, though they certainly help.
I’ve had a positive experience with
Nx
before. Its
print-affected
command allows you to see which apps were affected by the changes between two commits or branches. Really useful for CI/CD!
Nx has a suite of features geared towards monorepos. But keep in mind, you don’t have to buy into a monorepo tool wholesale. In the monorepo I set up at a previous workplace, we only used the
print-affected
command from Nx. Nothing else.
A notable competitor in the JS monorepo space has been
Turborepo
. I don’t have personal experience with it yet, but I’ve heard good things about it.
Final words
Moving existing repositories to a monorepo is not a trivial task. I hope this post provided you with insight into how you might go about that process yourself.
Mailing list
To be notified of new posts, subscribe to my mailing list.
Subscribe","June 11, 2023"
Multi-cursor code editing: An animated introduction,"When editing text, especially structured text, the need occurs to make repeated changes in multiple locations. A common case is renaming a variable.
Loading editor...
Play
Play again
View steps
Select and type, select and type.
For a small block of code it’s fine. A bit tedious, but fine. Banging this out doesn’t take a lot of time.
However, the number of keystrokes grows linearly. Increasing the number of references to a few dozens already makes the task quite taxing.
We want the effort for repeated changes to grow in a non-linear fashion. We can do that using
Command
D
.
Loading editor...
Play
Play again
View steps
Note:
This post is focused on VS Code, but
Command
D
can be used in other text editors such as Sublime Text. Other text editors will have analogous keyboard shortcuts.
Command
D
selects the next instance of whatever you have selected, which enables multi-cursor editing.
Using
Command
D
seems deceptively simple. Find a pattern to match, and then make the change:
Loading editor...
Play
Play again
View steps
There’s already a lot of value in using
Command
D
for simple transformations, such as the above, but we’re just scratching the surface. Combined with smart text navigation techniques, we can take
Command
D
quite far.
Navigating text
First off, the basics.
Arrow keys
to move the cursor
Shift
to select text while moving the cursor.
Loading editor...
Play
Play again
View steps
Use
Option
to jump over words.
Loading editor...
Play
Play again
View steps
Jumping over words allows us to navigate text containing words of different lengths.
Loading editor...
Play
Play again
View steps
Use
Command
to jump to the beginning or end of a line.
Loading editor...
Play
Play again
View steps
Jumping to line boundaries allows us to navigate text that contains a variable number of words.
Loading editor...
Play
Play again
View steps
With text navigation locked down, let’s do some cool stuff.
Finding the pattern
Take this example of converting a series of
if
statements to a switch statement.
Loading editor...
Play
Play again
View steps
The
if
statements all have the exact same structure, so matching them is somewhat trivial. These sorts of patterns are the bread and butter of
Command
D
, they’re very common.
But
Command
D
is still very effective for non-uniform patterns. Those more complex patterns can come in the form of
a variable number of arguments,
a variable number of words in a string, or
different argument types.
Let’s take a look at an example.
Non-uniform patterns
Let’s say that we’re developing a library for evaluating math expressions.
import
{
evaluate
}
from
""imaginary-mathlib""
;
evaluate
(
""2 * 4""
)
;
// 8
evaluate
(
""[5, 10] / 2""
)
;
// [2.5, 5]
evaluate
(
""1 > 1/2 ? 1 : 'err'""
)
;
// 1
In making testing the library less verbose, we made a utility function that takes an expression, and its expected value.
function
expectEqual
(
expression
:
string
,
expectedValue
:
any
)
:
void
;
We have some test code using it that looks like so:
expectEqual
(
""2**4""
,
16
)
;
expectEqual
(
""1/0""
,
ERR_DIV_ZERO
)
;
expectEqual
(
""[1, 3, 5] * 2""
,
[
2
,
6
,
10
]
)
;
expectEqual
(
""1/10 < 0.2 ? 'a' : 'b'""
,
""a""
)
;
However, we want to convert this test code into the following:
const
tests
=
[
{
expression
:
""2**4""
,
value
:
16
}
,
{
expression
:
""1/0""
,
value
:
ERR_DIV_ZERO
}
,
{
expression
:
""[1, 3, 5] * 2""
,
value
:
[
2
,
6
,
10
]
}
,
{
expression
:
""1/10 < 0.2 ? 'a' : 'b'""
,
value
:
""a""
}
,
]
;
Since we have a lot of tests, doing this manually would be a lot of work. This is a prime case for using
Command
D
, we just need to find a pattern to match.
If we match
expectEqual
and move in from there, we run into the problem of the expressions being of different lengths.
Loading editor...
Play
Play again
View steps
Matching the end runs into the same problem. The values are of different lengths.
Loading editor...
Play
Play again
View steps
If we try to match the commas
,
between the expression and the value, we also match commas within the expressions and expected values:
Loading editor...
Play
Play again
View steps
The expression and expected value can be of any length, so matching the start or end is of no use.
However, we can observe that the expression is always a string. The expression always ends with double quote
""
immediately followed by a comma
,
. That’s a pattern we can match!
Loading editor...
Play
Play again
View steps
Matching every instance
In the example above, we matched four tests. That’s a pretty small number of tests, especially for a library that evaluates math expressions.
Pressing
Command
D
three times is not a lot of work, but if the number of tests were increased to 1,000 we would need to press
Command
D
999 times. This goes against our goal of making repeated changes grow non-linearly.
This is a nice time to introduce
Shift
Command
L
, which is the keyboard shortcut for
Select All Matches
.
Loading editor...
Play
Play again
View steps
You have to be a bit more careful with
Shift
Command
L
, since it selects
every
match in a file. You may match something that you did not intend to, which can occur outside of the current viewport.
For this reason, I prefer
Command
D
when working with a small number of matches. The matching feels more local, you visually see every match happen.
Skipping an instance
When selecting matches, you may want to skip an instance. To skip a match, press
Command
K
followed by
Command
D
.
Loading editor...
Play
Play again
View steps
In order to skip a match, you first need to add the match to the selection. After you have added a match to your selection, press
Command
K
and
Command
D
to unselect it and select the next match.
Pressing
Command
K
and
Command
D
resolves to a command called
Move Last Selection to Next Find Match
. It’s quite a technical name, but basically means
remove the most recent match, and
select the next match.
This is not very intuitive at first, but becomes second-nature given enough practice.
Matching line breaks
Matching every line can be useful when working with arbitrary data.
Take this text file:
Python
Java
C++
Go
Rust
Elixir
Let’s say that we want to convert the lines of this file into a JSON array of strings:
[
""Python""
,
""Java""
,
""C++""
,
""Go""
,
""Rust""
,
""Elixir""
,
]
There is no pattern across these lines, so matching each line seems impossible. However,
Command
D
allows us to match newlines.
Loading editor...
Play
Play again
View steps
Matching newlines is occasionally useful when
matching every line, or
matching a pattern that only appears at the end of a line, or
matching a pattern that spans two or more lines.
For an example of matching a multi-line pattern, take this example of only matching the empty arrays:
Loading editor...
Play
Play again
View steps
Case transformations
Translating between cases (such as changing snake-case to camelCase) comes up from time-to-time. I typically encounter this case when working across HTML, CSS and JavaScript.
VS Code has a handy
Transform to Uppercase
command that we can combine with
Command
D
to make this happen.
Loading editor...
Play
Play again
View steps
There is not a direct keyboard shortcut for the
Transform to Uppercase
command. In VS Code, you can run it by opening the command prompt with
Shift
Command
P
and then typing the name of the command.
Note:
Unfortunately, you will not be able to use the
Transform to Uppercase
method in this editor. This post uses Monaco Editor, which does not have VS Code’s command prompt.
That’s a wrap!
There are many ways to do multi-cursor editing using VS Code, but I find
Command
D
to be the simplest and most useful method.
Take what you learned in this post and apply it in your own work! There is a learning curve, but if you get past it then I promise that
Command
D
will prove itself to be a really useful and productive tool.
Thanks for reading the post!
Mailing list
To be notified of new posts, subscribe to my mailing list.
Subscribe","Jan 28, 2023"
Build your own schema language with TypeScript’s infer keyword,"The
infer
keyword in TypeScript, especially when combined with recursive types, is incredibly powerful. It enables you to transform types in complex and intricate ways that feel like they should be impossible.
In this article, we’ll solve the problems I encountered in building a
schema builder library
that makes extensive use of
infer
and recursive types.
By reading this article, I offer you an understanding of the
infer
keyword which will make you better suited to tackling new and harder TypeScript problems.
Introduction
A few years ago when I was learning Go, I learned about struct tags.
type
Payload
struct
{
Email
string
`json:""email,omitempty""`
}
Struct tags allow you to attach “meta information” to fields. They can then be read by other parts of your program to modify its behavior.
In other languages that do not have this feature, metadata can be attached to fields by wrapping the field in some type.
interface
FieldWithMetadata
<
T
>
{
field
:
T
;
metadata
:
string
;
}
Schema builders need to solve this problem. To create useful schemas you will want to add constraints to fields, such as requiring that an input string is a valid email address. Using Yup, a JavaScript schema builder, you might write code like this:
import
{
object
,
string
}
from
""yup""
;
const
schema
=
object
(
{
email
:
string
(
)
.
email
(
)
,
}
)
;
This syntax is nice. However, there are some aspects of the syntax that are more verbose than I would like.
Let’s take some examples. To mark a field as required, we add
.required()
.
const
schema
=
object
(
{
email
:
string
(
)
.
email
(
)
.
required
(
)
,
}
)
;
To add a default value, we add
.default()
.
const
schema
=
object
(
{
email
:
string
(
)
.
email
(
)
.
default
(
""
[email protected]
""
)
,
}
)
;
And for list of values, we wrap the type in
array()
.
const
schema
=
object
(
{
emails
:
array
(
string
(
)
.
email
(
)
)
.
required
(
)
,
}
)
;
This is all fine, but I would love to be able to use a more terse, “native-feeling”, syntax to describe the schema.
Here’s what I would like. To start, I want to denote the optionality of a field using the same syntax as TypeScript:
const
schema
=
object
(
{
email
?
:
string
(
)
.
email
(
)
,
}
)
;
Then, we would use the same syntax for default values as in JavaScript destructuring assignments:
const
schema
=
object
(
{
email
?
:
string
(
)
.
email
(
)
=
""
[email protected]
""
,
}
)
;
For lists of values, I would like to use an array literal syntax like so:
const
schema
=
object
(
{
contacts
:
string
[
]
,
}
)
;
Finally, let’s invent some custom syntax around constraints such as
.email()
.
const
schema
=
object
(
{
email
?
:
string
<
email
>
= ""
[email protected]
"",
});
I like this, but it won’t compile. This is just not valid JavaScript (or TypeScript) syntax.
But why should we let JavaScript dictate what we can and cannot do? CSS-in-JS is a thing, and they use template literals to embed CSS in JavaScript.
const
Button
=
styled
.
button
`
display
:
inline-block
;
border-radius
:
50
%
;
`
;
Well, we can do the same thing.
const
schema
=
compileSchema
(
`
{
email?: string <email> = ""
[email protected]
"";
}
`
)
;
Don’t we lose all type information?
It certainly feels like we should, but no!
Right now, our schema builder’s interface can be described like so.
function
compileSchema
<
T
extends
string
>
(
template
:
T
)
:
Schema
<???>
;
We need to fill in the blanks. We somehow want to take the string template
T
and convert it to the type that it represents.
TypeScript has features that enable us to do that. Let’s start with the basics and build from there.
Parsing primitives
The
extends
keyword enables conditional types in TypeScript.
type
Test
<
T
>
=
T
extends
""yes""
?
0
:
1
;
Test
<
""yes""
>
;
// 0
Test
<
""no""
>
;
// 1
We can use that to get the primitive represented by an input string:
type
ParsePrimitive
<
T
>
=
T
extends
""string""
?
string
:
T
extends
""number""
?
number
:
T
extends
""boolean""
?
boolean
:
never
;
ParsePrimitive
<
""boolean""
>
;
// boolean
The repetitive
? : ? :
is somewhat unwieldy and hard to read, but it allows us to create a chain of conditionals.
Parsing objects
The
ParsePrimitive
type is useful, but it’s insufficient to tackle a more complex string such as
""{value:number}""
. We can’t create an infinite number of cases to match every possible key-value combination.
To convert an object string
T
into a real type we need to
parse that
T
represents an object,
extract the key from
T
,
extract the value from
T
,
create an object using the key-value pair
We can test whether a string
T
matches the key-value object pattern using
Template Literal Types
.
type
IsObjectString
<
T
>
=
T
extends
`
{
${
string
}
:
${
string
}
}
`
?
true
:
false
;
This alone is not very useful. If we want to transform the string
T
into the actual object type it represents, we need to extract information about the key and value from
T
.
type
ParseObject
<
T
>
=
T
extends
`
{
${
string
}
:
${
string
}
}
`
?
something
// We need to extract information from 'T'
:
never
;
The
infer
keyword allows us to create variables during pattern matching.
type
ParseObject
<
T
>
=
T
extends
`
{
${
infer
K
}
:
${
infer
V
}
}
`
?
// We have access to 'K' and 'V' here
something
:
// 'K' and 'V' are not accessible here
never
;
The variables
K
and
V
are
only
created if
T
matches the pattern.
With them, we can create an object type.
type
ParseObject
<
T
>
=
T
extends
`
{
${
infer
K
}
:
${
infer
V
}
}
`
?
{
[
key
in
K
]
:
ParsePrimitive
<
V
>
}
:
never
;
ParseObject
<
`
{value:number}
`
>
;
// { value: number }
Objects with multiple properties
The first big hurdle we encounter is objects with multiple properties.
ParseObject
<
`
{a:string;b:number}
`
>
;
// { a: never }
The naive approach would be to match create multiple conditionals for each number of properties:
type
ParseObject
<
T
>
=
T
extends
`
{
${
infer
K0
}
:
${
infer
V0
}
}
`
?
{
[
key
in
K0
]
:
ParsePrimitive
<
V0
>
}
:
T
extends
`
{
${
infer
K0
}
:
${
infer
V0
}
;
${
infer
K1
}
:
${
infer
V1
}
}
`
?
{
[
key
in
K0
]
:
ParsePrimitive
<
V0
>
}
&
{
[
key
in
K1
]
:
ParsePrimitive
<
V1
>
}
:
T
extends
`
{
${
infer
K0
}
:
${
infer
V0
}
;
${
infer
K1
}
:
${
infer
V1
}
};
${
infer
K2
}
:
${
infer
V2
}
}
`
?
{
[
key
in
K0
]
:
ParsePrimitive
<
V0
>
}
&
{
[
key
in
K1
]
:
ParsePrimitive
<
V1
>
}
&
{
[
key
in
K2
]
:
ParsePrimitive
<
V2
>
}
:
never
;
This is terrible and does not scale. We can divide and conquer instead.
Given that we have the content of an object string
T
that contains N properties, we can split the content of
T
into N many strings that contain one property. We can then parse each property string individually.
type
ParseObject
<
T
>
=
T
extends
`
{
${
infer
Content
}
}
`
?
MergeArrayOfObjects
<
ParseProperties
<
SplitProperties
<
Content
>>>
:
never
;
Let’s start off with
SplitProperties
.
Split properties
Given a string
T
:
`
a:string;b:number;c:boolean
`
We want the output of
SplitProperties<T>
to be:
[
""a:string""
,
""b:number""
,
""c:boolean""
]
;
We can somewhat trivially create a type that splits the string by
;
.
type
SplitProperties
<
T
>
=
T
extends
`
${
infer
A
}
;
${
infer
B
}
`
?
[
A
,
B
]
:
[
T
]
;
Equals
<
SplitProperties
<
`
a:string;b:number;c:boolean
`
>
,
[
""a:string""
,
""b:number;c:boolean""
]
,
>
;
Note:
Equals
as used above asserts that the two arguments are equal.
But this only splits at the first instance of
;
.
We can recursively split the latter part of the string until we reach the base case of a string that contains no
;
.
type
SplitProperties
<
T
>
=
T
extends
`
${
infer
A
}
;
${
infer
B
}
`
?
[
A
,
...
SplitProperties
<
B
>
]
:
[
T
]
;
Equals
<
SplitProperties
<
`
a:string;b:number;c:boolean
`
>
,
[
""a:string""
,
""b:number""
,
""c:boolean""
]
,
>
;
This is our first example of recursive types. To better visualize what is going on, we can break down what is happening step by step:
// Shortened to 'Split' for brevity
type
Split
<
T
>
=
T
extends
`
${
infer
A
}
;
${
infer
B
}
`
?
[
A
,
...
Split
<
B
>
]
:
[
T
]
;
Split
<
`
1;2;3;4
`
>
;
// [`1`, ...Split<`2;3;4`>]
Split
<
`
2;3;4
`
>
;
// [`2`, ...Split<`3;4`>]
Split
<
`
3;4
`
>
;
// [`3`, ...Split<`4`>]
Split
<
`
4
`
>
;
// [`4`]
At each iteration, we find a single substring and delegate the responsibility of finding the rest of the substrings by recursing. Once we reach the base case of a string with no
;
, we return the string and stop recursing.
We’re going to be using recursive types
a lot
so take a moment to deeply understand what is going on. Things will only get more complex from here.
Parsing and merging the list of properties
Once we have the array (technically, a tuple) of strings, we need to parse each element emitted by
SplitProperties<T>
.
type
ParseProperties
<
T
extends
string
[
]
>
=
{
[
K
in
keyof
T
]
:
ParseProperty
<
T
[
K
]
>
;
}
;
We’ll implement
ParseProperty
later. For now, we’ll assume that
ParseProperty<T>
returns an object type that looks like so:
{
[
key
in
K
]
:
V
}
;
So for our example string, we have an output of:
Equals
<
ParseProperties
<
SplitProperties
<
`
a:string;b:number;c:boolean
`
>>
,
[
{
a
:
string
}
,
{
b
:
number
}
,
{
c
:
boolean
}
]
,
>
;
We can merge an array of objects like so:
type
MergeArrayOfObjects
<
T
>
=
T
extends
[
infer
R
,
...
infer
Rest
]
?
R
&
MergeArrayOfObjects
<
Rest
>
:
{
}
;
Equals
<
MergeArrayOfObjects
<
[
{
a
:
string
}
,
{
b
:
number
}
,
{
c
:
boolean
}
]
>
,
{
a
:
string
}
&
{
b
:
number
}
&
{
c
:
boolean
}
,
>
;
We’re using recursive types again. Let’s break this down a bit.
T extends [infer R, ...infer Rest]
will only match if
T
is an array with
at least
one element.
On a successful match, a variable
R
will be created that contains the first element in the array. The rest of the elements will be placed into an array
Rest
.
The
...
in
...Rest
indicates that we want the rest of the elements, from zero to infinity.
type
Example
<
T
>
=
T
extends
[
infer
R
,
...
infer
Rest
]
?
{
R
:
R
,
Rest
:
Rest
}
:
never
;
Example
<
[
1
,
2
,
3
]
>
// { R: 1, Rest: [2, 3] }
Example
<
[
2
,
3
]
>
// { R: 2, Rest: [3] }
Example
<
[
3
]
>
// { R: 3, Rest: [] }
Example
<
[
]
>
// never -- there are no elements for 'R' to match
Let’s break down the
MergeArrayOfObjects
in the same way:
// Shortened to 'Merge' for brevity
type
Merge
<
T
>
=
T
extends
[
infer
R
,
...
infer
Rest
]
?
R
&
Merge
<
Rest
>
:
{
}
;
Merge
<
[
{
a
:
1
}
,
{
b
:
2
}
,
{
c
:
3
}
]
>
// { a: 1 } & Merge<[{ b: 2 }, { c: 3 }]>
Merge
<
[
{
b
:
2
}
,
{
c
:
3
}
]
>
// { b: 2 } & Merge<[{ c: 3 }]>
Merge
<
[
{
c
:
3
}
]
>
// { c: 3 } & Merge<[]>
Merge
<
[
]
>
// {}
We keep recursing until we reach a base case. For
SplitProperties
, the base case was a string
T
without a
;
. For
MergeArrayOfObjects
, the base case is an empty array.
Object properties
A schema language that only supports primitives would produce large flat objects:
const
schema
=
schema
(
`
{
bookName: string;
bookDescription: string;
authorName: string;
authorAge: number;
}
`
)
;
I would much rather write this as two object properties:
const
schema
=
schema
(
`
{
book: {
name: string;
description: string;
};
author: {
name: string;
age: number;
};
}
`
)
;
In supporting object properties, we run into our first edge case.
type
SplitProperties
<
T
>
=
T
extends
`
${
infer
A
}
;
${
infer
B
}
`
?
[
A
,
...
SplitProperties
<
B
>
]
:
[
T
]
;
Equal
<
SplitProperties
<
`
a:{b:string;c:number};d:boolean
`
>
,
[
""a:{b:string""
,
""c:number}""
,
""d:boolean""
]
,
>
;
The pattern matching in
${infer A};${infer B}
is greedy so it matches the first instance of
;
that it encounters. This splits object properties with multiple sub-properties.
We could try to amend this by splitting by objects before splitting by
;
.
type
SplitProperties
<
T
>
=
T
extends
`
${
infer
A
}
{
${
infer
Content
}
};
${
infer
B
}
`
?
[
`
${
A
}
{
${
Content
}
}
`
,
...
SplitProperties
<
B
>
]
:
T
extends
`
${
infer
A
}
;
${
infer
B
}
`
?
[
A
,
...
SplitProperties
<
B
>
]
:
[
T
]
;
Equals
<
SplitProperties
<
`
a:{b:string;c:number};d:boolean
`
>
,
[
""a:{b:string;c:number}""
,
""d:boolean""
]
,
>
;
And, well, this seems to produce the correct result. However, this is easily broken by introducing one more level of nesting.
Equals
<
SplitProperties
<
`
a:{b:{c:string};d:number};e:boolean
`
>
,
[
""a:{b:{c:string}""
,
""d:number}""
,
""e:boolean""
]
,
>
;
This just moves the problem one level down.
Additionally, specifically matching
;
after
{}
is a problem when the object is the last property.
type
SplitProperties
<
T
>
=
T
extends
`
${
infer
A
}
{
${
infer
Content
}
};
${
infer
B
}
`
//                                     ^
?
[
`
${
A
}
{
${
Content
}
}
`
,
...
SplitProperties
<
B
>
]
:
/* ... */
;
type
T1
=
Equals
<
SplitProperties
<
`
a:string;b:{c:number;d:boolean}
`
>
,
[
""a:string""
,
""b:{c:number""
,
""d:boolean}""
]
,
>
We need a more robust way to deal with object properties.
Balancing brackets
The solutions we’ve used to split the list of properties all have the same problem. They split up object properties.
If we take a look at an incorrectly split-up property, such as
a:{b:string
or
a:{b:{c:string}
, we can observe that the number of opening and closing brackets (
{
and
}
) are unequal. In a well-formed object property, the number of opening and closing brackets will always be equal.
This observation leads to a different solution. Instead of preventing object properties from being split in the first place, we can fix them after the fact by balancing brackets.
Balancing brackets can be done with a relatively simple algorithm. Starting at the first element.
If the number of
{
and the number of
}
in the current element are not equal, then the string is unbalanced.
If the string is unbalanced, merge the current element with the next element and repeat step 1 again.
If the string is balanced, move to the next element.
In JavaScript, a recursive version of this algorithm looks like so:
function
areBracketsBalanced
(
s
:
string
)
{
return
numberOf
(
""{""
)
.
in
(
s
)
===
numberOf
(
""}""
)
.
in
(
s
)
;
}
function
balanceBrackets
(
items
:
string
[
]
)
{
if
(
items
.
length
<
2
)
return
items
;
if
(
areBracketsBalanced
(
items
[
0
]
)
)
{
return
[
items
[
0
]
,
...
balanceBrackets
(
items
.
slice
(
1
)
)
]
;
}
const
merged
=
items
[
0
]
+
items
[
1
]
;
return
balanceBrackets
(
[
merged
,
...
items
.
slice
(
2
)
]
)
;
}
Note:
This recursive solution is terrible for memory usage. We’re constructing a new array in every iteration. An iterative approach with a while loop would be optimal.
We can apply the same recursive pattern to balance brackets using types:
type
BalanceBrackets
<
T
extends
string
[
]
>
=
T
extends
[
infer
Curr
extends
string
,
infer
Next
extends
string
,
...
infer
Rest
extends
string
[
]
]
?
AreBracketsBalanced
<
Curr
>
extends
true
?
// Process next item
[
Curr
,
...
BalanceBrackets
<
[
Next
,
...
Rest
]
>
]
:
// Merge the next item with the current item
// and recursively process the merged item
BalanceBrackets
<
[
`
${
Curr
}
;
${
Next
}
`
,
...
Rest
]
>
:
T
;
This implements the same algorithm as the JavaScript example above, just for types.
The base case occurs when there are less than two elements in the array (we can’t merge 0 or 1 elements), which we implement in JavaScript with:
if
(
items
.
length
<
2
)
return
items
;
In TypeScript, we do that with:
T
extends
[
infer
Curr
,
infer
Next
,
...
infer
Rest
[
]
]
This pattern requires that both
Curr
and
Next
match a specific element in the array. If there are not at least two elements in the array
Curr
and
Next
can’t be assigned, so that pattern is not matched. This implements the base case for our recursion.
Note:
Remember that
...Rest
can be assigned zero to infinite elements.
However, we need to define
AreBracketsBalanced
. We want that type to return
true
if the string
T
contains the same number of
{
and
}
, and false otherwise.
Counting the number of characters in string type
To be able to check if a string contains an equal number of
{
and
}
, we first need to be able to count the number of those characters in the string.
We can access the number of elements in a tuple by reading its
length
property:
[
string
,
string
,
string
]
[
""length""
]
;
// 3
However, TypeScript just returns
number
for the length of string constants.
""abc""
[
""length""
]
;
// number
So what this problem boils down to is:
converting an input string
T
into a tuple of characters
filtering the tuple to only contain the character we’re counting
reading the
length
of the tuple
We can convert a string into a tuple by recursively inferring one character at a time.
type
StringToTuple
<
T
extends
string
>
=
T
extends
`
${
infer
Char
}
${
infer
Rest
}
`
?
[
Char
,
...
StringToTuple
<
Rest
>
]
:
[
]
;
StringToTuple
<
""abc""
>
;
// [""a"", ""b"", ""c""]
We can filter that tuple with some more recursive inference.
type
FilterTuple
<
T
extends
any
[
]
,
Include
>
=
T
extends
[
infer
Item
,
...
infer
Rest
]
?
Item
extends
Include
?
[
Item
,
...
FilterTuple
<
Rest
,
Include
>
]
:
FilterTuple
<
Rest
,
Include
>
:
[
]
;
FilterTuple
<
[
3
,
2
,
3
,
3
,
4
,
5
]
,
3
>
;
// [3, 3, 3]
Combining these, we can count the instances of a character in a string.
type
InstancesInString
<
T
extends
string
,
Char
>
=
FilterTuple
<
StringToTuple
<
T
>
,
Char
>
[
""length""
]
;
InstancesInString
<
`
a:{b:{c:string}
`
,
""{""
>
;
// 2
InstancesInString
<
`
a:{b:{c:string}
`
,
""}""
>
;
// 1
With that, we can create a type that checks whether the brackets are balanced.
type
AreBracketsBalanced
<
T
extends
string
>
=
InstancesInString
<
T
,
""{""
>
extends
InstancesInString
<
T
,
""}""
>
?
true
:
false
;
AreBracketsBalanced
<
`
a:{b:{c:string}
`
>
;
// false
AreBracketsBalanced
<
`
a:{b:{c:string}}
`
>
;
// true
Putting all of this together, we can now split properties correctly:
type
SplitProperties
<
T
extends
string
>
=
BalanceBrackets
<
SplitString
<
T
,
"";""
>>
;
Equals
<
SplitProperties
<
`
a:{b:string;c:number};d:boolean
`
>
,
[
""a:{b:string;c:number}""
,
""d:boolean""
]
,
>
;
Parsing a property
SplitProperties
is now producing an array of strings representing properties for us to process. Let’s now get to implementing
ParseProperty
, which I promised earlier.
Currently, properties take the form of
a primitive property, such as
a:string
an object property containing sub-properties, such as
a:{b:string}
The commonality between these is that both start with a key and a colon, allowing us to create a common
KeyValue
type.
type
KeyValue
<
T
extends
string
>
=
T
extends
`
${
infer
K
}
:
${
infer
V
}
`
?
{
key
:
K
;
value
:
ParseValue
<
V
>
;
}
:
never
;
When parsing the value, we can somewhat trivially distinguish between an object property and a primitive property.
type
ParseValue
<
T
>
=
T
extends
`
{
${
string
}
}
`
?
ParseObject
<
T
>
:
ParsePrimitive
<
T
>
;
With these, we can create a
ParseProperty
type.
type
ParseProperty
<
T
extends
string
>
=
KeyValue
<
T
>
extends
{
key
:
infer
K
extends
string
;
value
:
infer
V
;
}
?
{
[
key
in
K
]
:
V
}
:
never
;
Putting this together, we have now implemented a somewhat basic parser.
type
ParseObject
<
T
>
=
T
extends
`
{
${
infer
Content
}
}
`
?
MergeArrayOfObjects
<
ParseProperties
<
SplitProperties
<
Content
>>>
:
never
;
Equals
<
ParseObject
<
`
{a:{b:string;c:number};d:boolean}
`
>
,
{
a
:
{
b
:
string
;
c
:
number
}
;
d
:
boolean
;
}
,
>
Array properties
As mentioned earlier, I would like to support array properties using an array literal syntax.
const
schema
=
compileSchema
(
`
{
values: number[];
}
`
)
;
Arrays of objects should be supported, and arrays should be able to be multi-dimensional.
const
schema
=
compileSchema
(
`
{
matrix: { value: number }[][];
}
`
)
;
To support this, we can augment
FindValue
to check for array notation.
type
ParseValue
<
T
>
=
// Match array notation
T
extends
`
${
infer
Before
}
[]
`
?
ParseValue
<
Before
>
[
]
:
// Match object
T
extends
`
{
${
string
}
}
`
?
ParseObject
<
T
>
:
// Default to primitives if neither array nor object
ParsePrimitive
<
T
>
;
ParseValue
<
`
{a:string[]}[][]
`
>
;
// { a: string[]; }[][]
Optional values
I would like to be able to denote optional properties using
?:
like in TypeScript:
const
schema
=
compileSchema
(
`
{
value?: number;
}
`
)
;
We can update
KeyValue
to check for the presence of
?:
.
type
KeyValue
<
T
extends
string
>
=
// Optional property
T
extends
`
${
infer
K
}
?:
${
infer
V
}
`
?
{
key
:
K
;
value
:
ParseValue
<
V
>
|
null
;
}
:
// Required property
T
extends
`
${
infer
K
}
:
${
infer
V
}
`
?
{
key
:
K
;
value
:
ParseValue
<
V
>
;
}
:
never
;
ParseValue
<
`
{a?:number}
`
>
;
// { a: number | null }
This looks sensible, but there’s a subtle bug.
If a non-optional object property contains an optional property, then the
?:
in
${infer K}?:${infer V}
matches the property inside of the object.
type
KeyValue
<
T
extends
string
>
=
T
extends
`
${
infer
K
}
?:
${
infer
V
}
`
?
[
K
,
V
]
:
never
;
KeyValue
<
`
a:{b?:string}
`
>
;
// [""a:{b"", ""string}""]
We can resolve this by always matching the first
:
and then checking whether
K
ends with a
?
.
type
KeyValue
<
T
extends
string
>
=
T
extends
`
${
infer
K
}
:
${
infer
V
}
`
?
K
extends
`
${
infer
KeyWithoutQuestionmark
}
?
`
?
{
key
:
KeyWithoutQuestionmark
;
value
:
ParseValue
<
V
>
|
null
;
}
:
{
key
:
K
;
value
:
ParseValue
<
V
>
;
}
:
never
;
Whitespace
You may have noticed the lack of whitespace in the examples above. However, that doesn’t seem to square with how we intend for templates to be written by users.
const
schema
=
compileSchema
(
`
{
name: string;
email: string;
}
`
)
;
TypeScript template literals are whitespace sensitive, which we can sidestep by stripping out all whitespace from the input string before processing it.
We do that, of course, using
infer
and recursion.
type
RemoveSpaces
<
T
extends
string
>
=
T
extends
`
${
infer
L
}
${
infer
R
}
`
?
RemoveSpaces
<
`
${
L
}
${
R
}
`
>
:
T
;
type
RemoveTabs
<
T
extends
string
>
=
T
extends
`
${
infer
L
}
\t
${
infer
R
}
`
?
RemoveTabs
<
`
${
L
}
${
R
}
`
>
:
T
;
type
RemoveNewlines
<
T
extends
string
>
=
T
extends
`
${
infer
L
}
\n
${
infer
R
}
`
?
RemoveNewlines
<
`
${
L
}
${
R
}
`
>
:
T
;
type
RemoveWhitespace
<
T
extends
string
>
=
RemoveSpaces
<
RemoveTabs
<
RemoveNewlines
<
T
>>>
;
Equals
<
RemoveWhitespace
<
`
{\n  hello: { world: string;\n}
`
>
,
`
{hello:{world:string;}
`
,
>
;
We can apply this by wrapping the input string to the top-level parsing type with
RemoveWhitespace
.
type
Parse
<
T
extends
string
>
=
ParseObject
<
RemoveWhitespace
<
T
>>
;
Outro
I hope I was successful in showing how powerful and versatile the
infer
keyword and recursive types are in TypeScript.
The
source code
for this article is available for you to take a look at. Feel free to tinker, extend the code to support new features, or change up the syntax entirely!
If you would like to take a look at the open-source library I wrote, check out
strema
on GitHub
. It’s a more mature version of what we implemented in this article.
It implements:
Hash maps
Rules (such as
<email>
)
Default values
Tests for the types
Custom type errors at compile-time
A runtime template parser and data validator
Anyways, thanks for reading!
Mailing list
To be notified of new posts, subscribe to my mailing list.
Subscribe","Nov 8, 2022"
